{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kwonjihan/ML-teamproject/blob/developtemp/Embedding/FINAL_BERT_Embedding_Modified_parameter_1_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfRNbEvV-8tp",
        "outputId": "bb4b9fe1-c30f-4e4b-b925-89fa143513ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path='/content/drive/MyDrive/12K IMDB Dataset.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "woLaLsvCPFAi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from typing import Optional, Tuple\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgRXfpJiLsAz",
        "outputId": "7d45831a-b8d8-4e90-a839-5e88d4fc84d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting NRCLex\n",
            "  Downloading NRCLex-4.0-py3-none-any.whl (4.4 kB)\n",
            "Collecting textblob (from NRCLex)\n",
            "  Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.3/626.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of nrclex to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting NRCLex\n",
            "  Downloading NRCLex-3.0.0.tar.gz (396 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk>=3.8 in /usr/local/lib/python3.10/dist-packages (from textblob->NRCLex) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8->textblob->NRCLex) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8->textblob->NRCLex) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8->textblob->NRCLex) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8->textblob->NRCLex) (4.66.4)\n",
            "Building wheels for collected packages: NRCLex\n",
            "  Building wheel for NRCLex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NRCLex: filename=NRCLex-3.0.0-py3-none-any.whl size=43309 sha256=1337a9d2ce4803f9d7c575d47fbb69324bea2456c71f7853a29472f6d0e78cc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/10/44/6abfb1234298806a145fd6bcaec8cbc712e88dd1cd6cb242fa\n",
            "Successfully built NRCLex\n",
            "Installing collected packages: textblob, NRCLex\n",
            "Successfully installed NRCLex-3.0.0 textblob-0.18.0.post0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "!pip install NRCLex\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px00_B1UNyv1"
      },
      "source": [
        "## 감정에 해당하는 토큰 임베딩에 큰 포션을 취하는 방법\n",
        "- 1. 우선 문장을 토큰화하기 전에 감정이 드러난 단어를 찾는다\n",
        "- 2. 해당 단어를 버트 토크나이저를 통해 토크나이즈 된 결과를 저장해둔다\n",
        "- 3. 만약 감정이 있다면 해당 단어가 벡터로 표현되고 합해져서 임베딩 될 때 더 크게 영향을 주도록 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGZfCrtcI7Ba",
        "outputId": "1e71571f-1af6-4d12-ddff-85b6c6dfc331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive words: []\n",
            "Negative words: []\n"
          ]
        }
      ],
      "source": [
        "## 문장에서 단어 감정 추출 예시 ##\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def analyze_sentence(sentence):\n",
        "    # 문장을 토큰화\n",
        "    words = word_tokenize(sentence)\n",
        "\n",
        "    # VADER 초기화\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # 감정이 포함된 단어들 저장\n",
        "    positive_words = []\n",
        "    negative_words = []\n",
        "\n",
        "    # 각 단어의 감정 점수 분석\n",
        "    for word in words:\n",
        "        score = analyzer.polarity_scores(word)['compound']\n",
        "        if score > 0:\n",
        "            positive_words.append(word)\n",
        "        elif score < 0:\n",
        "            negative_words.append(word)\n",
        "\n",
        "    return positive_words, negative_words\n",
        "\n",
        "# 테스트 문장\n",
        "sentence = \"i wouldn't rent this one even on dollar rental night.\"\n",
        "positive_words, negative_words = analyze_sentence(sentence)\n",
        "\n",
        "print(\"Positive words:\", positive_words)\n",
        "print(\"Negative words:\", negative_words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzetDrS4Op6t"
      },
      "source": [
        "\n",
        "## 1.우선 문장을 토큰화하기 전에 감정이 드러난 단어를 찾는다\n",
        "## 2.해당 단어를 버트 토크나이저를 통해 토크나이즈 된 결과를 저장해둔다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CIQbjs9wOs-p"
      },
      "outputs": [],
      "source": [
        "# 데이터 전처리 #\n",
        "import itertools\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = re.sub(r'<[^>]+>', ' ', self.texts[idx])  # HTML 태그 제거\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # 문장을 토큰화하고 감정 점수를 분석\n",
        "        words = word_tokenize(text)\n",
        "        sentiment_words = []\n",
        "        for word in words:\n",
        "            score = self.analyzer.polarity_scores(word)['compound']\n",
        "            if score > 0:\n",
        "                sentiment_words.append(word)\n",
        "            elif score < 0:\n",
        "                sentiment_words.append(word)\n",
        "\n",
        "\n",
        "        # 감정 단어들을 토큰화\n",
        "        tokenized_sentiment_words = []\n",
        "        for word in sentiment_words:\n",
        "            tokenized = self.tokenizer(word, add_special_tokens=False)['input_ids']\n",
        "            tokenized_sentiment_words.append(tokenized) # 토큰화된 감정단어들\n",
        "\n",
        "        # '##' 붙은 서브워드 제거\n",
        "        filtered_tokens = []\n",
        "        for token_ids in tokenized_sentiment_words:\n",
        "            tokens = self.tokenizer.convert_ids_to_tokens(token_ids)\n",
        "            filtered_tokens.extend([token for token in tokens if not token.startswith('##')])\n",
        "\n",
        "        # 토큰들을 하나의 텍스트로 이어붙이기\n",
        "        result_text = ' '.join(filtered_tokens)\n",
        "\n",
        "        # 토큰화 및 인코딩\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze()\n",
        "        attention_mask = encoding['attention_mask'].squeeze()\n",
        "        token_type_ids = encoding['token_type_ids'].squeeze()\n",
        "\n",
        "        if not result_text:\n",
        "            result_text = \"[PAD]\"\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            result_text,\n",
        "            add_special_tokens=False,\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        sentiment_tokens = encoding['input_ids'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'token_type_ids': token_type_ids,\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "            #'sentiment_words' :  sentiment_words,\n",
        "            #'tokenized_sentiment_words' : tokenized_sentiment_words,\n",
        "            \"sentiment_tokens\" :  sentiment_tokens,\n",
        "        }\n",
        "\n",
        "def load_data(file_path, tokenizer, max_length=512):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "    texts = df['review'].tolist()   # 리스트 요소 하나에 풀 문장이 들어있음\n",
        "    labels = df['sentiment'].tolist()\n",
        "    print(texts[0])\n",
        "    train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "    print(train_texts[0])\n",
        "\n",
        "    train_dataset = SentimentDataset(train_texts, train_labels, tokenizer, max_length)\n",
        "    val_dataset = SentimentDataset(val_texts, val_labels, tokenizer, max_length)\n",
        "\n",
        "    return train_dataset, val_dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPKCGzikOsnP"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349,
          "referenced_widgets": [
            "be946dbf8eea4895a9971a24f18a40cd",
            "637ccc8734664877819d97f1b4519061",
            "1807253a9188400a89aa4653c0401319",
            "2c6e8ccb76e54b319d15d563b33ac629",
            "36f8816c0d834a18a1cc1400fd769e25",
            "7c28744a2ae848fcae8bd837579f07b3",
            "dc9acfa22c6649fbb2bdc3ef2564dc97",
            "85f58d528ac542dd8252a1b9c928478d",
            "e921f70094fb4d0f82a85d470c09f823",
            "cd766b48d84147b88bbc3a8729f9810c",
            "e62297d2a1c14f249c6725c44227c68e",
            "db19d6c49d494039bc3e93a6ef3054a8",
            "849d3880b87c418a9473d07690335c3d",
            "ccfb21ba8e1441848bcf6a678abd3863",
            "ea5c368baca44632b98aff25ec1ffe0f",
            "e633b32f8c224295b98c63f02fdffc9d",
            "3acd0f1491454a7181634612612be0b6",
            "a8665cd421634275ac0d83451d9846d7",
            "f42b7fb4a7b74dcab80e2892a7f01feb",
            "a30bebcc79bc4e43be2d42e44e1bfc1a",
            "ee5329ebd97342b4a496fda3304249e6",
            "fc93f8c6011c4625a2e8e2ee4154fd51",
            "c15208ae697e46bfa92732c9d1e29f40",
            "deb706245dfc4685bd964c42f33ebef4",
            "efee37703456456984ac8903a8d596bf",
            "672a7cbcaa59493f9195153a1737498d",
            "59d7c97b205c4a1a9d219e6f8e43fd00",
            "259fd8592ab34d14b4b5b1e1c7b6c85a",
            "aa38bbaf62c44438b922e4dd4349d74d",
            "ca96e9a826144004888b272a998a5304",
            "912cc447ac5f4fce9d31a13732a75478",
            "29f124f9e67d45ed8e7ecc1b2d5cdf9e",
            "0ebf2753b23745079dab2a7fb72211bc",
            "8a8e0f01621b4e10bd9bec34952ccb95",
            "65d4737b70e54817a0b3a666c2a957cd",
            "aa93eda1590548a38898315eee07c58d",
            "9f33d34b938342d1ba9b56654285a6a9",
            "7011d9e310994e39b2d84321d8360c7e",
            "b55a3c6f079545caabe7c9c4eed65bc9",
            "f6b94d7571494ff4b8b48778241c9e84",
            "c7b5e0c9042e448b900b550a4b307513",
            "9ba66f6a9aa54cae919ce690eab9e101",
            "7b01aac93372427a99a777c9d7903db0",
            "8ef4d97255ce40dea3126022e6e46a40"
          ]
        },
        "id": "zuK6Nz5JO1ip",
        "outputId": "7427369a-1f1e-468a-ca9c-5b7bbb148103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be946dbf8eea4895a9971a24f18a40cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db19d6c49d494039bc3e93a6ef3054a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c15208ae697e46bfa92732c9d1e29f40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a8e0f01621b4e10bd9bec34952ccb95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
            "What can I say??? This movie was so Dumb & Stupid I thought it was a Psychotic DRAG Comedy - They should rename it \"Bitching Pregnant Cat Fight!\" What a stupid waste of time , if you want to see(DIE DIE!!! \"I WANT YOUR BABY DRAG QUEEN) Jennifer Tilly being her Freaky self then just rent out one Of the \"Chucky\" movie, oh ya , \"The Bride Of Chucky.\" It's more fun watching the Two Ugly Plastic dolls (one of them Jennifer Tilly turned into the UGLY Female version of Chucky) having Squeaky plastic rubber sex then watching Daryl Hannah being pregnant , Dumb & stupid; & Jennifer Tilly Grinding up her Husbang in a Food Processor reminded me of my Mother trying to do House Work! OK it's just BAD!!!\n"
          ]
        }
      ],
      "source": [
        "# 토크나이저 초기화\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# 데이터 로드\n",
        "train_dataset, val_dataset = load_data(file_path, tokenizer)\n",
        "\n",
        "# 데이터 로더 생성\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIJy9bbke-7H",
        "outputId": "52e580f7-24af-4d11-d8c0-e60b25fa9161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([  101,  1045,  2876,  1005,  1056,  9278,  2023,  2028,  2130,  2006,\n",
            "         7922, 12635,  2305,  1012,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(0), 'sentiment_tokens': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])}\n",
            "i wouldn't rent this one even on dollar rental night.\n"
          ]
        }
      ],
      "source": [
        "# 데이터셋 전체에서 가장 짧은 길이를 찾는 코드\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# 사전 학습된 BERT 토크나이저 로드\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "# 각 항목의 길이를 저장할 딕셔너리 초기화\n",
        "\n",
        "\n",
        "\n",
        "print(train_dataset[4891])\n",
        "input_ids = torch.tensor([101, 1045, 2876, 1005, 1056, 9278, 2023, 2028, 2130, 2006,\n",
        "                          7922, 12635, 2305, 1012, 102, 0, 0, 0, 0, 0,])\n",
        "decoded_text = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
        "\n",
        "# 결과 출력\n",
        "print(decoded_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "xnF-HxEmERu7",
        "outputId": "0aa0b4eb-04f2-42aa-f2d6-7c9e47e8d7c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample text: Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.<br /><br />The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.<br /><br />The acting is good under Mr. Mattei's direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.<br /><br />We wish Mr. Mattei good luck and await anxiously for his next work.\n",
            "Tokenized input IDs: [101, 2023, 3185, 2003, 2241, 2006, 1996, 2338, 1010, 1000, 1037, 2116, 11867, 7770, 7983, 2098, 2518, 1000, 2011, 7658, 10514, 25811, 1998, 10455, 3314, 1997, 2679, 4262, 2090, 4004, 2015, 1998, 12461, 1010, 1037, 8476, 2008, 3310, 2013, 7658, 1005, 1055, 3167, 6322, 2004, 2019, 23399, 3652, 2039, 1999, 2859, 1012, 2008, 4281, 1010, 1998, 1996, 3376, 4291, 4290, 10906, 1010, 3957, 2023, 2293, 2466, 1037, 4310, 1998, 2738, 15236, 7224, 2005, 2049, 2051, 1012, 2060, 2084, 2008, 1010, 1996, 2466, 2003, 1037, 12991, 27086, 7472, 2007, 1037, 13432, 2299, 2008, 2003, 3383, 2062, 4622, 2084, 1996, 3185, 2993, 1012, 1996, 3376, 7673, 3557, 3504, 1996, 2112, 1998, 3957, 1037, 6919, 1010, 7436, 4222, 2836, 2004, 1037, 3460, 1997, 3816, 8843, 2076, 1996, 13896, 1997, 15523, 1999, 8240, 2859, 1012, 2520, 9988, 2196, 2246, 2488, 2652, 1037, 6298, 2599, 2004, 1037, 4988, 5266, 2162, 7950, 4655, 1999, 1996, 2088, 1012, 1996, 3772, 2003, 2327, 18624, 1010, 1998, 1996, 6370, 2090, 1996, 2048, 10205, 3640, 2005, 2070, 10218, 5312, 1997, 3165, 3898, 12242, 2469, 2000, 14899, 1996, 8072, 1997, 2216, 2040, 2024, 6298, 3973, 13050, 1012, 1996, 16434, 2428, 7545, 2041, 5595, 1005, 1055, 4291, 4290, 1010, 2926, 1996, 25566, 12549, 1996, 6496, 2073, 1996, 2048, 10205, 5247, 2037, 2087, 10305, 5312, 1012, 1996, 4566, 2003, 1037, 2613, 7697, 1011, 12181, 2121, 1012, 2070, 2089, 5136, 23069, 7472, 2015, 3413, 2063, 1010, 2021, 1010, 2005, 2216, 2040, 5959, 4438, 5365, 2293, 3441, 1010, 2023, 2003, 1037, 9716, 2742, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Tokenized tokens: ['[CLS]', 'this', 'movie', 'is', 'based', 'on', 'the', 'book', ',', '\"', 'a', 'many', 'sp', '##len', '##dor', '##ed', 'thing', '\"', 'by', 'han', 'su', '##yin', 'and', 'tackles', 'issues', 'of', 'race', 'relations', 'between', 'asian', '##s', 'and', 'whites', ',', 'a', 'topic', 'that', 'comes', 'from', 'han', \"'\", 's', 'personal', 'experiences', 'as', 'an', 'eurasian', 'growing', 'up', 'in', 'china', '.', 'that', 'background', ',', 'and', 'the', 'beautiful', 'hong', 'kong', 'settings', ',', 'gives', 'this', 'love', 'story', 'a', 'unique', 'and', 'rather', 'daring', 'atmosphere', 'for', 'its', 'time', '.', 'other', 'than', 'that', ',', 'the', 'story', 'is', 'a', 'stereo', '##typical', 'romance', 'with', 'a', 'memorable', 'song', 'that', 'is', 'perhaps', 'more', 'remembered', 'than', 'the', 'movie', 'itself', '.', 'the', 'beautiful', 'jennifer', 'jones', 'looks', 'the', 'part', 'and', 'gives', 'a', 'wonderful', ',', 'oscar', 'nominated', 'performance', 'as', 'a', 'doctor', 'of', 'mixed', 'breed', 'during', 'the', 'advent', 'of', 'communism', 'in', 'mainland', 'china', '.', 'william', 'holden', 'never', 'looked', 'better', 'playing', 'a', 'romantic', 'lead', 'as', 'a', 'journalist', 'covering', 'war', 'torn', 'regions', 'in', 'the', 'world', '.', 'the', 'acting', 'is', 'top', 'notch', ',', 'and', 'the', 'chemistry', 'between', 'the', 'two', 'lovers', 'provides', 'for', 'some', 'genuine', 'moments', 'of', 'silver', 'screen', 'affection', 'sure', 'to', 'melt', 'the', 'hearts', 'of', 'those', 'who', 'are', 'romantic', '##ally', 'inclined', '.', 'the', 'cinematography', 'really', 'brings', 'out', 'fifty', \"'\", 's', 'hong', 'kong', ',', 'especially', 'the', 'hilltop', 'overlooking', 'the', 'harbor', 'where', 'the', 'two', 'lovers', 'spend', 'their', 'most', 'intimate', 'moments', '.', 'the', 'ending', 'is', 'a', 'real', 'tear', '-', 'jerk', '##er', '.', 'some', 'may', 'consider', 'sentimental', 'romance', '##s', 'pass', '##e', ',', 'but', ',', 'for', 'those', 'who', 'enjoy', 'classic', 'hollywood', 'love', 'stories', ',', 'this', 'is', 'a', 'shining', 'example', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "Tokenized attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Tokenized token type IDs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Label: 1\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'sentiment_words'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-2a3d077dada6>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tokenized token type IDs:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Label:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sentiment_words:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment_words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tokenized sentiment words:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized_sentiment_words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'sentiment_words'"
          ]
        }
      ],
      "source": [
        "    ## 예시 확인하기 ##\n",
        "df = pd.read_csv(file_path)\n",
        "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "texts = df['review'].tolist()\n",
        "labels = df['sentiment'].tolist()\n",
        "dataset = SentimentDataset(texts, labels, tokenizer, 512)\n",
        "\"\"\"\n",
        "            input_ids=batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask'],\n",
        "            token_type_ids=batch['token_type_ids'],\n",
        "            labels=batch['labels'],\n",
        "            sentiment_tokens=batch['sentiment_tokens']\n",
        "\"\"\"\n",
        "print(\"Sample text:\", texts[3])\n",
        "sample_item = dataset[19]\n",
        "print(\"Tokenized input IDs:\", sample_item['input_ids'].tolist())\n",
        "print(\"Tokenized tokens:\", tokenizer.convert_ids_to_tokens(sample_item['input_ids'].tolist()))\n",
        "print(\"Tokenized attention mask:\", sample_item['attention_mask'].tolist())\n",
        "print(\"Tokenized token type IDs:\", sample_item['token_type_ids'].tolist())\n",
        "print(\"Label:\", sample_item['labels'].item())\n",
        "print('sentiment_words:', sample_item['sentiment_words'])\n",
        "print('Tokenized sentiment words:',sample_item['tokenized_sentiment_words'])\n",
        "\n",
        "# 토큰화된 감정 단어들 출력\n",
        "tokenized_sentiment_words = sample_item['tokenized_sentiment_words']\n",
        "all_tokens = []\n",
        "filtered_all_tokens = []\n",
        "\n",
        "for token_ids in tokenized_sentiment_words:\n",
        "        tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
        "        filtered_tokens = [token for token in tokens if not token.startswith('##')]\n",
        "        filtered_all_tokens.append(filtered_tokens)\n",
        "        all_tokens.append(tokens)\n",
        "\n",
        "print('## removed Tokenized sentiment words :', filtered_all_tokens)\n",
        "print(len(sample_item['input_ids']))\n",
        "print(len(sample_item['attention_mask']))\n",
        "print(len(sample_item['token_type_ids']))\n",
        "print(len(sample_item[\"attention_mask\"]))\n",
        "print(len(sample_item[\"sentiment_tokens\"]))\n",
        "    ##===============##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8RxEd2bIQyQ1"
      },
      "outputs": [],
      "source": [
        "# [모델 준비] #\n",
        "\n",
        "# 활성화 함수\n",
        "def gelu(x):\n",
        "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
        "\n",
        "# 활성화 함수 매핑\n",
        "ACT2FN = {\"gelu\": gelu, \"relu\": torch.nn.functional.relu, \"swish\": torch.nn.functional.silu}\n",
        "\n",
        "# 모델 설정\n",
        "\n",
        "class BertEmbeddings(nn.Module):\n",
        "    #def __init__(self, config):\n",
        "    def __init__(self, config, sentiment_ratio_init: float = 1.5):\n",
        "        super().__init__()\n",
        "        # 단어 임베딩, 위치 임베딩, 토큰 타입 임베딩\n",
        "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)\n",
        "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
        "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
        "\n",
        "        # 레이어 정규화와 드롭아웃\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.position_embedding_type = getattr(config, \"position_embedding_type\", \"absolute\")\n",
        "        self.register_buffer(\"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)), persistent=False)\n",
        "        self.register_buffer(\"token_type_ids\", torch.zeros(self.position_ids.size(), dtype=torch.long), persistent=False)\n",
        "\n",
        "        # 학습 가능한 sentiment_ratio 파라미터 추가 및 초기값 설정\n",
        "        self.sentiment_ratio = nn.Parameter(torch.tensor(sentiment_ratio_init))\n",
        "\n",
        "    def forward(self, input_ids=None, token_type_ids=None, position_ids=None, inputs_embeds=None, past_key_values_length=0, sentiment_tokens=None):\n",
        "        if input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "        else:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "\n",
        "        seq_length = input_shape[1]\n",
        "\n",
        "        if position_ids is None:\n",
        "            position_ids = self.position_ids[:, past_key_values_length: seq_length + past_key_values_length]\n",
        "\n",
        "        if token_type_ids is None:\n",
        "            if hasattr(self, \"token_type_ids\"):\n",
        "                buffered_token_type_ids = self.token_type_ids[:, :seq_length]\n",
        "                buffered_token_type_ids_expanded = buffered_token_type_ids.expand(input_shape[0], seq_length)\n",
        "                token_type_ids = buffered_token_type_ids_expanded\n",
        "            else:\n",
        "                token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.position_ids.device)\n",
        "\n",
        "        if inputs_embeds is None:\n",
        "            inputs_embeds = self.word_embeddings(input_ids)\n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "\n",
        "        # 입력 임베딩 생성\n",
        "        embeddings = inputs_embeds + token_type_embeddings\n",
        "\n",
        "        for i in range(input_ids.size(0)):  # 배치의 각 문장에 대해\n",
        "            sentiment_token = sentiment_tokens[i]\n",
        "            sentiment_token_filtered = sentiment_token[(sentiment_token != 0) & (sentiment_token != 101) & (sentiment_token != 102)]\n",
        "            for j in range(input_ids.size(1)):  # 각 문장의 각 토큰에 대해\n",
        "                if input_ids[i, j] in sentiment_token_filtered:\n",
        "                    # 파라미터로 사용시\n",
        "                    embeddings[i, j] = self.sentiment_ratio * inputs_embeds[i, j] + token_type_embeddings[i, j]\n",
        "                if j == 0 and i == 0:\n",
        "                    print(\"Sentiment ratio for this batch: \", self.sentiment_ratio.item())\n",
        "                    # 정해줄 때\n",
        "                    #embeddings[i, j] = 1.5 * inputs_embeds[i, j] + token_type_embeddings[i, j]\n",
        "\n",
        "        if self.position_embedding_type == \"absolute\":\n",
        "            position_embeddings = self.position_embeddings(position_ids)\n",
        "            embeddings += position_embeddings\n",
        "\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "# 셀프 어텐션 구현 클래스\n",
        "class BertSelfAttention(nn.Module):\n",
        "    def __init__(self, config, position_embedding_type=None):\n",
        "        super().__init__()\n",
        "        # hidden_size가 num_attention_heads의 배수가 아니면 오류 발생\n",
        "        if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n",
        "                f\"heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "\n",
        "        # 어텐션 헤드의 수와 각 헤드의 크기, 전체 헤드 크기 설정\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(\n",
        "            config.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        # Query, Key, Value 행렬 정의\n",
        "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "\n",
        "        # 드롭아웃 레이어 정의\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        # 위치 임베딩 유형 설정\n",
        "        self.position_embedding_type = position_embedding_type or getattr(\n",
        "            config, \"position_embedding_type\", \"absolute\"\n",
        "        )\n",
        "        # 상대적 위치 임베딩을 사용하는 경우, 위치 임베딩 레이어 정의\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            self.max_position_embeddings = config.max_position_embeddings\n",
        "            self.distance_embedding = nn.Embedding(\n",
        "                2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
        "\n",
        "        # 디코더인지 여부 설정\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # 텐서의 크기 변환\n",
        "        new_x_shape = x.size()[\n",
        "            :-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(new_x_shape)\n",
        "        # 텐서의 차원 변경 [batch_size, num_heads, seq_len, head_size]\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        # Query 레이어 계산\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        # 크로스 어텐션인지 여부 확인\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention and past_key_value is not None:\n",
        "            # 과거의 k, v 값을 재사용 (크로스 어텐션)\n",
        "            key_layer = past_key_value[0]\n",
        "            value_layer = past_key_value[1]\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif is_cross_attention:\n",
        "            # 인코더의 키와 값을 사용하여 크로스 어텐션 수행\n",
        "            key_layer = self.transpose_for_scores(\n",
        "                self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(\n",
        "                self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif past_key_value is not None:\n",
        "            # 과거의 k, v 값을 현재의 k, v와 결합 (디코더의 셀프 어텐션)\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "            key_layer = torch.cat([past_key_value[0], key_layer], dim=2)\n",
        "            value_layer = torch.cat([past_key_value[1], value_layer], dim=2)\n",
        "        else:\n",
        "            # 현재의 히든 스테이트에서 키와 값을 계산 (셀프 어텐션)\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        # Query 레이어 변환\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # 캐시를 사용할지 여부 설정\n",
        "        use_cache = past_key_value is not None\n",
        "        if self.is_decoder:\n",
        "            # 디코더인 경우, 키와 값을 캐싱\n",
        "            past_key_value = (key_layer, value_layer)\n",
        "\n",
        "        # Query와 Key의 내적(dot product)을 통해 어텐션 스코어 계산\n",
        "        attention_scores = torch.matmul(\n",
        "            query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            # 상대적 위치 임베딩을 사용하는 경우\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(\n",
        "                    query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(\n",
        "                key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            # 거리 임베딩 계산\n",
        "            positional_embedding = self.distance_embedding(\n",
        "                distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(\n",
        "                dtype=query_layer.dtype)  # fp16 호환성\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                # 상대적 위치 임베딩을 쿼리에 적용\n",
        "                relative_position_scores = torch.einsum(\n",
        "                    \"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                # 상대적 위치 임베딩을 쿼리와 키에 적용\n",
        "                relative_position_scores_query = torch.einsum(\n",
        "                    \"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\n",
        "                    \"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + \\\n",
        "                    relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        # 어텐션 스코어를 정규화\n",
        "        attention_scores = attention_scores / \\\n",
        "            math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            # 어텐션 마스크 적용\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # 어텐션 스코어를 확률로 변환\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # 드롭아웃 적용\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # 헤드 마스크 적용\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        # 컨텍스트 레이어 계산\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        # 텐서의 크기 변환 및 재배치\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[\n",
        "            :-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        # 출력 생성\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (\n",
        "            context_layer,)\n",
        "\n",
        "        # 디코더인 경우, past_key_value를 출력에 포함\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "# 셀프 어텐션 출력 처리 클래스\n",
        "class BertSelfOutput(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        # 드롭아웃, 레이어 정규화, 잔차 연결 적용\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "\n",
        "# 어텐션 메커니즘 클래스\n",
        "class BertAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.self = BertSelfAttention(config)\n",
        "        self.output = BertSelfOutput(config)\n",
        "\n",
        "    def forward(self, input_tensor, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_value=None, output_attentions=False):\n",
        "        # 셀프 어텐션 및 출력 계산\n",
        "        self_outputs = self.self(\n",
        "            input_tensor,\n",
        "            attention_mask,\n",
        "            head_mask,\n",
        "            encoder_hidden_states,\n",
        "            encoder_attention_mask,\n",
        "            past_key_value,\n",
        "            output_attentions,\n",
        "        )\n",
        "        attention_output = self.output(self_outputs[0], input_tensor)\n",
        "        outputs = (attention_output,) + self_outputs[1:]\n",
        "        return outputs\n",
        "\n",
        "# 중간 레이어 활성화 함수 클래스\n",
        "class BertIntermediate(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
        "        self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        # 중간 레이어 활성화 함수 적용\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "# 중간 레이어 출력 처리 클래스\n",
        "class BertOutput(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        # 드롭아웃, 레이어 정규화, 잔차 연결 적용\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.Layer\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        # 드롭아웃, 레이어 정규화, 잔차 연결 적용\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "\n",
        "# 하나의 BERT 레이어를 구현하는 클래스\n",
        "class BertLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.attention = BertAttention(config)\n",
        "        self.intermediate = BertIntermediate(config)\n",
        "        self.output = BertOutput(config)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_value=None, output_attentions=False):\n",
        "        # 어텐션과 출력 계산\n",
        "        self_attention_outputs = self.attention(\n",
        "            hidden_states,\n",
        "            attention_mask,\n",
        "            head_mask,\n",
        "            encoder_hidden_states,\n",
        "            encoder_attention_mask,\n",
        "            past_key_value,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        attention_output = self_attention_outputs[0]\n",
        "        layer_output = self.output(self.intermediate(attention_output), attention_output)\n",
        "        outputs = (layer_output,) + self_attention_outputs[1:]\n",
        "        return outputs\n",
        "\n",
        "# 여러 BERT 레이어를 포함하는 인코더 클래스\n",
        "class BertEncoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_values=None, use_cache=None, output_attentions=False, output_hidden_states=False, return_dict=True):\n",
        "        all_hidden_states = () if output_hidden_states else None\n",
        "        all_attentions = () if output_attentions else None\n",
        "        for i, layer_module in enumerate(self.layer):\n",
        "            layer_head_mask = head_mask[i] if head_mask is not None else None\n",
        "            past_key_value = past_key_values[i] if past_key_values is not None else None\n",
        "\n",
        "            if output_hidden_states:\n",
        "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "            layer_outputs = layer_module(\n",
        "                hidden_states,\n",
        "                attention_mask,\n",
        "                layer_head_mask,\n",
        "                encoder_hidden_states,\n",
        "                encoder_attention_mask,\n",
        "                past_key_value,\n",
        "                output_attentions,\n",
        "            )\n",
        "            hidden_states = layer_outputs[0]\n",
        "\n",
        "            if output_attentions:\n",
        "                all_attentions = all_attentions + (layer_outputs[1],)\n",
        "\n",
        "        return (hidden_states, all_hidden_states, all_attentions)\n",
        "\n",
        "# 첫 번째 토큰의 출력을 풀링하는 클래스\n",
        "class BertPooler(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        # 첫 번째 토큰의 텐서를 사용해 풀링 출력 생성\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        pooled_output = self.dense(first_token_tensor)\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "        return pooled_output\n",
        "\n",
        "# 전체 BERT 모델을 구현하는 클래스\n",
        "class  userBertModel(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.embeddings = BertEmbeddings(config)\n",
        "        self.encoder = BertEncoder(config)\n",
        "        self.pooler = BertPooler(config)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_values=None, use_cache=None, output_attentions=None, output_hidden_states=None, return_dict=None, sentiment_tokens=None):\n",
        "        # 입력 텐서의 크기 확인\n",
        "        if input_ids is not None and inputs_embeds is not None:\n",
        "            raise ValueError(\"input_ids 혹은 inputs_embeds 둘 중 하나의 형식으로만 입력해야 합니다.\")\n",
        "        elif input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "        elif inputs_embeds is not None:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "        else:\n",
        "            raise ValueError(\"input_ids 또는 inputs_embeds의 형식이어야 합니다.\")\n",
        "\n",
        "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones(input_shape, device=device)\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "\n",
        "        extended_attention_mask = attention_mask[:, None, None, :]\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype)\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "\n",
        "        head_mask = [None] * self.config.num_hidden_layers\n",
        "\n",
        "        # 임베딩 출력 계산\n",
        "        embedding_output = self.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            position_ids=position_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            sentiment_tokens= sentiment_tokens,\n",
        "        )\n",
        "        # 인코더 출력 계산\n",
        "        encoder_outputs = self.encoder(\n",
        "            embedding_output,\n",
        "            attention_mask=extended_attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states=encoder_hidden_states,\n",
        "            encoder_attention_mask=encoder_attention_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        sequence_output = encoder_outputs[0]\n",
        "        pooled_output = self.pooler(sequence_output)\n",
        "        return sequence_output, pooled_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAXhMfNkYbth"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aTojxNkPIxO",
        "outputId": "694e0520-9fa5-425d-98b1-9df73fe47d60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment ratio for this batch:  1.5\n",
            "Epoch: 0, Batch: 0, Loss: 0.7190375328063965, Accuracy: 0.5\n",
            "Sentiment ratio for this batch:  1.498984932899475\n",
            "Sentiment ratio for this batch:  1.4980604648590088\n",
            "Sentiment ratio for this batch:  1.4971325397491455\n",
            "Sentiment ratio for this batch:  1.4965862035751343\n",
            "Sentiment ratio for this batch:  1.4958927631378174\n",
            "Sentiment ratio for this batch:  1.4953163862228394\n",
            "Sentiment ratio for this batch:  1.4948636293411255\n",
            "Sentiment ratio for this batch:  1.4943945407867432\n",
            "Sentiment ratio for this batch:  1.4940078258514404\n",
            "Sentiment ratio for this batch:  1.493620753288269\n",
            "Epoch: 0, Batch: 10, Loss: 0.7171031832695007, Accuracy: 0.4602272727272727\n",
            "Sentiment ratio for this batch:  1.4932990074157715\n",
            "Sentiment ratio for this batch:  1.4929747581481934\n",
            "Sentiment ratio for this batch:  1.4926480054855347\n",
            "Sentiment ratio for this batch:  1.4921807050704956\n",
            "Sentiment ratio for this batch:  1.4918067455291748\n",
            "Sentiment ratio for this batch:  1.4914281368255615\n",
            "Sentiment ratio for this batch:  1.4909982681274414\n",
            "Sentiment ratio for this batch:  1.4906212091445923\n",
            "Sentiment ratio for this batch:  1.4905240535736084\n",
            "Sentiment ratio for this batch:  1.4904855489730835\n",
            "Epoch: 0, Batch: 20, Loss: 0.6712021231651306, Accuracy: 0.5\n",
            "Sentiment ratio for this batch:  1.490399718284607\n",
            "Sentiment ratio for this batch:  1.4903048276901245\n",
            "Sentiment ratio for this batch:  1.4904314279556274\n",
            "Sentiment ratio for this batch:  1.4904983043670654\n",
            "Sentiment ratio for this batch:  1.4907028675079346\n",
            "Sentiment ratio for this batch:  1.4909099340438843\n",
            "Sentiment ratio for this batch:  1.4910945892333984\n",
            "Sentiment ratio for this batch:  1.4912388324737549\n",
            "Sentiment ratio for this batch:  1.4913102388381958\n",
            "Sentiment ratio for this batch:  1.491344690322876\n",
            "Epoch: 0, Batch: 30, Loss: 0.6965286731719971, Accuracy: 0.4939516129032258\n",
            "Sentiment ratio for this batch:  1.4915884733200073\n",
            "Sentiment ratio for this batch:  1.4918458461761475\n",
            "Sentiment ratio for this batch:  1.4920945167541504\n",
            "Sentiment ratio for this batch:  1.4922646284103394\n",
            "Sentiment ratio for this batch:  1.4926300048828125\n",
            "Sentiment ratio for this batch:  1.4929488897323608\n",
            "Sentiment ratio for this batch:  1.4931541681289673\n",
            "Sentiment ratio for this batch:  1.4933853149414062\n",
            "Sentiment ratio for this batch:  1.4934439659118652\n",
            "Sentiment ratio for this batch:  1.493505835533142\n",
            "Epoch: 0, Batch: 40, Loss: 0.670951247215271, Accuracy: 0.4954268292682927\n",
            "Sentiment ratio for this batch:  1.493664026260376\n",
            "Sentiment ratio for this batch:  1.4939082860946655\n",
            "Sentiment ratio for this batch:  1.4941706657409668\n",
            "Sentiment ratio for this batch:  1.4944260120391846\n",
            "Sentiment ratio for this batch:  1.4946656227111816\n",
            "Sentiment ratio for this batch:  1.4949358701705933\n",
            "Sentiment ratio for this batch:  1.4950522184371948\n",
            "Sentiment ratio for this batch:  1.4951026439666748\n",
            "Sentiment ratio for this batch:  1.495131254196167\n",
            "Sentiment ratio for this batch:  1.4951227903366089\n",
            "Epoch: 0, Batch: 50, Loss: 0.6844886541366577, Accuracy: 0.5012254901960784\n",
            "Sentiment ratio for this batch:  1.4950897693634033\n",
            "Sentiment ratio for this batch:  1.494917631149292\n",
            "Sentiment ratio for this batch:  1.494702696800232\n",
            "Sentiment ratio for this batch:  1.4947556257247925\n",
            "Sentiment ratio for this batch:  1.4948830604553223\n",
            "Sentiment ratio for this batch:  1.4951257705688477\n",
            "Sentiment ratio for this batch:  1.495448112487793\n",
            "Sentiment ratio for this batch:  1.4957314729690552\n",
            "Sentiment ratio for this batch:  1.4957988262176514\n",
            "Sentiment ratio for this batch:  1.4959114789962769\n",
            "Epoch: 0, Batch: 60, Loss: 0.6927765607833862, Accuracy: 0.5163934426229508\n",
            "Sentiment ratio for this batch:  1.495978593826294\n",
            "Sentiment ratio for this batch:  1.496103286743164\n",
            "Sentiment ratio for this batch:  1.496358871459961\n",
            "Sentiment ratio for this batch:  1.4967085123062134\n",
            "Sentiment ratio for this batch:  1.4970083236694336\n",
            "Sentiment ratio for this batch:  1.4973697662353516\n",
            "Sentiment ratio for this batch:  1.497788667678833\n",
            "Sentiment ratio for this batch:  1.4982945919036865\n",
            "Sentiment ratio for this batch:  1.4986472129821777\n",
            "Sentiment ratio for this batch:  1.4991154670715332\n",
            "Epoch: 0, Batch: 70, Loss: 0.6814751625061035, Accuracy: 0.5334507042253521\n",
            "Sentiment ratio for this batch:  1.4995535612106323\n",
            "Sentiment ratio for this batch:  1.4999855756759644\n",
            "Sentiment ratio for this batch:  1.5006381273269653\n",
            "Sentiment ratio for this batch:  1.5012813806533813\n",
            "Sentiment ratio for this batch:  1.5015954971313477\n",
            "Sentiment ratio for this batch:  1.5016993284225464\n",
            "Sentiment ratio for this batch:  1.502063512802124\n",
            "Sentiment ratio for this batch:  1.502518653869629\n",
            "Sentiment ratio for this batch:  1.5031040906906128\n",
            "Sentiment ratio for this batch:  1.503704309463501\n",
            "Epoch: 0, Batch: 80, Loss: 0.715328574180603, Accuracy: 0.5339506172839507\n",
            "Sentiment ratio for this batch:  1.5039646625518799\n",
            "Sentiment ratio for this batch:  1.5041197538375854\n",
            "Sentiment ratio for this batch:  1.5042575597763062\n",
            "Sentiment ratio for this batch:  1.5045571327209473\n",
            "Sentiment ratio for this batch:  1.5049430131912231\n",
            "Sentiment ratio for this batch:  1.50527822971344\n",
            "Sentiment ratio for this batch:  1.5055423974990845\n",
            "Sentiment ratio for this batch:  1.506005048751831\n",
            "Sentiment ratio for this batch:  1.506327509880066\n",
            "Sentiment ratio for this batch:  1.5063434839248657\n",
            "Epoch: 0, Batch: 90, Loss: 0.5720112919807434, Accuracy: 0.5453296703296703\n",
            "Sentiment ratio for this batch:  1.506272554397583\n",
            "Sentiment ratio for this batch:  1.50602388381958\n",
            "Sentiment ratio for this batch:  1.5053718090057373\n",
            "Sentiment ratio for this batch:  1.5046725273132324\n",
            "Sentiment ratio for this batch:  1.5040749311447144\n",
            "Sentiment ratio for this batch:  1.5035966634750366\n",
            "Sentiment ratio for this batch:  1.5032663345336914\n",
            "Sentiment ratio for this batch:  1.5029239654541016\n",
            "Sentiment ratio for this batch:  1.5026875734329224\n",
            "Sentiment ratio for this batch:  1.5023226737976074\n",
            "Epoch: 0, Batch: 100, Loss: 0.5736441016197205, Accuracy: 0.5612623762376238\n",
            "Sentiment ratio for this batch:  1.501638412475586\n",
            "Sentiment ratio for this batch:  1.5008488893508911\n",
            "Sentiment ratio for this batch:  1.500259280204773\n",
            "Sentiment ratio for this batch:  1.4994338750839233\n",
            "Sentiment ratio for this batch:  1.4985508918762207\n",
            "Sentiment ratio for this batch:  1.4978200197219849\n",
            "Sentiment ratio for this batch:  1.4970982074737549\n",
            "Sentiment ratio for this batch:  1.4966485500335693\n",
            "Sentiment ratio for this batch:  1.4964505434036255\n",
            "Sentiment ratio for this batch:  1.496311902999878\n",
            "Epoch: 0, Batch: 110, Loss: 0.7004785537719727, Accuracy: 0.5675675675675675\n",
            "Sentiment ratio for this batch:  1.496172308921814\n",
            "Sentiment ratio for this batch:  1.496337652206421\n",
            "Sentiment ratio for this batch:  1.4962034225463867\n",
            "Sentiment ratio for this batch:  1.4961198568344116\n",
            "Sentiment ratio for this batch:  1.4961599111557007\n",
            "Sentiment ratio for this batch:  1.4962753057479858\n",
            "Sentiment ratio for this batch:  1.4965887069702148\n",
            "Sentiment ratio for this batch:  1.4968675374984741\n",
            "Sentiment ratio for this batch:  1.4971544742584229\n",
            "Sentiment ratio for this batch:  1.4973567724227905\n",
            "Epoch: 0, Batch: 120, Loss: 0.6312729716300964, Accuracy: 0.5795454545454546\n",
            "Sentiment ratio for this batch:  1.4976372718811035\n",
            "Sentiment ratio for this batch:  1.4978004693984985\n",
            "Sentiment ratio for this batch:  1.4979877471923828\n",
            "Sentiment ratio for this batch:  1.497909426689148\n",
            "Sentiment ratio for this batch:  1.4976319074630737\n",
            "Sentiment ratio for this batch:  1.4972901344299316\n",
            "Sentiment ratio for this batch:  1.4972106218338013\n",
            "Sentiment ratio for this batch:  1.4970160722732544\n",
            "Sentiment ratio for this batch:  1.496788740158081\n",
            "Sentiment ratio for this batch:  1.4965823888778687\n",
            "Epoch: 0, Batch: 130, Loss: 0.5713976621627808, Accuracy: 0.5920801526717557\n",
            "Sentiment ratio for this batch:  1.4964754581451416\n",
            "Sentiment ratio for this batch:  1.4963449239730835\n",
            "Sentiment ratio for this batch:  1.4961196184158325\n",
            "Sentiment ratio for this batch:  1.4959197044372559\n",
            "Sentiment ratio for this batch:  1.4960076808929443\n",
            "Sentiment ratio for this batch:  1.496163010597229\n",
            "Sentiment ratio for this batch:  1.4963295459747314\n",
            "Sentiment ratio for this batch:  1.4965052604675293\n",
            "Sentiment ratio for this batch:  1.4966450929641724\n",
            "Sentiment ratio for this batch:  1.4967286586761475\n",
            "Epoch: 0, Batch: 140, Loss: 0.6478896737098694, Accuracy: 0.6019503546099291\n",
            "Sentiment ratio for this batch:  1.4971369504928589\n",
            "Sentiment ratio for this batch:  1.4976927042007446\n",
            "Sentiment ratio for this batch:  1.498400092124939\n",
            "Sentiment ratio for this batch:  1.4992130994796753\n",
            "Sentiment ratio for this batch:  1.500221848487854\n",
            "Sentiment ratio for this batch:  1.5012261867523193\n",
            "Sentiment ratio for this batch:  1.5023059844970703\n",
            "Sentiment ratio for this batch:  1.503456473350525\n",
            "Sentiment ratio for this batch:  1.5044058561325073\n",
            "Sentiment ratio for this batch:  1.5053033828735352\n",
            "Epoch: 0, Batch: 150, Loss: 0.5752930641174316, Accuracy: 0.6084437086092715\n",
            "Sentiment ratio for this batch:  1.5057997703552246\n",
            "Sentiment ratio for this batch:  1.5061790943145752\n",
            "Sentiment ratio for this batch:  1.5065687894821167\n",
            "Sentiment ratio for this batch:  1.5068684816360474\n",
            "Sentiment ratio for this batch:  1.5071815252304077\n",
            "Sentiment ratio for this batch:  1.5073646306991577\n",
            "Sentiment ratio for this batch:  1.5074139833450317\n",
            "Sentiment ratio for this batch:  1.5074257850646973\n",
            "Sentiment ratio for this batch:  1.5073689222335815\n",
            "Sentiment ratio for this batch:  1.5071903467178345\n",
            "Epoch: 0, Batch: 160, Loss: 0.5532694458961487, Accuracy: 0.6164596273291926\n",
            "Sentiment ratio for this batch:  1.5069119930267334\n",
            "Sentiment ratio for this batch:  1.5068823099136353\n",
            "Sentiment ratio for this batch:  1.5069068670272827\n",
            "Sentiment ratio for this batch:  1.5068714618682861\n",
            "Sentiment ratio for this batch:  1.506754755973816\n",
            "Sentiment ratio for this batch:  1.5064256191253662\n",
            "Sentiment ratio for this batch:  1.5062175989151\n",
            "Sentiment ratio for this batch:  1.5058925151824951\n",
            "Sentiment ratio for this batch:  1.50624680519104\n",
            "Sentiment ratio for this batch:  1.5070281028747559\n",
            "Epoch: 0, Batch: 170, Loss: 0.48834964632987976, Accuracy: 0.6253654970760234\n",
            "Sentiment ratio for this batch:  1.5075219869613647\n",
            "Sentiment ratio for this batch:  1.5079060792922974\n",
            "Sentiment ratio for this batch:  1.5082732439041138\n",
            "Sentiment ratio for this batch:  1.508577585220337\n",
            "Sentiment ratio for this batch:  1.5089759826660156\n",
            "Sentiment ratio for this batch:  1.5094445943832397\n",
            "Sentiment ratio for this batch:  1.5099767446517944\n",
            "Sentiment ratio for this batch:  1.5107853412628174\n",
            "Sentiment ratio for this batch:  1.511208415031433\n",
            "Sentiment ratio for this batch:  1.511740803718567\n",
            "Epoch: 0, Batch: 180, Loss: 0.5502873659133911, Accuracy: 0.6322513812154696\n",
            "Sentiment ratio for this batch:  1.5123963356018066\n",
            "Sentiment ratio for this batch:  1.5129207372665405\n",
            "Sentiment ratio for this batch:  1.5134567022323608\n",
            "Sentiment ratio for this batch:  1.5140825510025024\n",
            "Sentiment ratio for this batch:  1.5145965814590454\n",
            "Sentiment ratio for this batch:  1.5154362916946411\n",
            "Sentiment ratio for this batch:  1.5164897441864014\n",
            "Sentiment ratio for this batch:  1.5174041986465454\n",
            "Sentiment ratio for this batch:  1.5185725688934326\n",
            "Sentiment ratio for this batch:  1.5197935104370117\n",
            "Epoch: 0, Batch: 190, Loss: 0.4444434642791748, Accuracy: 0.6384162303664922\n",
            "Sentiment ratio for this batch:  1.5209200382232666\n",
            "Sentiment ratio for this batch:  1.5219535827636719\n",
            "Sentiment ratio for this batch:  1.5226333141326904\n",
            "Sentiment ratio for this batch:  1.5231916904449463\n",
            "Sentiment ratio for this batch:  1.5238903760910034\n",
            "Sentiment ratio for this batch:  1.52432119846344\n",
            "Sentiment ratio for this batch:  1.5248314142227173\n",
            "Sentiment ratio for this batch:  1.5255156755447388\n",
            "Sentiment ratio for this batch:  1.526489019393921\n",
            "Sentiment ratio for this batch:  1.527441143989563\n",
            "Epoch: 0, Batch: 200, Loss: 0.5995562076568604, Accuracy: 0.6461442786069652\n",
            "Sentiment ratio for this batch:  1.5286048650741577\n",
            "Sentiment ratio for this batch:  1.5295238494873047\n",
            "Sentiment ratio for this batch:  1.5302324295043945\n",
            "Sentiment ratio for this batch:  1.530970573425293\n",
            "Sentiment ratio for this batch:  1.5315253734588623\n",
            "Sentiment ratio for this batch:  1.5322051048278809\n",
            "Sentiment ratio for this batch:  1.532918930053711\n",
            "Sentiment ratio for this batch:  1.5334126949310303\n",
            "Sentiment ratio for this batch:  1.5338083505630493\n",
            "Sentiment ratio for this batch:  1.5337556600570679\n",
            "Epoch: 0, Batch: 210, Loss: 0.5242246389389038, Accuracy: 0.6534360189573459\n",
            "Sentiment ratio for this batch:  1.5336312055587769\n",
            "Sentiment ratio for this batch:  1.5335160493850708\n",
            "Sentiment ratio for this batch:  1.5333555936813354\n",
            "Sentiment ratio for this batch:  1.5333837270736694\n",
            "Sentiment ratio for this batch:  1.5333902835845947\n",
            "Sentiment ratio for this batch:  1.533754587173462\n",
            "Sentiment ratio for this batch:  1.5343713760375977\n",
            "Sentiment ratio for this batch:  1.5353248119354248\n",
            "Sentiment ratio for this batch:  1.5361155271530151\n",
            "Sentiment ratio for this batch:  1.5367141962051392\n",
            "Epoch: 0, Batch: 220, Loss: 0.5493060946464539, Accuracy: 0.6606334841628959\n",
            "Sentiment ratio for this batch:  1.5372520685195923\n",
            "Sentiment ratio for this batch:  1.5377967357635498\n",
            "Sentiment ratio for this batch:  1.5383511781692505\n",
            "Sentiment ratio for this batch:  1.5390878915786743\n",
            "Sentiment ratio for this batch:  1.5399013757705688\n",
            "Sentiment ratio for this batch:  1.5403856039047241\n",
            "Sentiment ratio for this batch:  1.5407800674438477\n",
            "Sentiment ratio for this batch:  1.541179895401001\n",
            "Sentiment ratio for this batch:  1.5413575172424316\n",
            "Sentiment ratio for this batch:  1.5414396524429321\n",
            "Epoch: 0, Batch: 230, Loss: 0.4861202836036682, Accuracy: 0.6669372294372294\n",
            "Sentiment ratio for this batch:  1.5415046215057373\n",
            "Sentiment ratio for this batch:  1.5415858030319214\n",
            "Sentiment ratio for this batch:  1.5415626764297485\n",
            "Sentiment ratio for this batch:  1.5410043001174927\n",
            "Sentiment ratio for this batch:  1.540440559387207\n",
            "Sentiment ratio for this batch:  1.539818286895752\n",
            "Sentiment ratio for this batch:  1.5392322540283203\n",
            "Sentiment ratio for this batch:  1.5387678146362305\n",
            "Sentiment ratio for this batch:  1.5385631322860718\n",
            "Sentiment ratio for this batch:  1.538684368133545\n",
            "Epoch: 0, Batch: 240, Loss: 0.4578072130680084, Accuracy: 0.6732365145228216\n",
            "Sentiment ratio for this batch:  1.538732886314392\n",
            "Sentiment ratio for this batch:  1.5389139652252197\n",
            "Sentiment ratio for this batch:  1.5386145114898682\n",
            "Sentiment ratio for this batch:  1.538365364074707\n",
            "Sentiment ratio for this batch:  1.5377581119537354\n",
            "Sentiment ratio for this batch:  1.5372296571731567\n",
            "Sentiment ratio for this batch:  1.5366240739822388\n",
            "Sentiment ratio for this batch:  1.535933494567871\n",
            "Sentiment ratio for this batch:  1.5356038808822632\n",
            "Sentiment ratio for this batch:  1.5353374481201172\n",
            "Epoch: 0, Batch: 250, Loss: 0.4784795641899109, Accuracy: 0.6792828685258964\n",
            "Sentiment ratio for this batch:  1.535061001777649\n",
            "Sentiment ratio for this batch:  1.5347234010696411\n",
            "Sentiment ratio for this batch:  1.5346018075942993\n",
            "Sentiment ratio for this batch:  1.53452730178833\n",
            "Sentiment ratio for this batch:  1.5343066453933716\n",
            "Sentiment ratio for this batch:  1.5344409942626953\n",
            "Sentiment ratio for this batch:  1.5346040725708008\n",
            "Sentiment ratio for this batch:  1.5346200466156006\n",
            "Sentiment ratio for this batch:  1.534656047821045\n",
            "Sentiment ratio for this batch:  1.5345497131347656\n",
            "Epoch: 0, Batch: 260, Loss: 0.3838745355606079, Accuracy: 0.6846264367816092\n",
            "Sentiment ratio for this batch:  1.534749150276184\n",
            "Sentiment ratio for this batch:  1.5346332788467407\n",
            "Sentiment ratio for this batch:  1.5343443155288696\n",
            "Sentiment ratio for this batch:  1.5341014862060547\n",
            "Sentiment ratio for this batch:  1.5339393615722656\n",
            "Sentiment ratio for this batch:  1.5337746143341064\n",
            "Sentiment ratio for this batch:  1.5339103937149048\n",
            "Sentiment ratio for this batch:  1.5339280366897583\n",
            "Sentiment ratio for this batch:  1.5341306924819946\n",
            "Sentiment ratio for this batch:  1.5345128774642944\n",
            "Epoch: 0, Batch: 270, Loss: 0.618915319442749, Accuracy: 0.6891143911439115\n",
            "Sentiment ratio for this batch:  1.5347803831100464\n",
            "Sentiment ratio for this batch:  1.5351264476776123\n",
            "Sentiment ratio for this batch:  1.5356606245040894\n",
            "Sentiment ratio for this batch:  1.5361369848251343\n",
            "Sentiment ratio for this batch:  1.5365585088729858\n",
            "Sentiment ratio for this batch:  1.5370335578918457\n",
            "Sentiment ratio for this batch:  1.5372796058654785\n",
            "Sentiment ratio for this batch:  1.537545084953308\n",
            "Sentiment ratio for this batch:  1.5378156900405884\n",
            "Sentiment ratio for this batch:  1.5378800630569458\n",
            "Epoch: 0, Batch: 280, Loss: 0.6361028552055359, Accuracy: 0.6923932384341637\n",
            "Sentiment ratio for this batch:  1.53807532787323\n",
            "Sentiment ratio for this batch:  1.5383068323135376\n",
            "Sentiment ratio for this batch:  1.5385133028030396\n",
            "Sentiment ratio for this batch:  1.5384373664855957\n",
            "Sentiment ratio for this batch:  1.5385838747024536\n",
            "Sentiment ratio for this batch:  1.539055585861206\n",
            "Sentiment ratio for this batch:  1.5392564535140991\n",
            "Sentiment ratio for this batch:  1.5393688678741455\n",
            "Sentiment ratio for this batch:  1.5393760204315186\n",
            "Sentiment ratio for this batch:  1.539515495300293\n",
            "Epoch: 0, Batch: 290, Loss: 0.22228825092315674, Accuracy: 0.6982388316151202\n",
            "Sentiment ratio for this batch:  1.5398002862930298\n",
            "Sentiment ratio for this batch:  1.539807677268982\n",
            "Sentiment ratio for this batch:  1.5401215553283691\n",
            "Sentiment ratio for this batch:  1.5402984619140625\n",
            "Sentiment ratio for this batch:  1.5407172441482544\n",
            "Sentiment ratio for this batch:  1.5406606197357178\n",
            "Sentiment ratio for this batch:  1.5406467914581299\n",
            "Sentiment ratio for this batch:  1.5405573844909668\n",
            "Sentiment ratio for this batch:  1.5400530099868774\n",
            "Sentiment ratio for this batch:  1.5397623777389526\n",
            "Epoch: 0, Batch: 300, Loss: 0.5056687593460083, Accuracy: 0.7005813953488372\n",
            "Sentiment ratio for this batch:  1.5398310422897339\n",
            "Sentiment ratio for this batch:  1.5398882627487183\n",
            "Sentiment ratio for this batch:  1.5400362014770508\n",
            "Sentiment ratio for this batch:  1.5403984785079956\n",
            "Sentiment ratio for this batch:  1.5408705472946167\n",
            "Sentiment ratio for this batch:  1.54129958152771\n",
            "Sentiment ratio for this batch:  1.5416061878204346\n",
            "Sentiment ratio for this batch:  1.5415278673171997\n",
            "Sentiment ratio for this batch:  1.5415706634521484\n",
            "Sentiment ratio for this batch:  1.5417848825454712\n",
            "Epoch: 0, Batch: 310, Loss: 0.2768527567386627, Accuracy: 0.7063906752411575\n",
            "Sentiment ratio for this batch:  1.5421191453933716\n",
            "Sentiment ratio for this batch:  1.542311668395996\n",
            "Sentiment ratio for this batch:  1.5424766540527344\n",
            "Sentiment ratio for this batch:  1.5427913665771484\n",
            "Sentiment ratio for this batch:  1.542917251586914\n",
            "Sentiment ratio for this batch:  1.5430179834365845\n",
            "Sentiment ratio for this batch:  1.543136715888977\n",
            "Sentiment ratio for this batch:  1.5433599948883057\n",
            "Sentiment ratio for this batch:  1.543566107749939\n",
            "Sentiment ratio for this batch:  1.543810486793518\n",
            "Epoch: 0, Batch: 320, Loss: 0.6004658937454224, Accuracy: 0.7114485981308412\n",
            "Sentiment ratio for this batch:  1.5438600778579712\n",
            "Sentiment ratio for this batch:  1.5439527034759521\n",
            "Sentiment ratio for this batch:  1.5440222024917603\n",
            "Sentiment ratio for this batch:  1.5440714359283447\n",
            "Sentiment ratio for this batch:  1.544562578201294\n",
            "Sentiment ratio for this batch:  1.5450928211212158\n",
            "Sentiment ratio for this batch:  1.5455570220947266\n",
            "Sentiment ratio for this batch:  1.5460294485092163\n",
            "Sentiment ratio for this batch:  1.5465800762176514\n",
            "Sentiment ratio for this batch:  1.5466952323913574\n",
            "Epoch: 0, Batch: 330, Loss: 0.2695251405239105, Accuracy: 0.7162009063444109\n",
            "Sentiment ratio for this batch:  1.5468746423721313\n",
            "Sentiment ratio for this batch:  1.547156572341919\n",
            "Sentiment ratio for this batch:  1.5472062826156616\n",
            "Sentiment ratio for this batch:  1.5475237369537354\n",
            "Sentiment ratio for this batch:  1.547528624534607\n",
            "Sentiment ratio for this batch:  1.547549843788147\n",
            "Sentiment ratio for this batch:  1.54740309715271\n",
            "Sentiment ratio for this batch:  1.547323226928711\n",
            "Sentiment ratio for this batch:  1.5472606420516968\n",
            "Sentiment ratio for this batch:  1.5474791526794434\n",
            "Epoch: 0, Batch: 340, Loss: 0.39538756012916565, Accuracy: 0.718291788856305\n",
            "Sentiment ratio for this batch:  1.5478039979934692\n",
            "Sentiment ratio for this batch:  1.5481491088867188\n",
            "Sentiment ratio for this batch:  1.5485262870788574\n",
            "Sentiment ratio for this batch:  1.548763394355774\n",
            "Sentiment ratio for this batch:  1.5487712621688843\n",
            "Sentiment ratio for this batch:  1.549121379852295\n",
            "Sentiment ratio for this batch:  1.549460530281067\n",
            "Sentiment ratio for this batch:  1.5496865510940552\n",
            "Sentiment ratio for this batch:  1.5497667789459229\n",
            "Sentiment ratio for this batch:  1.5497300624847412\n",
            "Epoch: 0, Batch: 350, Loss: 0.31365230679512024, Accuracy: 0.7222222222222222\n",
            "Sentiment ratio for this batch:  1.5496140718460083\n",
            "Sentiment ratio for this batch:  1.5497947931289673\n",
            "Sentiment ratio for this batch:  1.549919843673706\n",
            "Sentiment ratio for this batch:  1.5499471426010132\n",
            "Sentiment ratio for this batch:  1.5499471426010132\n",
            "Sentiment ratio for this batch:  1.549790859222412\n",
            "Sentiment ratio for this batch:  1.549570918083191\n",
            "Sentiment ratio for this batch:  1.5495595932006836\n",
            "Sentiment ratio for this batch:  1.5496286153793335\n",
            "Sentiment ratio for this batch:  1.5497037172317505\n",
            "Epoch: 0, Batch: 360, Loss: 0.45853468775749207, Accuracy: 0.7248961218836565\n",
            "Sentiment ratio for this batch:  1.5498230457305908\n",
            "Sentiment ratio for this batch:  1.5493130683898926\n",
            "Sentiment ratio for this batch:  1.548827886581421\n",
            "Sentiment ratio for this batch:  1.548421025276184\n",
            "Sentiment ratio for this batch:  1.5483307838439941\n",
            "Sentiment ratio for this batch:  1.5488091707229614\n",
            "Sentiment ratio for this batch:  1.5493226051330566\n",
            "Sentiment ratio for this batch:  1.550516963005066\n",
            "Sentiment ratio for this batch:  1.5515356063842773\n",
            "Sentiment ratio for this batch:  1.5524733066558838\n",
            "Epoch: 0, Batch: 370, Loss: 0.3745051622390747, Accuracy: 0.7284366576819407\n",
            "Sentiment ratio for this batch:  1.5534642934799194\n",
            "Sentiment ratio for this batch:  1.5543406009674072\n",
            "Sentiment ratio for this batch:  1.5549002885818481\n",
            "Sentiment ratio for this batch:  1.5552195310592651\n",
            "Sentiment ratio for this batch:  1.5554863214492798\n",
            "Sentiment ratio for this batch:  1.5557907819747925\n",
            "Sentiment ratio for this batch:  1.5561519861221313\n",
            "Sentiment ratio for this batch:  1.5560139417648315\n",
            "Sentiment ratio for this batch:  1.5557582378387451\n",
            "Sentiment ratio for this batch:  1.5552705526351929\n",
            "Epoch: 0, Batch: 380, Loss: 0.1298859417438507, Accuracy: 0.7322834645669292\n",
            "Sentiment ratio for this batch:  1.5548460483551025\n",
            "Sentiment ratio for this batch:  1.5540921688079834\n",
            "Sentiment ratio for this batch:  1.5532597303390503\n",
            "Sentiment ratio for this batch:  1.5523737668991089\n",
            "Sentiment ratio for this batch:  1.551705002784729\n",
            "Sentiment ratio for this batch:  1.5511233806610107\n",
            "Sentiment ratio for this batch:  1.5503510236740112\n",
            "Sentiment ratio for this batch:  1.5495131015777588\n",
            "Sentiment ratio for this batch:  1.548923134803772\n",
            "Sentiment ratio for this batch:  1.5482985973358154\n",
            "Epoch: 0, Batch: 390, Loss: 0.16320067644119263, Accuracy: 0.7359335038363172\n",
            "Sentiment ratio for this batch:  1.5478562116622925\n",
            "Sentiment ratio for this batch:  1.547256588935852\n",
            "Sentiment ratio for this batch:  1.5464812517166138\n",
            "Sentiment ratio for this batch:  1.5460015535354614\n",
            "Sentiment ratio for this batch:  1.545547366142273\n",
            "Sentiment ratio for this batch:  1.5451037883758545\n",
            "Sentiment ratio for this batch:  1.5447901487350464\n",
            "Sentiment ratio for this batch:  1.5442907810211182\n",
            "Sentiment ratio for this batch:  1.5439655780792236\n",
            "Sentiment ratio for this batch:  1.5437747240066528\n",
            "Epoch: 0, Batch: 400, Loss: 0.21018308401107788, Accuracy: 0.7387780548628429\n",
            "Sentiment ratio for this batch:  1.5435233116149902\n",
            "Sentiment ratio for this batch:  1.5428881645202637\n",
            "Sentiment ratio for this batch:  1.542266607284546\n",
            "Sentiment ratio for this batch:  1.5418832302093506\n",
            "Sentiment ratio for this batch:  1.54120934009552\n",
            "Sentiment ratio for this batch:  1.5405902862548828\n",
            "Sentiment ratio for this batch:  1.5399471521377563\n",
            "Sentiment ratio for this batch:  1.5393341779708862\n",
            "Sentiment ratio for this batch:  1.5385817289352417\n",
            "Sentiment ratio for this batch:  1.538022756576538\n",
            "Epoch: 0, Batch: 410, Loss: 0.26810571551322937, Accuracy: 0.7416362530413625\n",
            "Sentiment ratio for this batch:  1.53748619556427\n",
            "Sentiment ratio for this batch:  1.536950945854187\n",
            "Sentiment ratio for this batch:  1.53671395778656\n",
            "Sentiment ratio for this batch:  1.536372184753418\n",
            "Sentiment ratio for this batch:  1.5359920263290405\n",
            "Sentiment ratio for this batch:  1.535669207572937\n",
            "Sentiment ratio for this batch:  1.5353835821151733\n",
            "Sentiment ratio for this batch:  1.535075306892395\n",
            "Sentiment ratio for this batch:  1.5348522663116455\n",
            "Sentiment ratio for this batch:  1.5347270965576172\n",
            "Epoch: 0, Batch: 420, Loss: 0.4384424686431885, Accuracy: 0.7451009501187649\n",
            "Sentiment ratio for this batch:  1.5346981287002563\n",
            "Sentiment ratio for this batch:  1.5350595712661743\n",
            "Sentiment ratio for this batch:  1.5354957580566406\n",
            "Sentiment ratio for this batch:  1.5359959602355957\n",
            "Sentiment ratio for this batch:  1.5365877151489258\n",
            "Sentiment ratio for this batch:  1.5371686220169067\n",
            "Sentiment ratio for this batch:  1.5377352237701416\n",
            "Sentiment ratio for this batch:  1.5386525392532349\n",
            "Sentiment ratio for this batch:  1.5394766330718994\n",
            "Sentiment ratio for this batch:  1.5403285026550293\n",
            "Epoch: 0, Batch: 430, Loss: 0.19454994797706604, Accuracy: 0.747969837587007\n",
            "Sentiment ratio for this batch:  1.541001319885254\n",
            "Sentiment ratio for this batch:  1.5415258407592773\n",
            "Sentiment ratio for this batch:  1.5419795513153076\n",
            "Sentiment ratio for this batch:  1.5421438217163086\n",
            "Sentiment ratio for this batch:  1.5422922372817993\n",
            "Sentiment ratio for this batch:  1.5424697399139404\n",
            "Sentiment ratio for this batch:  1.5425325632095337\n",
            "Sentiment ratio for this batch:  1.5427178144454956\n",
            "Sentiment ratio for this batch:  1.5428054332733154\n",
            "Sentiment ratio for this batch:  1.5431925058364868\n",
            "Epoch: 0, Batch: 440, Loss: 0.3064782917499542, Accuracy: 0.7509920634920635\n",
            "Sentiment ratio for this batch:  1.5437301397323608\n",
            "Sentiment ratio for this batch:  1.5441365242004395\n",
            "Sentiment ratio for this batch:  1.5444778203964233\n",
            "Sentiment ratio for this batch:  1.544874906539917\n",
            "Sentiment ratio for this batch:  1.5452601909637451\n",
            "Sentiment ratio for this batch:  1.5455265045166016\n",
            "Sentiment ratio for this batch:  1.5457652807235718\n",
            "Sentiment ratio for this batch:  1.54597806930542\n",
            "Sentiment ratio for this batch:  1.5460407733917236\n",
            "Sentiment ratio for this batch:  1.5460225343704224\n",
            "Epoch: 0, Batch: 450, Loss: 0.42893826961517334, Accuracy: 0.7541574279379157\n",
            "Sentiment ratio for this batch:  1.546015977859497\n",
            "Sentiment ratio for this batch:  1.5460236072540283\n",
            "Sentiment ratio for this batch:  1.5459372997283936\n",
            "Sentiment ratio for this batch:  1.5459930896759033\n",
            "Sentiment ratio for this batch:  1.5459563732147217\n",
            "Sentiment ratio for this batch:  1.5457444190979004\n",
            "Sentiment ratio for this batch:  1.5455182790756226\n",
            "Sentiment ratio for this batch:  1.5454167127609253\n",
            "Sentiment ratio for this batch:  1.5452935695648193\n",
            "Sentiment ratio for this batch:  1.5452663898468018\n",
            "Epoch: 0, Batch: 460, Loss: 0.30669283866882324, Accuracy: 0.7563720173535792\n",
            "Sentiment ratio for this batch:  1.5454964637756348\n",
            "Sentiment ratio for this batch:  1.545756220817566\n",
            "Sentiment ratio for this batch:  1.546067476272583\n",
            "Sentiment ratio for this batch:  1.5463510751724243\n",
            "Sentiment ratio for this batch:  1.5464898347854614\n",
            "Sentiment ratio for this batch:  1.5464388132095337\n",
            "Sentiment ratio for this batch:  1.546403169631958\n",
            "Sentiment ratio for this batch:  1.5463283061981201\n",
            "Sentiment ratio for this batch:  1.5463345050811768\n",
            "Sentiment ratio for this batch:  1.546323299407959\n",
            "Epoch: 0, Batch: 470, Loss: 0.1545204520225525, Accuracy: 0.7587579617834395\n",
            "Sentiment ratio for this batch:  1.5464452505111694\n",
            "Sentiment ratio for this batch:  1.5464328527450562\n",
            "Sentiment ratio for this batch:  1.5464400053024292\n",
            "Sentiment ratio for this batch:  1.5464627742767334\n",
            "Sentiment ratio for this batch:  1.5462862253189087\n",
            "Sentiment ratio for this batch:  1.5460058450698853\n",
            "Sentiment ratio for this batch:  1.5457587242126465\n",
            "Sentiment ratio for this batch:  1.545530915260315\n",
            "Sentiment ratio for this batch:  1.545236349105835\n",
            "Sentiment ratio for this batch:  1.5451267957687378\n",
            "Epoch: 0, Batch: 480, Loss: 0.32908138632774353, Accuracy: 0.7611746361746362\n",
            "Sentiment ratio for this batch:  1.54468834400177\n",
            "Sentiment ratio for this batch:  1.5442699193954468\n",
            "Sentiment ratio for this batch:  1.5438746213912964\n",
            "Sentiment ratio for this batch:  1.5433353185653687\n",
            "Sentiment ratio for this batch:  1.542799472808838\n",
            "Sentiment ratio for this batch:  1.5421510934829712\n",
            "Sentiment ratio for this batch:  1.5415711402893066\n",
            "Sentiment ratio for this batch:  1.5407487154006958\n",
            "Sentiment ratio for this batch:  1.540415644645691\n",
            "Sentiment ratio for this batch:  1.540319561958313\n",
            "Epoch: 0, Batch: 490, Loss: 0.2733495831489563, Accuracy: 0.7631109979633401\n",
            "Sentiment ratio for this batch:  1.5402488708496094\n",
            "Sentiment ratio for this batch:  1.5401302576065063\n",
            "Sentiment ratio for this batch:  1.5399739742279053\n",
            "Sentiment ratio for this batch:  1.5397357940673828\n",
            "Sentiment ratio for this batch:  1.539618730545044\n",
            "Sentiment ratio for this batch:  1.539537787437439\n",
            "Sentiment ratio for this batch:  1.5393145084381104\n",
            "Sentiment ratio for this batch:  1.5393143892288208\n",
            "Sentiment ratio for this batch:  1.5391839742660522\n",
            "Sentiment ratio for this batch:  1.5389938354492188\n",
            "Epoch: 0, Batch: 500, Loss: 0.26953911781311035, Accuracy: 0.7653443113772455\n",
            "Sentiment ratio for this batch:  1.5388495922088623\n",
            "Sentiment ratio for this batch:  1.5387529134750366\n",
            "Sentiment ratio for this batch:  1.5386099815368652\n",
            "Sentiment ratio for this batch:  1.5384702682495117\n",
            "Sentiment ratio for this batch:  1.5383111238479614\n",
            "Sentiment ratio for this batch:  1.5379425287246704\n",
            "Sentiment ratio for this batch:  1.5377590656280518\n",
            "Sentiment ratio for this batch:  1.5373958349227905\n",
            "Sentiment ratio for this batch:  1.5371016263961792\n",
            "Sentiment ratio for this batch:  1.5369300842285156\n",
            "Epoch: 0, Batch: 510, Loss: 0.37586352229118347, Accuracy: 0.7676125244618396\n",
            "Sentiment ratio for this batch:  1.5367858409881592\n",
            "Sentiment ratio for this batch:  1.5366055965423584\n",
            "Sentiment ratio for this batch:  1.5364750623703003\n",
            "Sentiment ratio for this batch:  1.5363630056381226\n",
            "Sentiment ratio for this batch:  1.5363551378250122\n",
            "Sentiment ratio for this batch:  1.5363515615463257\n",
            "Sentiment ratio for this batch:  1.5363569259643555\n",
            "Sentiment ratio for this batch:  1.5361391305923462\n",
            "Sentiment ratio for this batch:  1.536229133605957\n",
            "Sentiment ratio for this batch:  1.5364044904708862\n",
            "Epoch: 0, Batch: 520, Loss: 0.27806201577186584, Accuracy: 0.7695537428023033\n",
            "Sentiment ratio for this batch:  1.5365432500839233\n",
            "Sentiment ratio for this batch:  1.5368177890777588\n",
            "Sentiment ratio for this batch:  1.5372005701065063\n",
            "Sentiment ratio for this batch:  1.5373793840408325\n",
            "Sentiment ratio for this batch:  1.53752863407135\n",
            "Sentiment ratio for this batch:  1.5375440120697021\n",
            "Sentiment ratio for this batch:  1.537424087524414\n",
            "Sentiment ratio for this batch:  1.5373950004577637\n",
            "Sentiment ratio for this batch:  1.5375239849090576\n",
            "Sentiment ratio for this batch:  1.537716031074524\n",
            "Epoch: 0, Batch: 530, Loss: 0.47354981303215027, Accuracy: 0.7709510357815442\n",
            "Sentiment ratio for this batch:  1.5375924110412598\n",
            "Sentiment ratio for this batch:  1.5372490882873535\n",
            "Sentiment ratio for this batch:  1.536908745765686\n",
            "Sentiment ratio for this batch:  1.536461591720581\n",
            "Sentiment ratio for this batch:  1.5360509157180786\n",
            "Sentiment ratio for this batch:  1.5358344316482544\n",
            "Sentiment ratio for this batch:  1.5356584787368774\n",
            "Sentiment ratio for this batch:  1.5356733798980713\n",
            "Sentiment ratio for this batch:  1.5356402397155762\n",
            "Sentiment ratio for this batch:  1.5359023809432983\n",
            "Epoch: 0, Batch: 540, Loss: 0.4700993597507477, Accuracy: 0.7722966728280961\n",
            "Sentiment ratio for this batch:  1.5360946655273438\n",
            "Sentiment ratio for this batch:  1.5363175868988037\n",
            "Sentiment ratio for this batch:  1.53643798828125\n",
            "Sentiment ratio for this batch:  1.536609411239624\n",
            "Sentiment ratio for this batch:  1.5367872714996338\n",
            "Sentiment ratio for this batch:  1.5370157957077026\n",
            "Sentiment ratio for this batch:  1.5371774435043335\n",
            "Sentiment ratio for this batch:  1.537383794784546\n",
            "Sentiment ratio for this batch:  1.5372551679611206\n",
            "Sentiment ratio for this batch:  1.5371897220611572\n",
            "Epoch: 0, Batch: 550, Loss: 0.44824686646461487, Accuracy: 0.7737068965517241\n",
            "Sentiment ratio for this batch:  1.5372217893600464\n",
            "Sentiment ratio for this batch:  1.5371631383895874\n",
            "Sentiment ratio for this batch:  1.5369657278060913\n",
            "Sentiment ratio for this batch:  1.5367834568023682\n",
            "Sentiment ratio for this batch:  1.5365718603134155\n",
            "Sentiment ratio for this batch:  1.5359523296356201\n",
            "Sentiment ratio for this batch:  1.5354148149490356\n",
            "Sentiment ratio for this batch:  1.534919261932373\n",
            "Sentiment ratio for this batch:  1.534382700920105\n",
            "Sentiment ratio for this batch:  1.5339410305023193\n",
            "Epoch: 0, Batch: 560, Loss: 0.11902020126581192, Accuracy: 0.7759581105169341\n",
            "Sentiment ratio for this batch:  1.5336240530014038\n",
            "Sentiment ratio for this batch:  1.5332592725753784\n",
            "Sentiment ratio for this batch:  1.532984733581543\n",
            "Sentiment ratio for this batch:  1.5325525999069214\n",
            "Sentiment ratio for this batch:  1.5323386192321777\n",
            "Sentiment ratio for this batch:  1.5322089195251465\n",
            "Sentiment ratio for this batch:  1.5320816040039062\n",
            "Sentiment ratio for this batch:  1.5320614576339722\n",
            "Sentiment ratio for this batch:  1.532097339630127\n",
            "Sentiment ratio for this batch:  1.5322152376174927\n",
            "Epoch: 0, Batch: 570, Loss: 0.14075562357902527, Accuracy: 0.7774737302977233\n",
            "Sentiment ratio for this batch:  1.532488226890564\n",
            "Sentiment ratio for this batch:  1.5327337980270386\n",
            "Sentiment ratio for this batch:  1.532986044883728\n",
            "Sentiment ratio for this batch:  1.5333976745605469\n",
            "Sentiment ratio for this batch:  1.5338590145111084\n",
            "Sentiment ratio for this batch:  1.5343413352966309\n",
            "Sentiment ratio for this batch:  1.5345767736434937\n",
            "Sentiment ratio for this batch:  1.5348079204559326\n",
            "Sentiment ratio for this batch:  1.5349938869476318\n",
            "Sentiment ratio for this batch:  1.5349969863891602\n",
            "Epoch: 0, Batch: 580, Loss: 0.21375110745429993, Accuracy: 0.7787220309810671\n",
            "Sentiment ratio for this batch:  1.535008192062378\n",
            "Sentiment ratio for this batch:  1.5350013971328735\n",
            "Sentiment ratio for this batch:  1.5348674058914185\n",
            "Sentiment ratio for this batch:  1.5345925092697144\n",
            "Sentiment ratio for this batch:  1.5341503620147705\n",
            "Sentiment ratio for this batch:  1.5335758924484253\n",
            "Sentiment ratio for this batch:  1.53299880027771\n",
            "Sentiment ratio for this batch:  1.5323575735092163\n",
            "Sentiment ratio for this batch:  1.5316896438598633\n",
            "Sentiment ratio for this batch:  1.5306789875030518\n",
            "Epoch: 0, Batch: 590, Loss: 0.38541314005851746, Accuracy: 0.7798223350253807\n",
            "Sentiment ratio for this batch:  1.5296080112457275\n",
            "Sentiment ratio for this batch:  1.5285557508468628\n",
            "Sentiment ratio for this batch:  1.5276309251785278\n",
            "Sentiment ratio for this batch:  1.5267616510391235\n",
            "Sentiment ratio for this batch:  1.5260682106018066\n",
            "Sentiment ratio for this batch:  1.5254100561141968\n",
            "Sentiment ratio for this batch:  1.5249390602111816\n",
            "Sentiment ratio for this batch:  1.52447509765625\n",
            "Sentiment ratio for this batch:  1.5240623950958252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 1/3 [1:09:03<2:18:07, 4143.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 finished with average loss: 0.44747457234809795, Accuracy: 0.7809375\n",
            "Sentiment ratio for this batch:  1.5235602855682373\n",
            "Epoch: 1, Batch: 0, Loss: 0.12863481044769287, Accuracy: 1.0\n",
            "Sentiment ratio for this batch:  1.523108720779419\n",
            "Sentiment ratio for this batch:  1.5226198434829712\n",
            "Sentiment ratio for this batch:  1.522116780281067\n",
            "Sentiment ratio for this batch:  1.521687388420105\n",
            "Sentiment ratio for this batch:  1.5211899280548096\n",
            "Sentiment ratio for this batch:  1.5207035541534424\n",
            "Sentiment ratio for this batch:  1.5202912092208862\n",
            "Sentiment ratio for this batch:  1.5198334455490112\n",
            "Sentiment ratio for this batch:  1.5193995237350464\n",
            "Sentiment ratio for this batch:  1.5190927982330322\n",
            "Epoch: 1, Batch: 10, Loss: 0.1331559270620346, Accuracy: 0.9147727272727273\n",
            "Sentiment ratio for this batch:  1.5187791585922241\n",
            "Sentiment ratio for this batch:  1.518471360206604\n",
            "Sentiment ratio for this batch:  1.5181865692138672\n",
            "Sentiment ratio for this batch:  1.5176705121994019\n",
            "Sentiment ratio for this batch:  1.5172226428985596\n",
            "Sentiment ratio for this batch:  1.516863226890564\n",
            "Sentiment ratio for this batch:  1.5163768529891968\n",
            "Sentiment ratio for this batch:  1.515984296798706\n",
            "Sentiment ratio for this batch:  1.5156524181365967\n",
            "Sentiment ratio for this batch:  1.515390396118164\n",
            "Epoch: 1, Batch: 20, Loss: 0.16276247799396515, Accuracy: 0.9017857142857143\n",
            "Sentiment ratio for this batch:  1.5152654647827148\n",
            "Sentiment ratio for this batch:  1.515175700187683\n",
            "Sentiment ratio for this batch:  1.5151960849761963\n",
            "Sentiment ratio for this batch:  1.5150837898254395\n",
            "Sentiment ratio for this batch:  1.514976143836975\n",
            "Sentiment ratio for this batch:  1.5147072076797485\n",
            "Sentiment ratio for this batch:  1.514600396156311\n",
            "Sentiment ratio for this batch:  1.5146005153656006\n",
            "Sentiment ratio for this batch:  1.5146267414093018\n",
            "Sentiment ratio for this batch:  1.5147346258163452\n",
            "Epoch: 1, Batch: 30, Loss: 0.3119434714317322, Accuracy: 0.9012096774193549\n",
            "Sentiment ratio for this batch:  1.514751672744751\n",
            "Sentiment ratio for this batch:  1.514866828918457\n",
            "Sentiment ratio for this batch:  1.5148544311523438\n",
            "Sentiment ratio for this batch:  1.5148330926895142\n",
            "Sentiment ratio for this batch:  1.514919638633728\n",
            "Sentiment ratio for this batch:  1.5151435136795044\n",
            "Sentiment ratio for this batch:  1.515668511390686\n",
            "Sentiment ratio for this batch:  1.5160927772521973\n",
            "Sentiment ratio for this batch:  1.5164676904678345\n",
            "Sentiment ratio for this batch:  1.516850233078003\n",
            "Epoch: 1, Batch: 40, Loss: 0.1685260683298111, Accuracy: 0.8826219512195121\n",
            "Sentiment ratio for this batch:  1.5170856714248657\n",
            "Sentiment ratio for this batch:  1.5173801183700562\n",
            "Sentiment ratio for this batch:  1.517695426940918\n",
            "Sentiment ratio for this batch:  1.5177648067474365\n",
            "Sentiment ratio for this batch:  1.517525315284729\n",
            "Sentiment ratio for this batch:  1.5172449350357056\n",
            "Sentiment ratio for this batch:  1.5169745683670044\n",
            "Sentiment ratio for this batch:  1.5167722702026367\n",
            "Sentiment ratio for this batch:  1.5166374444961548\n",
            "Sentiment ratio for this batch:  1.5165646076202393\n",
            "Epoch: 1, Batch: 50, Loss: 0.2771693468093872, Accuracy: 0.8713235294117647\n",
            "Sentiment ratio for this batch:  1.5163750648498535\n",
            "Sentiment ratio for this batch:  1.516196370124817\n",
            "Sentiment ratio for this batch:  1.516119122505188\n",
            "Sentiment ratio for this batch:  1.5159207582473755\n",
            "Sentiment ratio for this batch:  1.5158462524414062\n",
            "Sentiment ratio for this batch:  1.5157279968261719\n",
            "Sentiment ratio for this batch:  1.5156570672988892\n",
            "Sentiment ratio for this batch:  1.51530122756958\n",
            "Sentiment ratio for this batch:  1.5149234533309937\n",
            "Sentiment ratio for this batch:  1.5146970748901367\n",
            "Epoch: 1, Batch: 60, Loss: 0.3788939416408539, Accuracy: 0.8698770491803278\n",
            "Sentiment ratio for this batch:  1.5144978761672974\n",
            "Sentiment ratio for this batch:  1.5142600536346436\n",
            "Sentiment ratio for this batch:  1.5140246152877808\n",
            "Sentiment ratio for this batch:  1.5137008428573608\n",
            "Sentiment ratio for this batch:  1.5134283304214478\n",
            "Sentiment ratio for this batch:  1.513250708580017\n",
            "Sentiment ratio for this batch:  1.5129649639129639\n",
            "Sentiment ratio for this batch:  1.5125871896743774\n",
            "Sentiment ratio for this batch:  1.512431025505066\n",
            "Sentiment ratio for this batch:  1.512249231338501\n",
            "Epoch: 1, Batch: 70, Loss: 0.616528332233429, Accuracy: 0.8697183098591549\n",
            "Sentiment ratio for this batch:  1.5120576620101929\n",
            "Sentiment ratio for this batch:  1.5119805335998535\n",
            "Sentiment ratio for this batch:  1.5118963718414307\n",
            "Sentiment ratio for this batch:  1.5117462873458862\n",
            "Sentiment ratio for this batch:  1.5116280317306519\n",
            "Sentiment ratio for this batch:  1.5117957592010498\n",
            "Sentiment ratio for this batch:  1.5120633840560913\n",
            "Sentiment ratio for this batch:  1.5123181343078613\n",
            "Sentiment ratio for this batch:  1.5124472379684448\n",
            "Sentiment ratio for this batch:  1.5125855207443237\n",
            "Epoch: 1, Batch: 80, Loss: 0.22855859994888306, Accuracy: 0.8765432098765432\n",
            "Sentiment ratio for this batch:  1.512733817100525\n",
            "Sentiment ratio for this batch:  1.5128166675567627\n",
            "Sentiment ratio for this batch:  1.5126582384109497\n",
            "Sentiment ratio for this batch:  1.5124716758728027\n",
            "Sentiment ratio for this batch:  1.5121772289276123\n",
            "Sentiment ratio for this batch:  1.5118482112884521\n",
            "Sentiment ratio for this batch:  1.511364459991455\n",
            "Sentiment ratio for this batch:  1.5109367370605469\n",
            "Sentiment ratio for this batch:  1.5105236768722534\n",
            "Sentiment ratio for this batch:  1.510209560394287\n",
            "Epoch: 1, Batch: 90, Loss: 0.16218027472496033, Accuracy: 0.8798076923076923\n",
            "Sentiment ratio for this batch:  1.5098682641983032\n",
            "Sentiment ratio for this batch:  1.5094292163848877\n",
            "Sentiment ratio for this batch:  1.5090092420578003\n",
            "Sentiment ratio for this batch:  1.5086323022842407\n",
            "Sentiment ratio for this batch:  1.5083117485046387\n",
            "Sentiment ratio for this batch:  1.507789134979248\n",
            "Sentiment ratio for this batch:  1.507341742515564\n",
            "Sentiment ratio for this batch:  1.5070099830627441\n",
            "Sentiment ratio for this batch:  1.5067726373672485\n",
            "Sentiment ratio for this batch:  1.5066566467285156\n",
            "Epoch: 1, Batch: 100, Loss: 0.09235866367816925, Accuracy: 0.8787128712871287\n",
            "Sentiment ratio for this batch:  1.5065468549728394\n",
            "Sentiment ratio for this batch:  1.5064855813980103\n",
            "Sentiment ratio for this batch:  1.5063430070877075\n",
            "Sentiment ratio for this batch:  1.5062391757965088\n",
            "Sentiment ratio for this batch:  1.5060975551605225\n",
            "Sentiment ratio for this batch:  1.5058939456939697\n",
            "Sentiment ratio for this batch:  1.5057859420776367\n",
            "Sentiment ratio for this batch:  1.5056045055389404\n",
            "Sentiment ratio for this batch:  1.5051920413970947\n",
            "Sentiment ratio for this batch:  1.504941701889038\n",
            "Epoch: 1, Batch: 110, Loss: 0.26739490032196045, Accuracy: 0.8783783783783784\n",
            "Sentiment ratio for this batch:  1.50470769405365\n",
            "Sentiment ratio for this batch:  1.5045021772384644\n",
            "Sentiment ratio for this batch:  1.5041476488113403\n",
            "Sentiment ratio for this batch:  1.5037113428115845\n",
            "Sentiment ratio for this batch:  1.503403902053833\n",
            "Sentiment ratio for this batch:  1.5031938552856445\n",
            "Sentiment ratio for this batch:  1.5032038688659668\n",
            "Sentiment ratio for this batch:  1.503188967704773\n",
            "Sentiment ratio for this batch:  1.5031659603118896\n",
            "Sentiment ratio for this batch:  1.5030180215835571\n",
            "Epoch: 1, Batch: 120, Loss: 0.3352285325527191, Accuracy: 0.8786157024793388\n",
            "Sentiment ratio for this batch:  1.5029405355453491\n",
            "Sentiment ratio for this batch:  1.5028705596923828\n",
            "Sentiment ratio for this batch:  1.5028749704360962\n",
            "Sentiment ratio for this batch:  1.5029581785202026\n",
            "Sentiment ratio for this batch:  1.503184199333191\n",
            "Sentiment ratio for this batch:  1.5033845901489258\n",
            "Sentiment ratio for this batch:  1.503497838973999\n",
            "Sentiment ratio for this batch:  1.5035197734832764\n",
            "Sentiment ratio for this batch:  1.5036641359329224\n",
            "Sentiment ratio for this batch:  1.5035206079483032\n",
            "Epoch: 1, Batch: 130, Loss: 0.07849473506212234, Accuracy: 0.8812022900763359\n",
            "Sentiment ratio for this batch:  1.5033868551254272\n",
            "Sentiment ratio for this batch:  1.503234624862671\n",
            "Sentiment ratio for this batch:  1.5030596256256104\n",
            "Sentiment ratio for this batch:  1.502918004989624\n",
            "Sentiment ratio for this batch:  1.5028072595596313\n",
            "Sentiment ratio for this batch:  1.502610445022583\n",
            "Sentiment ratio for this batch:  1.5024107694625854\n",
            "Sentiment ratio for this batch:  1.5021674633026123\n",
            "Sentiment ratio for this batch:  1.501932978630066\n",
            "Sentiment ratio for this batch:  1.5017406940460205\n",
            "Epoch: 1, Batch: 140, Loss: 0.1568271815776825, Accuracy: 0.8838652482269503\n",
            "Sentiment ratio for this batch:  1.5015183687210083\n",
            "Sentiment ratio for this batch:  1.5011324882507324\n",
            "Sentiment ratio for this batch:  1.500781774520874\n",
            "Sentiment ratio for this batch:  1.5004708766937256\n",
            "Sentiment ratio for this batch:  1.5001001358032227\n",
            "Sentiment ratio for this batch:  1.4997683763504028\n",
            "Sentiment ratio for this batch:  1.4995687007904053\n",
            "Sentiment ratio for this batch:  1.499388575553894\n",
            "Sentiment ratio for this batch:  1.4992426633834839\n",
            "Sentiment ratio for this batch:  1.4988889694213867\n",
            "Epoch: 1, Batch: 150, Loss: 0.2964341342449188, Accuracy: 0.8832781456953642\n",
            "Sentiment ratio for this batch:  1.4985755681991577\n",
            "Sentiment ratio for this batch:  1.4982298612594604\n",
            "Sentiment ratio for this batch:  1.4979052543640137\n",
            "Sentiment ratio for this batch:  1.4976049661636353\n",
            "Sentiment ratio for this batch:  1.4973363876342773\n",
            "Sentiment ratio for this batch:  1.4970439672470093\n",
            "Sentiment ratio for this batch:  1.4967116117477417\n",
            "Sentiment ratio for this batch:  1.4961979389190674\n",
            "Sentiment ratio for this batch:  1.4957447052001953\n",
            "Sentiment ratio for this batch:  1.4953356981277466\n",
            "Epoch: 1, Batch: 160, Loss: 0.5462663173675537, Accuracy: 0.8815993788819876\n",
            "Sentiment ratio for this batch:  1.4947071075439453\n",
            "Sentiment ratio for this batch:  1.4941785335540771\n",
            "Sentiment ratio for this batch:  1.4935976266860962\n",
            "Sentiment ratio for this batch:  1.4928672313690186\n",
            "Sentiment ratio for this batch:  1.4921903610229492\n",
            "Sentiment ratio for this batch:  1.4915835857391357\n",
            "Sentiment ratio for this batch:  1.4911353588104248\n",
            "Sentiment ratio for this batch:  1.490539789199829\n",
            "Sentiment ratio for this batch:  1.4899628162384033\n",
            "Sentiment ratio for this batch:  1.4893953800201416\n",
            "Epoch: 1, Batch: 170, Loss: 0.1626286506652832, Accuracy: 0.8797514619883041\n",
            "Sentiment ratio for this batch:  1.4888157844543457\n",
            "Sentiment ratio for this batch:  1.4883028268814087\n",
            "Sentiment ratio for this batch:  1.487984538078308\n",
            "Sentiment ratio for this batch:  1.487743854522705\n",
            "Sentiment ratio for this batch:  1.4876023530960083\n",
            "Sentiment ratio for this batch:  1.4875142574310303\n",
            "Sentiment ratio for this batch:  1.48745858669281\n",
            "Sentiment ratio for this batch:  1.4874722957611084\n",
            "Sentiment ratio for this batch:  1.4875414371490479\n",
            "Sentiment ratio for this batch:  1.4876070022583008\n",
            "Epoch: 1, Batch: 180, Loss: 0.18980933725833893, Accuracy: 0.8812154696132597\n",
            "Sentiment ratio for this batch:  1.4878422021865845\n",
            "Sentiment ratio for this batch:  1.4880897998809814\n",
            "Sentiment ratio for this batch:  1.4883716106414795\n",
            "Sentiment ratio for this batch:  1.488560438156128\n",
            "Sentiment ratio for this batch:  1.4888920783996582\n",
            "Sentiment ratio for this batch:  1.4893981218338013\n",
            "Sentiment ratio for this batch:  1.4897640943527222\n",
            "Sentiment ratio for this batch:  1.4900999069213867\n",
            "Sentiment ratio for this batch:  1.4904063940048218\n",
            "Sentiment ratio for this batch:  1.4905686378479004\n",
            "Epoch: 1, Batch: 190, Loss: 0.09140409529209137, Accuracy: 0.8828534031413613\n",
            "Sentiment ratio for this batch:  1.490676760673523\n",
            "Sentiment ratio for this batch:  1.4907974004745483\n",
            "Sentiment ratio for this batch:  1.4908156394958496\n",
            "Sentiment ratio for this batch:  1.4908033609390259\n",
            "Sentiment ratio for this batch:  1.4908524751663208\n",
            "Sentiment ratio for this batch:  1.490861415863037\n",
            "Sentiment ratio for this batch:  1.4908970594406128\n",
            "Sentiment ratio for this batch:  1.490962266921997\n",
            "Sentiment ratio for this batch:  1.4910454750061035\n",
            "Sentiment ratio for this batch:  1.4910746812820435\n",
            "Epoch: 1, Batch: 200, Loss: 0.463807612657547, Accuracy: 0.8852611940298507\n",
            "Sentiment ratio for this batch:  1.4911428689956665\n",
            "Sentiment ratio for this batch:  1.4913012981414795\n",
            "Sentiment ratio for this batch:  1.4915056228637695\n",
            "Sentiment ratio for this batch:  1.4918262958526611\n",
            "Sentiment ratio for this batch:  1.4919750690460205\n",
            "Sentiment ratio for this batch:  1.4921045303344727\n",
            "Sentiment ratio for this batch:  1.492297887802124\n",
            "Sentiment ratio for this batch:  1.4923934936523438\n",
            "Sentiment ratio for this batch:  1.4924336671829224\n",
            "Sentiment ratio for this batch:  1.4924969673156738\n",
            "Epoch: 1, Batch: 210, Loss: 0.07186590880155563, Accuracy: 0.8874407582938388\n",
            "Sentiment ratio for this batch:  1.4925867319107056\n",
            "Sentiment ratio for this batch:  1.4926562309265137\n",
            "Sentiment ratio for this batch:  1.492722749710083\n",
            "Sentiment ratio for this batch:  1.4927105903625488\n",
            "Sentiment ratio for this batch:  1.4927140474319458\n",
            "Sentiment ratio for this batch:  1.492721438407898\n",
            "Sentiment ratio for this batch:  1.492766261100769\n",
            "Sentiment ratio for this batch:  1.493116855621338\n",
            "Sentiment ratio for this batch:  1.4933501482009888\n",
            "Sentiment ratio for this batch:  1.4936209917068481\n",
            "Epoch: 1, Batch: 220, Loss: 0.30485111474990845, Accuracy: 0.8888574660633484\n",
            "Sentiment ratio for this batch:  1.493892788887024\n",
            "Sentiment ratio for this batch:  1.4941433668136597\n",
            "Sentiment ratio for this batch:  1.4945200681686401\n",
            "Sentiment ratio for this batch:  1.4950157403945923\n",
            "Sentiment ratio for this batch:  1.495483636856079\n",
            "Sentiment ratio for this batch:  1.4958977699279785\n",
            "Sentiment ratio for this batch:  1.4962713718414307\n",
            "Sentiment ratio for this batch:  1.496835708618164\n",
            "Sentiment ratio for this batch:  1.4973721504211426\n",
            "Sentiment ratio for this batch:  1.4978618621826172\n",
            "Epoch: 1, Batch: 230, Loss: 0.08660071343183517, Accuracy: 0.8893398268398268\n",
            "Sentiment ratio for this batch:  1.498357892036438\n",
            "Sentiment ratio for this batch:  1.4993395805358887\n",
            "Sentiment ratio for this batch:  1.5002275705337524\n",
            "Sentiment ratio for this batch:  1.5010632276535034\n",
            "Sentiment ratio for this batch:  1.5017588138580322\n",
            "Sentiment ratio for this batch:  1.5024707317352295\n",
            "Sentiment ratio for this batch:  1.5032068490982056\n",
            "Sentiment ratio for this batch:  1.5038338899612427\n",
            "Sentiment ratio for this batch:  1.5042470693588257\n",
            "Sentiment ratio for this batch:  1.504259467124939\n",
            "Epoch: 1, Batch: 240, Loss: 0.12658992409706116, Accuracy: 0.8892634854771784\n",
            "Sentiment ratio for this batch:  1.5043177604675293\n",
            "Sentiment ratio for this batch:  1.5042273998260498\n",
            "Sentiment ratio for this batch:  1.503876805305481\n",
            "Sentiment ratio for this batch:  1.5035107135772705\n",
            "Sentiment ratio for this batch:  1.5032055377960205\n",
            "Sentiment ratio for this batch:  1.503007173538208\n",
            "Sentiment ratio for this batch:  1.502800703048706\n",
            "Sentiment ratio for this batch:  1.502541184425354\n",
            "Sentiment ratio for this batch:  1.5026028156280518\n",
            "Sentiment ratio for this batch:  1.5025849342346191\n",
            "Epoch: 1, Batch: 250, Loss: 0.5070350766181946, Accuracy: 0.888695219123506\n",
            "Sentiment ratio for this batch:  1.5025970935821533\n",
            "Sentiment ratio for this batch:  1.5025206804275513\n",
            "Sentiment ratio for this batch:  1.5024222135543823\n",
            "Sentiment ratio for this batch:  1.5022391080856323\n",
            "Sentiment ratio for this batch:  1.5019911527633667\n",
            "Sentiment ratio for this batch:  1.5017163753509521\n",
            "Sentiment ratio for this batch:  1.5014700889587402\n",
            "Sentiment ratio for this batch:  1.501277208328247\n",
            "Sentiment ratio for this batch:  1.50098717212677\n",
            "Sentiment ratio for this batch:  1.5006462335586548\n",
            "Epoch: 1, Batch: 260, Loss: 0.36322641372680664, Accuracy: 0.889367816091954\n",
            "Sentiment ratio for this batch:  1.50027596950531\n",
            "Sentiment ratio for this batch:  1.4997835159301758\n",
            "Sentiment ratio for this batch:  1.4993540048599243\n",
            "Sentiment ratio for this batch:  1.4989800453186035\n",
            "Sentiment ratio for this batch:  1.4987311363220215\n",
            "Sentiment ratio for this batch:  1.4985201358795166\n",
            "Sentiment ratio for this batch:  1.498386263847351\n",
            "Sentiment ratio for this batch:  1.4982558488845825\n",
            "Sentiment ratio for this batch:  1.4981244802474976\n",
            "Sentiment ratio for this batch:  1.4980480670928955\n",
            "Epoch: 1, Batch: 270, Loss: 0.12806522846221924, Accuracy: 0.8911439114391144\n",
            "Sentiment ratio for this batch:  1.4979785680770874\n",
            "Sentiment ratio for this batch:  1.4979745149612427\n",
            "Sentiment ratio for this batch:  1.49813973903656\n",
            "Sentiment ratio for this batch:  1.498178482055664\n",
            "Sentiment ratio for this batch:  1.498223900794983\n",
            "Sentiment ratio for this batch:  1.4982788562774658\n",
            "Sentiment ratio for this batch:  1.4983925819396973\n",
            "Sentiment ratio for this batch:  1.4984607696533203\n",
            "Sentiment ratio for this batch:  1.4986342191696167\n",
            "Sentiment ratio for this batch:  1.4987956285476685\n",
            "Epoch: 1, Batch: 280, Loss: 0.46205443143844604, Accuracy: 0.8896797153024911\n",
            "Sentiment ratio for this batch:  1.499018669128418\n",
            "Sentiment ratio for this batch:  1.4992913007736206\n",
            "Sentiment ratio for this batch:  1.4996287822723389\n",
            "Sentiment ratio for this batch:  1.4998931884765625\n",
            "Sentiment ratio for this batch:  1.5001254081726074\n",
            "Sentiment ratio for this batch:  1.5004452466964722\n",
            "Sentiment ratio for this batch:  1.5005775690078735\n",
            "Sentiment ratio for this batch:  1.5006864070892334\n",
            "Sentiment ratio for this batch:  1.5007612705230713\n",
            "Sentiment ratio for this batch:  1.5008397102355957\n",
            "Epoch: 1, Batch: 290, Loss: 0.09113569557666779, Accuracy: 0.8904639175257731\n",
            "Sentiment ratio for this batch:  1.5009174346923828\n",
            "Sentiment ratio for this batch:  1.5010054111480713\n",
            "Sentiment ratio for this batch:  1.5010521411895752\n",
            "Sentiment ratio for this batch:  1.5008243322372437\n",
            "Sentiment ratio for this batch:  1.5005308389663696\n",
            "Sentiment ratio for this batch:  1.500200867652893\n",
            "Sentiment ratio for this batch:  1.4999325275421143\n",
            "Sentiment ratio for this batch:  1.4998427629470825\n",
            "Sentiment ratio for this batch:  1.4996238946914673\n",
            "Sentiment ratio for this batch:  1.4994170665740967\n",
            "Epoch: 1, Batch: 300, Loss: 0.1356428563594818, Accuracy: 0.8905730897009967\n",
            "Sentiment ratio for this batch:  1.499280333518982\n",
            "Sentiment ratio for this batch:  1.498979091644287\n",
            "Sentiment ratio for this batch:  1.498738408088684\n",
            "Sentiment ratio for this batch:  1.4986568689346313\n",
            "Sentiment ratio for this batch:  1.4985264539718628\n",
            "Sentiment ratio for this batch:  1.4983561038970947\n",
            "Sentiment ratio for this batch:  1.4982075691223145\n",
            "Sentiment ratio for this batch:  1.4977587461471558\n",
            "Sentiment ratio for this batch:  1.497454285621643\n",
            "Sentiment ratio for this batch:  1.4972975254058838\n",
            "Epoch: 1, Batch: 310, Loss: 0.08026793599128723, Accuracy: 0.8914790996784566\n",
            "Sentiment ratio for this batch:  1.4972673654556274\n",
            "Sentiment ratio for this batch:  1.497288465499878\n",
            "Sentiment ratio for this batch:  1.497270107269287\n",
            "Sentiment ratio for this batch:  1.4972816705703735\n",
            "Sentiment ratio for this batch:  1.4971864223480225\n",
            "Sentiment ratio for this batch:  1.4970591068267822\n",
            "Sentiment ratio for this batch:  1.4970554113388062\n",
            "Sentiment ratio for this batch:  1.4969980716705322\n",
            "Sentiment ratio for this batch:  1.4969137907028198\n",
            "Sentiment ratio for this batch:  1.4967679977416992\n",
            "Epoch: 1, Batch: 320, Loss: 0.6221396327018738, Accuracy: 0.8917445482866043\n",
            "Sentiment ratio for this batch:  1.4965966939926147\n",
            "Sentiment ratio for this batch:  1.4964438676834106\n",
            "Sentiment ratio for this batch:  1.4961432218551636\n",
            "Sentiment ratio for this batch:  1.495873212814331\n",
            "Sentiment ratio for this batch:  1.4956170320510864\n",
            "Sentiment ratio for this batch:  1.4954105615615845\n",
            "Sentiment ratio for this batch:  1.4951492547988892\n",
            "Sentiment ratio for this batch:  1.494916558265686\n",
            "Sentiment ratio for this batch:  1.4946203231811523\n",
            "Sentiment ratio for this batch:  1.4943432807922363\n",
            "Epoch: 1, Batch: 330, Loss: 0.2819269001483917, Accuracy: 0.8931268882175226\n",
            "Sentiment ratio for this batch:  1.494141697883606\n",
            "Sentiment ratio for this batch:  1.4939831495285034\n",
            "Sentiment ratio for this batch:  1.4937487840652466\n",
            "Sentiment ratio for this batch:  1.493669033050537\n",
            "Sentiment ratio for this batch:  1.4934015274047852\n",
            "Sentiment ratio for this batch:  1.49320387840271\n",
            "Sentiment ratio for this batch:  1.4930908679962158\n",
            "Sentiment ratio for this batch:  1.4929659366607666\n",
            "Sentiment ratio for this batch:  1.4927306175231934\n",
            "Sentiment ratio for this batch:  1.4924888610839844\n",
            "Epoch: 1, Batch: 340, Loss: 0.1930972784757614, Accuracy: 0.8938782991202346\n",
            "Sentiment ratio for this batch:  1.4921588897705078\n",
            "Sentiment ratio for this batch:  1.491936206817627\n",
            "Sentiment ratio for this batch:  1.491628885269165\n",
            "Sentiment ratio for this batch:  1.4912458658218384\n",
            "Sentiment ratio for this batch:  1.4905656576156616\n",
            "Sentiment ratio for this batch:  1.4900970458984375\n",
            "Sentiment ratio for this batch:  1.4898293018341064\n",
            "Sentiment ratio for this batch:  1.4896130561828613\n",
            "Sentiment ratio for this batch:  1.4895877838134766\n",
            "Sentiment ratio for this batch:  1.4896364212036133\n",
            "Epoch: 1, Batch: 350, Loss: 0.2089843451976776, Accuracy: 0.8944088319088319\n",
            "Sentiment ratio for this batch:  1.4897652864456177\n",
            "Sentiment ratio for this batch:  1.4898793697357178\n",
            "Sentiment ratio for this batch:  1.4899377822875977\n",
            "Sentiment ratio for this batch:  1.490065574645996\n",
            "Sentiment ratio for this batch:  1.4900994300842285\n",
            "Sentiment ratio for this batch:  1.4899559020996094\n",
            "Sentiment ratio for this batch:  1.489798665046692\n",
            "Sentiment ratio for this batch:  1.4896211624145508\n",
            "Sentiment ratio for this batch:  1.489417552947998\n",
            "Sentiment ratio for this batch:  1.489182949066162\n",
            "Epoch: 1, Batch: 360, Loss: 0.2743431627750397, Accuracy: 0.8938711911357341\n",
            "Sentiment ratio for this batch:  1.4889862537384033\n",
            "Sentiment ratio for this batch:  1.4885327816009521\n",
            "Sentiment ratio for this batch:  1.4880361557006836\n",
            "Sentiment ratio for this batch:  1.4875690937042236\n",
            "Sentiment ratio for this batch:  1.4871255159378052\n",
            "Sentiment ratio for this batch:  1.4867687225341797\n",
            "Sentiment ratio for this batch:  1.486451268196106\n",
            "Sentiment ratio for this batch:  1.4863026142120361\n",
            "Sentiment ratio for this batch:  1.4861705303192139\n",
            "Sentiment ratio for this batch:  1.486164927482605\n",
            "Epoch: 1, Batch: 370, Loss: 0.4105042815208435, Accuracy: 0.8940363881401617\n",
            "Sentiment ratio for this batch:  1.4863253831863403\n",
            "Sentiment ratio for this batch:  1.4864200353622437\n",
            "Sentiment ratio for this batch:  1.4864989519119263\n",
            "Sentiment ratio for this batch:  1.486635684967041\n",
            "Sentiment ratio for this batch:  1.486817479133606\n",
            "Sentiment ratio for this batch:  1.4871422052383423\n",
            "Sentiment ratio for this batch:  1.4874918460845947\n",
            "Sentiment ratio for this batch:  1.487722635269165\n",
            "Sentiment ratio for this batch:  1.4879810810089111\n",
            "Sentiment ratio for this batch:  1.487924575805664\n",
            "Epoch: 1, Batch: 380, Loss: 0.07299631834030151, Accuracy: 0.8941929133858267\n",
            "Sentiment ratio for this batch:  1.4878734350204468\n",
            "Sentiment ratio for this batch:  1.487462043762207\n",
            "Sentiment ratio for this batch:  1.487009048461914\n",
            "Sentiment ratio for this batch:  1.4864816665649414\n",
            "Sentiment ratio for this batch:  1.4859466552734375\n",
            "Sentiment ratio for this batch:  1.48544442653656\n",
            "Sentiment ratio for this batch:  1.4849148988723755\n",
            "Sentiment ratio for this batch:  1.4844032526016235\n",
            "Sentiment ratio for this batch:  1.4836695194244385\n",
            "Sentiment ratio for this batch:  1.4829660654067993\n",
            "Epoch: 1, Batch: 390, Loss: 0.07675519585609436, Accuracy: 0.8945012787723785\n",
            "Sentiment ratio for this batch:  1.4823700189590454\n",
            "Sentiment ratio for this batch:  1.4818214178085327\n",
            "Sentiment ratio for this batch:  1.4811210632324219\n",
            "Sentiment ratio for this batch:  1.4806344509124756\n",
            "Sentiment ratio for this batch:  1.4802201986312866\n",
            "Sentiment ratio for this batch:  1.479770541191101\n",
            "Sentiment ratio for this batch:  1.4794021844863892\n",
            "Sentiment ratio for this batch:  1.4789581298828125\n",
            "Sentiment ratio for this batch:  1.4785300493240356\n",
            "Sentiment ratio for this batch:  1.4781440496444702\n",
            "Epoch: 1, Batch: 400, Loss: 0.15713004767894745, Accuracy: 0.8949501246882793\n",
            "Sentiment ratio for this batch:  1.4778668880462646\n",
            "Sentiment ratio for this batch:  1.477605938911438\n",
            "Sentiment ratio for this batch:  1.4774104356765747\n",
            "Sentiment ratio for this batch:  1.4771876335144043\n",
            "Sentiment ratio for this batch:  1.4770110845565796\n",
            "Sentiment ratio for this batch:  1.4770033359527588\n",
            "Sentiment ratio for this batch:  1.4769450426101685\n",
            "Sentiment ratio for this batch:  1.4768892526626587\n",
            "Sentiment ratio for this batch:  1.476567029953003\n",
            "Sentiment ratio for this batch:  1.4762612581253052\n",
            "Epoch: 1, Batch: 410, Loss: 0.20087212324142456, Accuracy: 0.8949209245742092\n",
            "Sentiment ratio for this batch:  1.476142168045044\n",
            "Sentiment ratio for this batch:  1.4759448766708374\n",
            "Sentiment ratio for this batch:  1.475846290588379\n",
            "Sentiment ratio for this batch:  1.475740671157837\n",
            "Sentiment ratio for this batch:  1.4755908250808716\n",
            "Sentiment ratio for this batch:  1.4754526615142822\n",
            "Sentiment ratio for this batch:  1.4753611087799072\n",
            "Sentiment ratio for this batch:  1.4752657413482666\n",
            "Sentiment ratio for this batch:  1.4753234386444092\n",
            "Sentiment ratio for this batch:  1.475406527519226\n",
            "Epoch: 1, Batch: 420, Loss: 0.3899209797382355, Accuracy: 0.8954869358669834\n",
            "Sentiment ratio for this batch:  1.4754949808120728\n",
            "Sentiment ratio for this batch:  1.4758350849151611\n",
            "Sentiment ratio for this batch:  1.476212739944458\n",
            "Sentiment ratio for this batch:  1.4764565229415894\n",
            "Sentiment ratio for this batch:  1.4769082069396973\n",
            "Sentiment ratio for this batch:  1.4775364398956299\n",
            "Sentiment ratio for this batch:  1.4781943559646606\n",
            "Sentiment ratio for this batch:  1.4789235591888428\n",
            "Sentiment ratio for this batch:  1.4795962572097778\n",
            "Sentiment ratio for this batch:  1.4799938201904297\n",
            "Epoch: 1, Batch: 430, Loss: 0.12692543864250183, Accuracy: 0.8954466357308585\n",
            "Sentiment ratio for this batch:  1.4801794290542603\n",
            "Sentiment ratio for this batch:  1.480401635169983\n",
            "Sentiment ratio for this batch:  1.4806112051010132\n",
            "Sentiment ratio for this batch:  1.4808305501937866\n",
            "Sentiment ratio for this batch:  1.4808757305145264\n",
            "Sentiment ratio for this batch:  1.4808441400527954\n",
            "Sentiment ratio for this batch:  1.480685830116272\n",
            "Sentiment ratio for this batch:  1.4805907011032104\n",
            "Sentiment ratio for this batch:  1.480479121208191\n",
            "Sentiment ratio for this batch:  1.480385422706604\n",
            "Epoch: 1, Batch: 440, Loss: 0.20451736450195312, Accuracy: 0.8958333333333334\n",
            "Sentiment ratio for this batch:  1.4803504943847656\n",
            "Sentiment ratio for this batch:  1.4802805185317993\n",
            "Sentiment ratio for this batch:  1.480226993560791\n",
            "Sentiment ratio for this batch:  1.4801377058029175\n",
            "Sentiment ratio for this batch:  1.480063796043396\n",
            "Sentiment ratio for this batch:  1.4799774885177612\n",
            "Sentiment ratio for this batch:  1.4799883365631104\n",
            "Sentiment ratio for this batch:  1.480023980140686\n",
            "Sentiment ratio for this batch:  1.479905605316162\n",
            "Sentiment ratio for this batch:  1.4798879623413086\n",
            "Epoch: 1, Batch: 450, Loss: 0.28744304180145264, Accuracy: 0.8966186252771619\n",
            "Sentiment ratio for this batch:  1.4799771308898926\n",
            "Sentiment ratio for this batch:  1.4801634550094604\n",
            "Sentiment ratio for this batch:  1.4805264472961426\n",
            "Sentiment ratio for this batch:  1.4809305667877197\n",
            "Sentiment ratio for this batch:  1.4813108444213867\n",
            "Sentiment ratio for this batch:  1.4816488027572632\n",
            "Sentiment ratio for this batch:  1.4817613363265991\n",
            "Sentiment ratio for this batch:  1.4818668365478516\n",
            "Sentiment ratio for this batch:  1.4818192720413208\n",
            "Sentiment ratio for this batch:  1.4817042350769043\n",
            "Epoch: 1, Batch: 460, Loss: 0.15275751054286957, Accuracy: 0.8973698481561823\n",
            "Sentiment ratio for this batch:  1.4816378355026245\n",
            "Sentiment ratio for this batch:  1.481544017791748\n",
            "Sentiment ratio for this batch:  1.4816259145736694\n",
            "Sentiment ratio for this batch:  1.4817719459533691\n",
            "Sentiment ratio for this batch:  1.481793999671936\n",
            "Sentiment ratio for this batch:  1.481866717338562\n",
            "Sentiment ratio for this batch:  1.4819753170013428\n",
            "Sentiment ratio for this batch:  1.4820595979690552\n",
            "Sentiment ratio for this batch:  1.4821685552597046\n",
            "Sentiment ratio for this batch:  1.482197642326355\n",
            "Epoch: 1, Batch: 470, Loss: 0.07531369477510452, Accuracy: 0.8983545647558386\n",
            "Sentiment ratio for this batch:  1.4822629690170288\n",
            "Sentiment ratio for this batch:  1.482295036315918\n",
            "Sentiment ratio for this batch:  1.482332468032837\n",
            "Sentiment ratio for this batch:  1.482495665550232\n",
            "Sentiment ratio for this batch:  1.4825630187988281\n",
            "Sentiment ratio for this batch:  1.4821977615356445\n",
            "Sentiment ratio for this batch:  1.4818750619888306\n",
            "Sentiment ratio for this batch:  1.4815152883529663\n",
            "Sentiment ratio for this batch:  1.4811601638793945\n",
            "Sentiment ratio for this batch:  1.4805543422698975\n",
            "Epoch: 1, Batch: 480, Loss: 0.40456339716911316, Accuracy: 0.8985187110187111\n",
            "Sentiment ratio for this batch:  1.4799044132232666\n",
            "Sentiment ratio for this batch:  1.4792600870132446\n",
            "Sentiment ratio for this batch:  1.4787448644638062\n",
            "Sentiment ratio for this batch:  1.4784204959869385\n",
            "Sentiment ratio for this batch:  1.4780635833740234\n",
            "Sentiment ratio for this batch:  1.4775053262710571\n",
            "Sentiment ratio for this batch:  1.4769582748413086\n",
            "Sentiment ratio for this batch:  1.4763896465301514\n",
            "Sentiment ratio for this batch:  1.4758914709091187\n",
            "Sentiment ratio for this batch:  1.4755350351333618\n",
            "Epoch: 1, Batch: 490, Loss: 0.11012431979179382, Accuracy: 0.8990580448065173\n",
            "Sentiment ratio for this batch:  1.4752756357192993\n",
            "Sentiment ratio for this batch:  1.4750360250473022\n",
            "Sentiment ratio for this batch:  1.4747742414474487\n",
            "Sentiment ratio for this batch:  1.47446870803833\n",
            "Sentiment ratio for this batch:  1.4742543697357178\n",
            "Sentiment ratio for this batch:  1.4741986989974976\n",
            "Sentiment ratio for this batch:  1.474261999130249\n",
            "Sentiment ratio for this batch:  1.4743969440460205\n",
            "Sentiment ratio for this batch:  1.4745436906814575\n",
            "Sentiment ratio for this batch:  1.4746612310409546\n",
            "Epoch: 1, Batch: 500, Loss: 0.14278434216976166, Accuracy: 0.8998253493013972\n",
            "Sentiment ratio for this batch:  1.4747737646102905\n",
            "Sentiment ratio for this batch:  1.4750043153762817\n",
            "Sentiment ratio for this batch:  1.475024700164795\n",
            "Sentiment ratio for this batch:  1.4750038385391235\n",
            "Sentiment ratio for this batch:  1.4749964475631714\n",
            "Sentiment ratio for this batch:  1.47478449344635\n",
            "Sentiment ratio for this batch:  1.4746061563491821\n",
            "Sentiment ratio for this batch:  1.474234700202942\n",
            "Sentiment ratio for this batch:  1.4738436937332153\n",
            "Sentiment ratio for this batch:  1.4735325574874878\n",
            "Epoch: 1, Batch: 510, Loss: 0.43461287021636963, Accuracy: 0.9003180039138943\n",
            "Sentiment ratio for this batch:  1.4730418920516968\n",
            "Sentiment ratio for this batch:  1.472647786140442\n",
            "Sentiment ratio for this batch:  1.4723138809204102\n",
            "Sentiment ratio for this batch:  1.4719123840332031\n",
            "Sentiment ratio for this batch:  1.4714993238449097\n",
            "Sentiment ratio for this batch:  1.4711315631866455\n",
            "Sentiment ratio for this batch:  1.470693826675415\n",
            "Sentiment ratio for this batch:  1.4701515436172485\n",
            "Sentiment ratio for this batch:  1.469763994216919\n",
            "Sentiment ratio for this batch:  1.469489336013794\n",
            "Epoch: 1, Batch: 520, Loss: 0.06958868354558945, Accuracy: 0.9003119001919386\n",
            "Sentiment ratio for this batch:  1.4692882299423218\n",
            "Sentiment ratio for this batch:  1.4691975116729736\n",
            "Sentiment ratio for this batch:  1.4691914319992065\n",
            "Sentiment ratio for this batch:  1.4691637754440308\n",
            "Sentiment ratio for this batch:  1.4691346883773804\n",
            "Sentiment ratio for this batch:  1.469106912612915\n",
            "Sentiment ratio for this batch:  1.4691400527954102\n",
            "Sentiment ratio for this batch:  1.4692784547805786\n",
            "Sentiment ratio for this batch:  1.4694163799285889\n",
            "Sentiment ratio for this batch:  1.4694582223892212\n",
            "Epoch: 1, Batch: 530, Loss: 0.43838557600975037, Accuracy: 0.8997175141242938\n",
            "Sentiment ratio for this batch:  1.4693048000335693\n",
            "Sentiment ratio for this batch:  1.468992829322815\n",
            "Sentiment ratio for this batch:  1.4686784744262695\n",
            "Sentiment ratio for this batch:  1.4685120582580566\n",
            "Sentiment ratio for this batch:  1.4683276414871216\n",
            "Sentiment ratio for this batch:  1.468166708946228\n",
            "Sentiment ratio for this batch:  1.4682111740112305\n",
            "Sentiment ratio for this batch:  1.4682966470718384\n",
            "Sentiment ratio for this batch:  1.4684009552001953\n",
            "Sentiment ratio for this batch:  1.4685661792755127\n",
            "Epoch: 1, Batch: 540, Loss: 0.34879329800605774, Accuracy: 0.8997227356746765\n",
            "Sentiment ratio for this batch:  1.4687408208847046\n",
            "Sentiment ratio for this batch:  1.4688985347747803\n",
            "Sentiment ratio for this batch:  1.4689152240753174\n",
            "Sentiment ratio for this batch:  1.4690089225769043\n",
            "Sentiment ratio for this batch:  1.4690067768096924\n",
            "Sentiment ratio for this batch:  1.4690172672271729\n",
            "Sentiment ratio for this batch:  1.4688576459884644\n",
            "Sentiment ratio for this batch:  1.468693494796753\n",
            "Sentiment ratio for this batch:  1.4682471752166748\n",
            "Sentiment ratio for this batch:  1.4678999185562134\n",
            "Epoch: 1, Batch: 550, Loss: 0.27927905321121216, Accuracy: 0.9002949183303085\n",
            "Sentiment ratio for this batch:  1.4675657749176025\n",
            "Sentiment ratio for this batch:  1.4672505855560303\n",
            "Sentiment ratio for this batch:  1.4669620990753174\n",
            "Sentiment ratio for this batch:  1.4667061567306519\n",
            "Sentiment ratio for this batch:  1.4664831161499023\n",
            "Sentiment ratio for this batch:  1.4661115407943726\n",
            "Sentiment ratio for this batch:  1.4657480716705322\n",
            "Sentiment ratio for this batch:  1.4653916358947754\n",
            "Sentiment ratio for this batch:  1.4650871753692627\n",
            "Sentiment ratio for this batch:  1.4647728204727173\n",
            "Epoch: 1, Batch: 560, Loss: 0.02738676778972149, Accuracy: 0.901403743315508\n",
            "Sentiment ratio for this batch:  1.46448814868927\n",
            "Sentiment ratio for this batch:  1.4641852378845215\n",
            "Sentiment ratio for this batch:  1.4640147686004639\n",
            "Sentiment ratio for this batch:  1.463701844215393\n",
            "Sentiment ratio for this batch:  1.463469386100769\n",
            "Sentiment ratio for this batch:  1.4634790420532227\n",
            "Sentiment ratio for this batch:  1.463484287261963\n",
            "Sentiment ratio for this batch:  1.4632574319839478\n",
            "Sentiment ratio for this batch:  1.4632368087768555\n",
            "Sentiment ratio for this batch:  1.463268756866455\n",
            "Epoch: 1, Batch: 570, Loss: 0.0790872797369957, Accuracy: 0.9008318739054291\n",
            "Sentiment ratio for this batch:  1.4634017944335938\n",
            "Sentiment ratio for this batch:  1.4634606838226318\n",
            "Sentiment ratio for this batch:  1.463545322418213\n",
            "Sentiment ratio for this batch:  1.4637887477874756\n",
            "Sentiment ratio for this batch:  1.463956594467163\n",
            "Sentiment ratio for this batch:  1.464118242263794\n",
            "Sentiment ratio for this batch:  1.4641025066375732\n",
            "Sentiment ratio for this batch:  1.4641399383544922\n",
            "Sentiment ratio for this batch:  1.4641740322113037\n",
            "Sentiment ratio for this batch:  1.464223027229309\n",
            "Epoch: 1, Batch: 580, Loss: 0.14574497938156128, Accuracy: 0.9011402753872634\n",
            "Sentiment ratio for this batch:  1.4642443656921387\n",
            "Sentiment ratio for this batch:  1.4643309116363525\n",
            "Sentiment ratio for this batch:  1.4642910957336426\n",
            "Sentiment ratio for this batch:  1.464296817779541\n",
            "Sentiment ratio for this batch:  1.4643877744674683\n",
            "Sentiment ratio for this batch:  1.464321494102478\n",
            "Sentiment ratio for this batch:  1.4642881155014038\n",
            "Sentiment ratio for this batch:  1.4640967845916748\n",
            "Sentiment ratio for this batch:  1.4639341831207275\n",
            "Sentiment ratio for this batch:  1.463497281074524\n",
            "Epoch: 1, Batch: 590, Loss: 0.199019655585289, Accuracy: 0.9016497461928934\n",
            "Sentiment ratio for this batch:  1.463016390800476\n",
            "Sentiment ratio for this batch:  1.4624873399734497\n",
            "Sentiment ratio for this batch:  1.4620261192321777\n",
            "Sentiment ratio for this batch:  1.4616261720657349\n",
            "Sentiment ratio for this batch:  1.4612497091293335\n",
            "Sentiment ratio for this batch:  1.4611618518829346\n",
            "Sentiment ratio for this batch:  1.4613933563232422\n",
            "Sentiment ratio for this batch:  1.4615788459777832\n",
            "Sentiment ratio for this batch:  1.4618051052093506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [2:19:48<1:10:03, 4203.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 finished with average loss: 0.25003535935655236, Accuracy: 0.9015625\n",
            "Sentiment ratio for this batch:  1.4618444442749023\n",
            "Epoch: 2, Batch: 0, Loss: 0.1384744644165039, Accuracy: 0.875\n",
            "Sentiment ratio for this batch:  1.4618985652923584\n",
            "Sentiment ratio for this batch:  1.461990475654602\n",
            "Sentiment ratio for this batch:  1.462033748626709\n",
            "Sentiment ratio for this batch:  1.4620318412780762\n",
            "Sentiment ratio for this batch:  1.4619163274765015\n",
            "Sentiment ratio for this batch:  1.4617818593978882\n",
            "Sentiment ratio for this batch:  1.4616450071334839\n",
            "Sentiment ratio for this batch:  1.4614100456237793\n",
            "Sentiment ratio for this batch:  1.461128830909729\n",
            "Sentiment ratio for this batch:  1.4607359170913696\n",
            "Epoch: 2, Batch: 10, Loss: 0.09979420900344849, Accuracy: 0.9261363636363636\n",
            "Sentiment ratio for this batch:  1.460355520248413\n",
            "Sentiment ratio for this batch:  1.45991849899292\n",
            "Sentiment ratio for this batch:  1.459479570388794\n",
            "Sentiment ratio for this batch:  1.4590667486190796\n",
            "Sentiment ratio for this batch:  1.45872163772583\n",
            "Sentiment ratio for this batch:  1.4584851264953613\n",
            "Sentiment ratio for this batch:  1.4582520723342896\n",
            "Sentiment ratio for this batch:  1.4579615592956543\n",
            "Sentiment ratio for this batch:  1.4576058387756348\n",
            "Sentiment ratio for this batch:  1.4573265314102173\n",
            "Epoch: 2, Batch: 20, Loss: 0.07954851537942886, Accuracy: 0.9255952380952381\n",
            "Sentiment ratio for this batch:  1.45712149143219\n",
            "Sentiment ratio for this batch:  1.456969976425171\n",
            "Sentiment ratio for this batch:  1.4568411111831665\n",
            "Sentiment ratio for this batch:  1.456709384918213\n",
            "Sentiment ratio for this batch:  1.4565633535385132\n",
            "Sentiment ratio for this batch:  1.456495761871338\n",
            "Sentiment ratio for this batch:  1.4564658403396606\n",
            "Sentiment ratio for this batch:  1.4565646648406982\n",
            "Sentiment ratio for this batch:  1.4564828872680664\n",
            "Sentiment ratio for this batch:  1.45648992061615\n",
            "Epoch: 2, Batch: 30, Loss: 0.3487797975540161, Accuracy: 0.9254032258064516\n",
            "Sentiment ratio for this batch:  1.4563913345336914\n",
            "Sentiment ratio for this batch:  1.4563374519348145\n",
            "Sentiment ratio for this batch:  1.4561207294464111\n",
            "Sentiment ratio for this batch:  1.4560106992721558\n",
            "Sentiment ratio for this batch:  1.4559968709945679\n",
            "Sentiment ratio for this batch:  1.4560893774032593\n",
            "Sentiment ratio for this batch:  1.4561412334442139\n",
            "Sentiment ratio for this batch:  1.4561926126480103\n",
            "Sentiment ratio for this batch:  1.4561876058578491\n",
            "Sentiment ratio for this batch:  1.4561337232589722\n",
            "Epoch: 2, Batch: 40, Loss: 0.04366911202669144, Accuracy: 0.9237804878048781\n",
            "Sentiment ratio for this batch:  1.4560807943344116\n",
            "Sentiment ratio for this batch:  1.4560418128967285\n",
            "Sentiment ratio for this batch:  1.4560449123382568\n",
            "Sentiment ratio for this batch:  1.4556347131729126\n",
            "Sentiment ratio for this batch:  1.4552596807479858\n",
            "Sentiment ratio for this batch:  1.4547537565231323\n",
            "Sentiment ratio for this batch:  1.4543401002883911\n",
            "Sentiment ratio for this batch:  1.4539762735366821\n",
            "Sentiment ratio for this batch:  1.4538003206253052\n",
            "Sentiment ratio for this batch:  1.4536715745925903\n",
            "Epoch: 2, Batch: 50, Loss: 0.21524907648563385, Accuracy: 0.9191176470588235\n",
            "Sentiment ratio for this batch:  1.453512191772461\n",
            "Sentiment ratio for this batch:  1.4533960819244385\n",
            "Sentiment ratio for this batch:  1.4532792568206787\n",
            "Sentiment ratio for this batch:  1.4532636404037476\n",
            "Sentiment ratio for this batch:  1.4533125162124634\n",
            "Sentiment ratio for this batch:  1.453156590461731\n",
            "Sentiment ratio for this batch:  1.4533756971359253\n",
            "Sentiment ratio for this batch:  1.4533724784851074\n",
            "Sentiment ratio for this batch:  1.4533967971801758\n",
            "Sentiment ratio for this batch:  1.4535585641860962\n",
            "Epoch: 2, Batch: 60, Loss: 0.1827479600906372, Accuracy: 0.9139344262295082\n",
            "Sentiment ratio for this batch:  1.453608751296997\n",
            "Sentiment ratio for this batch:  1.4535707235336304\n",
            "Sentiment ratio for this batch:  1.4532519578933716\n",
            "Sentiment ratio for this batch:  1.4528276920318604\n",
            "Sentiment ratio for this batch:  1.4524493217468262\n",
            "Sentiment ratio for this batch:  1.4521822929382324\n",
            "Sentiment ratio for this batch:  1.4518935680389404\n",
            "Sentiment ratio for this batch:  1.4514355659484863\n",
            "Sentiment ratio for this batch:  1.451061487197876\n",
            "Sentiment ratio for this batch:  1.4507417678833008\n",
            "Epoch: 2, Batch: 70, Loss: 0.46912363171577454, Accuracy: 0.9110915492957746\n",
            "Sentiment ratio for this batch:  1.4504667520523071\n",
            "Sentiment ratio for this batch:  1.4502301216125488\n",
            "Sentiment ratio for this batch:  1.4502253532409668\n",
            "Sentiment ratio for this batch:  1.4500749111175537\n",
            "Sentiment ratio for this batch:  1.4501979351043701\n",
            "Sentiment ratio for this batch:  1.45040762424469\n",
            "Sentiment ratio for this batch:  1.450799822807312\n",
            "Sentiment ratio for this batch:  1.4511659145355225\n",
            "Sentiment ratio for this batch:  1.4514503479003906\n",
            "Sentiment ratio for this batch:  1.4515444040298462\n",
            "Epoch: 2, Batch: 80, Loss: 0.14824776351451874, Accuracy: 0.9128086419753086\n",
            "Sentiment ratio for this batch:  1.451657772064209\n",
            "Sentiment ratio for this batch:  1.4517009258270264\n",
            "Sentiment ratio for this batch:  1.4515929222106934\n",
            "Sentiment ratio for this batch:  1.451520562171936\n",
            "Sentiment ratio for this batch:  1.4513278007507324\n",
            "Sentiment ratio for this batch:  1.4512295722961426\n",
            "Sentiment ratio for this batch:  1.4510865211486816\n",
            "Sentiment ratio for this batch:  1.4509668350219727\n",
            "Sentiment ratio for this batch:  1.4508730173110962\n",
            "Sentiment ratio for this batch:  1.4507943391799927\n",
            "Epoch: 2, Batch: 90, Loss: 0.10356578230857849, Accuracy: 0.9148351648351648\n",
            "Sentiment ratio for this batch:  1.4506689310073853\n",
            "Sentiment ratio for this batch:  1.4503493309020996\n",
            "Sentiment ratio for this batch:  1.4499396085739136\n",
            "Sentiment ratio for this batch:  1.449562430381775\n",
            "Sentiment ratio for this batch:  1.4492744207382202\n",
            "Sentiment ratio for this batch:  1.4488943815231323\n",
            "Sentiment ratio for this batch:  1.4485406875610352\n",
            "Sentiment ratio for this batch:  1.4482768774032593\n",
            "Sentiment ratio for this batch:  1.4479790925979614\n",
            "Sentiment ratio for this batch:  1.447802186012268\n",
            "Epoch: 2, Batch: 100, Loss: 0.046368811279535294, Accuracy: 0.9146039603960396\n",
            "Sentiment ratio for this batch:  1.4476429224014282\n",
            "Sentiment ratio for this batch:  1.4475220441818237\n",
            "Sentiment ratio for this batch:  1.4475079774856567\n",
            "Sentiment ratio for this batch:  1.4474977254867554\n",
            "Sentiment ratio for this batch:  1.447564721107483\n",
            "Sentiment ratio for this batch:  1.447590947151184\n",
            "Sentiment ratio for this batch:  1.4476635456085205\n",
            "Sentiment ratio for this batch:  1.447567105293274\n",
            "Sentiment ratio for this batch:  1.4474456310272217\n",
            "Sentiment ratio for this batch:  1.447340488433838\n",
            "Epoch: 2, Batch: 110, Loss: 0.47833168506622314, Accuracy: 0.9121621621621622\n",
            "Sentiment ratio for this batch:  1.4470850229263306\n",
            "Sentiment ratio for this batch:  1.4468587636947632\n",
            "Sentiment ratio for this batch:  1.446618676185608\n",
            "Sentiment ratio for this batch:  1.4463993310928345\n",
            "Sentiment ratio for this batch:  1.446195363998413\n",
            "Sentiment ratio for this batch:  1.4461833238601685\n",
            "Sentiment ratio for this batch:  1.4463375806808472\n",
            "Sentiment ratio for this batch:  1.4465045928955078\n",
            "Sentiment ratio for this batch:  1.446668267250061\n",
            "Sentiment ratio for this batch:  1.4468334913253784\n",
            "Epoch: 2, Batch: 120, Loss: 0.13930989801883698, Accuracy: 0.9142561983471075\n",
            "Sentiment ratio for this batch:  1.4470945596694946\n",
            "Sentiment ratio for this batch:  1.4472336769104004\n",
            "Sentiment ratio for this batch:  1.4474329948425293\n",
            "Sentiment ratio for this batch:  1.4479424953460693\n",
            "Sentiment ratio for this batch:  1.4484667778015137\n",
            "Sentiment ratio for this batch:  1.4489680528640747\n",
            "Sentiment ratio for this batch:  1.4493284225463867\n",
            "Sentiment ratio for this batch:  1.4496575593948364\n",
            "Sentiment ratio for this batch:  1.4499884843826294\n",
            "Sentiment ratio for this batch:  1.450052261352539\n",
            "Epoch: 2, Batch: 130, Loss: 0.04932563751935959, Accuracy: 0.9169847328244275\n",
            "Sentiment ratio for this batch:  1.45014226436615\n",
            "Sentiment ratio for this batch:  1.450250267982483\n",
            "Sentiment ratio for this batch:  1.4503271579742432\n",
            "Sentiment ratio for this batch:  1.4504810571670532\n",
            "Sentiment ratio for this batch:  1.450690507888794\n",
            "Sentiment ratio for this batch:  1.450906753540039\n",
            "Sentiment ratio for this batch:  1.451065182685852\n",
            "Sentiment ratio for this batch:  1.4511613845825195\n",
            "Sentiment ratio for this batch:  1.4512183666229248\n",
            "Sentiment ratio for this batch:  1.4513248205184937\n",
            "Epoch: 2, Batch: 140, Loss: 0.11804376542568207, Accuracy: 0.9202127659574468\n",
            "Sentiment ratio for this batch:  1.4513278007507324\n",
            "Sentiment ratio for this batch:  1.4511263370513916\n",
            "Sentiment ratio for this batch:  1.4510138034820557\n",
            "Sentiment ratio for this batch:  1.450916051864624\n",
            "Sentiment ratio for this batch:  1.4508213996887207\n",
            "Sentiment ratio for this batch:  1.45073401927948\n",
            "Sentiment ratio for this batch:  1.4507170915603638\n",
            "Sentiment ratio for this batch:  1.4505733251571655\n",
            "Sentiment ratio for this batch:  1.4504426717758179\n",
            "Sentiment ratio for this batch:  1.4502049684524536\n",
            "Epoch: 2, Batch: 150, Loss: 0.3091331422328949, Accuracy: 0.9201158940397351\n",
            "Sentiment ratio for this batch:  1.4499797821044922\n",
            "Sentiment ratio for this batch:  1.449853539466858\n",
            "Sentiment ratio for this batch:  1.4496777057647705\n",
            "Sentiment ratio for this batch:  1.4494625329971313\n",
            "Sentiment ratio for this batch:  1.4492725133895874\n",
            "Sentiment ratio for this batch:  1.4491239786148071\n",
            "Sentiment ratio for this batch:  1.4490445852279663\n",
            "Sentiment ratio for this batch:  1.448927640914917\n",
            "Sentiment ratio for this batch:  1.4489052295684814\n",
            "Sentiment ratio for this batch:  1.44882333278656\n",
            "Epoch: 2, Batch: 160, Loss: 0.22827951610088348, Accuracy: 0.9208074534161491\n",
            "Sentiment ratio for this batch:  1.448540449142456\n",
            "Sentiment ratio for this batch:  1.4483869075775146\n",
            "Sentiment ratio for this batch:  1.4482359886169434\n",
            "Sentiment ratio for this batch:  1.447896122932434\n",
            "Sentiment ratio for this batch:  1.4475470781326294\n",
            "Sentiment ratio for this batch:  1.447222352027893\n",
            "Sentiment ratio for this batch:  1.4470200538635254\n",
            "Sentiment ratio for this batch:  1.446785807609558\n",
            "Sentiment ratio for this batch:  1.4463688135147095\n",
            "Sentiment ratio for this batch:  1.4459987878799438\n",
            "Epoch: 2, Batch: 170, Loss: 0.1845761239528656, Accuracy: 0.9195906432748538\n",
            "Sentiment ratio for this batch:  1.4456418752670288\n",
            "Sentiment ratio for this batch:  1.4451441764831543\n",
            "Sentiment ratio for this batch:  1.4447021484375\n",
            "Sentiment ratio for this batch:  1.4443708658218384\n",
            "Sentiment ratio for this batch:  1.444031000137329\n",
            "Sentiment ratio for this batch:  1.4437094926834106\n",
            "Sentiment ratio for this batch:  1.4434510469436646\n",
            "Sentiment ratio for this batch:  1.4431895017623901\n",
            "Sentiment ratio for this batch:  1.442979335784912\n",
            "Sentiment ratio for this batch:  1.4429216384887695\n",
            "Epoch: 2, Batch: 180, Loss: 0.1687668114900589, Accuracy: 0.9205801104972375\n",
            "Sentiment ratio for this batch:  1.4429333209991455\n",
            "Sentiment ratio for this batch:  1.4430210590362549\n",
            "Sentiment ratio for this batch:  1.4432880878448486\n",
            "Sentiment ratio for this batch:  1.4434235095977783\n",
            "Sentiment ratio for this batch:  1.443503499031067\n",
            "Sentiment ratio for this batch:  1.4435869455337524\n",
            "Sentiment ratio for this batch:  1.4435441493988037\n",
            "Sentiment ratio for this batch:  1.4433667659759521\n",
            "Sentiment ratio for this batch:  1.4432203769683838\n",
            "Sentiment ratio for this batch:  1.4429031610488892\n",
            "Epoch: 2, Batch: 190, Loss: 0.0779251679778099, Accuracy: 0.9217931937172775\n",
            "Sentiment ratio for this batch:  1.4424158334732056\n",
            "Sentiment ratio for this batch:  1.4419740438461304\n",
            "Sentiment ratio for this batch:  1.4415737390518188\n",
            "Sentiment ratio for this batch:  1.441117763519287\n",
            "Sentiment ratio for this batch:  1.440725564956665\n",
            "Sentiment ratio for this batch:  1.440450668334961\n",
            "Sentiment ratio for this batch:  1.4402447938919067\n",
            "Sentiment ratio for this batch:  1.4401644468307495\n",
            "Sentiment ratio for this batch:  1.4402114152908325\n",
            "Sentiment ratio for this batch:  1.4402451515197754\n",
            "Epoch: 2, Batch: 200, Loss: 0.35267210006713867, Accuracy: 0.9231965174129353\n",
            "Sentiment ratio for this batch:  1.440402865409851\n",
            "Sentiment ratio for this batch:  1.4405494928359985\n",
            "Sentiment ratio for this batch:  1.440686821937561\n",
            "Sentiment ratio for this batch:  1.4406840801239014\n",
            "Sentiment ratio for this batch:  1.4405536651611328\n",
            "Sentiment ratio for this batch:  1.4404388666152954\n",
            "Sentiment ratio for this batch:  1.4403271675109863\n",
            "Sentiment ratio for this batch:  1.4402328729629517\n",
            "Sentiment ratio for this batch:  1.4401226043701172\n",
            "Sentiment ratio for this batch:  1.4399851560592651\n",
            "Epoch: 2, Batch: 210, Loss: 0.046848032623529434, Accuracy: 0.9247630331753555\n",
            "Sentiment ratio for this batch:  1.439866304397583\n",
            "Sentiment ratio for this batch:  1.4396861791610718\n",
            "Sentiment ratio for this batch:  1.4395173788070679\n",
            "Sentiment ratio for this batch:  1.4394316673278809\n",
            "Sentiment ratio for this batch:  1.43936026096344\n",
            "Sentiment ratio for this batch:  1.439310073852539\n",
            "Sentiment ratio for this batch:  1.4392801523208618\n",
            "Sentiment ratio for this batch:  1.439189076423645\n",
            "Sentiment ratio for this batch:  1.439035177230835\n",
            "Sentiment ratio for this batch:  1.4388031959533691\n",
            "Epoch: 2, Batch: 220, Loss: 0.4950714409351349, Accuracy: 0.9264705882352942\n",
            "Sentiment ratio for this batch:  1.438783049583435\n",
            "Sentiment ratio for this batch:  1.438773512840271\n",
            "Sentiment ratio for this batch:  1.438767671585083\n",
            "Sentiment ratio for this batch:  1.4388513565063477\n",
            "Sentiment ratio for this batch:  1.4389269351959229\n",
            "Sentiment ratio for this batch:  1.43898606300354\n",
            "Sentiment ratio for this batch:  1.4389837980270386\n",
            "Sentiment ratio for this batch:  1.4389570951461792\n",
            "Sentiment ratio for this batch:  1.4390100240707397\n",
            "Sentiment ratio for this batch:  1.4390558004379272\n",
            "Epoch: 2, Batch: 230, Loss: 0.05328649282455444, Accuracy: 0.9261363636363636\n",
            "Sentiment ratio for this batch:  1.439152479171753\n",
            "Sentiment ratio for this batch:  1.4394745826721191\n",
            "Sentiment ratio for this batch:  1.439683198928833\n",
            "Sentiment ratio for this batch:  1.4398926496505737\n",
            "Sentiment ratio for this batch:  1.4400498867034912\n",
            "Sentiment ratio for this batch:  1.4403306245803833\n",
            "Sentiment ratio for this batch:  1.44057297706604\n",
            "Sentiment ratio for this batch:  1.4407012462615967\n",
            "Sentiment ratio for this batch:  1.440748691558838\n",
            "Sentiment ratio for this batch:  1.440751314163208\n",
            "Epoch: 2, Batch: 240, Loss: 0.04446565359830856, Accuracy: 0.9268672199170125\n",
            "Sentiment ratio for this batch:  1.4407328367233276\n",
            "Sentiment ratio for this batch:  1.4406580924987793\n",
            "Sentiment ratio for this batch:  1.4404009580612183\n",
            "Sentiment ratio for this batch:  1.4401618242263794\n",
            "Sentiment ratio for this batch:  1.4398587942123413\n",
            "Sentiment ratio for this batch:  1.4397053718566895\n",
            "Sentiment ratio for this batch:  1.4394090175628662\n",
            "Sentiment ratio for this batch:  1.4389806985855103\n",
            "Sentiment ratio for this batch:  1.4388693571090698\n",
            "Sentiment ratio for this batch:  1.4387563467025757\n",
            "Epoch: 2, Batch: 250, Loss: 0.4193134605884552, Accuracy: 0.9255478087649402\n",
            "Sentiment ratio for this batch:  1.4386495351791382\n",
            "Sentiment ratio for this batch:  1.4384679794311523\n",
            "Sentiment ratio for this batch:  1.4380853176116943\n",
            "Sentiment ratio for this batch:  1.4377228021621704\n",
            "Sentiment ratio for this batch:  1.4373903274536133\n",
            "Sentiment ratio for this batch:  1.437037706375122\n",
            "Sentiment ratio for this batch:  1.4368318319320679\n",
            "Sentiment ratio for this batch:  1.4365078210830688\n",
            "Sentiment ratio for this batch:  1.436047077178955\n",
            "Sentiment ratio for this batch:  1.4358559846878052\n",
            "Epoch: 2, Batch: 260, Loss: 0.3029337227344513, Accuracy: 0.9264846743295019\n",
            "Sentiment ratio for this batch:  1.4355260133743286\n",
            "Sentiment ratio for this batch:  1.4351805448532104\n",
            "Sentiment ratio for this batch:  1.4347715377807617\n",
            "Sentiment ratio for this batch:  1.4343664646148682\n",
            "Sentiment ratio for this batch:  1.4340708255767822\n",
            "Sentiment ratio for this batch:  1.4336743354797363\n",
            "Sentiment ratio for this batch:  1.4333239793777466\n",
            "Sentiment ratio for this batch:  1.4329577684402466\n",
            "Sentiment ratio for this batch:  1.43263578414917\n",
            "Sentiment ratio for this batch:  1.432381272315979\n",
            "Epoch: 2, Batch: 270, Loss: 0.09555578976869583, Accuracy: 0.9273523985239852\n",
            "Sentiment ratio for this batch:  1.4321597814559937\n",
            "Sentiment ratio for this batch:  1.4319614171981812\n",
            "Sentiment ratio for this batch:  1.4322450160980225\n",
            "Sentiment ratio for this batch:  1.43239426612854\n",
            "Sentiment ratio for this batch:  1.4325233697891235\n",
            "Sentiment ratio for this batch:  1.4326189756393433\n",
            "Sentiment ratio for this batch:  1.4329743385314941\n",
            "Sentiment ratio for this batch:  1.4333372116088867\n",
            "Sentiment ratio for this batch:  1.433760404586792\n",
            "Sentiment ratio for this batch:  1.433721899986267\n",
            "Epoch: 2, Batch: 280, Loss: 0.3215695023536682, Accuracy: 0.9263790035587188\n",
            "Sentiment ratio for this batch:  1.4339900016784668\n",
            "Sentiment ratio for this batch:  1.4344395399093628\n",
            "Sentiment ratio for this batch:  1.4349675178527832\n",
            "Sentiment ratio for this batch:  1.435397744178772\n",
            "Sentiment ratio for this batch:  1.4357738494873047\n",
            "Sentiment ratio for this batch:  1.4361838102340698\n",
            "Sentiment ratio for this batch:  1.4364484548568726\n",
            "Sentiment ratio for this batch:  1.4367073774337769\n",
            "Sentiment ratio for this batch:  1.436935544013977\n",
            "Sentiment ratio for this batch:  1.4371644258499146\n",
            "Epoch: 2, Batch: 290, Loss: 0.016408855095505714, Accuracy: 0.9269759450171822\n",
            "Sentiment ratio for this batch:  1.4373704195022583\n",
            "Sentiment ratio for this batch:  1.4376170635223389\n",
            "Sentiment ratio for this batch:  1.4377973079681396\n",
            "Sentiment ratio for this batch:  1.437872052192688\n",
            "Sentiment ratio for this batch:  1.4379355907440186\n",
            "Sentiment ratio for this batch:  1.437995433807373\n",
            "Sentiment ratio for this batch:  1.4379273653030396\n",
            "Sentiment ratio for this batch:  1.437844157218933\n",
            "Sentiment ratio for this batch:  1.4375314712524414\n",
            "Sentiment ratio for this batch:  1.437059760093689\n",
            "Epoch: 2, Batch: 300, Loss: 0.21736417710781097, Accuracy: 0.9269102990033222\n",
            "Sentiment ratio for this batch:  1.4368128776550293\n",
            "Sentiment ratio for this batch:  1.4364850521087646\n",
            "Sentiment ratio for this batch:  1.4362534284591675\n",
            "Sentiment ratio for this batch:  1.436012625694275\n",
            "Sentiment ratio for this batch:  1.4358032941818237\n",
            "Sentiment ratio for this batch:  1.4355504512786865\n",
            "Sentiment ratio for this batch:  1.4354221820831299\n",
            "Sentiment ratio for this batch:  1.4350340366363525\n",
            "Sentiment ratio for this batch:  1.4347317218780518\n",
            "Sentiment ratio for this batch:  1.4345706701278687\n",
            "Epoch: 2, Batch: 310, Loss: 0.095271535217762, Accuracy: 0.927451768488746\n",
            "Sentiment ratio for this batch:  1.4345258474349976\n",
            "Sentiment ratio for this batch:  1.4344432353973389\n",
            "Sentiment ratio for this batch:  1.4340263605117798\n",
            "Sentiment ratio for this batch:  1.4336838722229004\n",
            "Sentiment ratio for this batch:  1.4333029985427856\n",
            "Sentiment ratio for this batch:  1.4329777956008911\n",
            "Sentiment ratio for this batch:  1.4328422546386719\n",
            "Sentiment ratio for this batch:  1.4327841997146606\n",
            "Sentiment ratio for this batch:  1.4327731132507324\n",
            "Sentiment ratio for this batch:  1.4327553510665894\n",
            "Epoch: 2, Batch: 320, Loss: 0.25846415758132935, Accuracy: 0.9273753894080997\n",
            "Sentiment ratio for this batch:  1.432641625404358\n",
            "Sentiment ratio for this batch:  1.4322413206100464\n",
            "Sentiment ratio for this batch:  1.4317731857299805\n",
            "Sentiment ratio for this batch:  1.4313228130340576\n",
            "Sentiment ratio for this batch:  1.4308456182479858\n",
            "Sentiment ratio for this batch:  1.430376410484314\n",
            "Sentiment ratio for this batch:  1.4299813508987427\n",
            "Sentiment ratio for this batch:  1.4296072721481323\n",
            "Sentiment ratio for this batch:  1.4290821552276611\n",
            "Sentiment ratio for this batch:  1.4286702871322632\n",
            "Epoch: 2, Batch: 330, Loss: 0.22871512174606323, Accuracy: 0.9274924471299094\n",
            "Sentiment ratio for this batch:  1.4283117055892944\n",
            "Sentiment ratio for this batch:  1.4280955791473389\n",
            "Sentiment ratio for this batch:  1.427889108657837\n",
            "Sentiment ratio for this batch:  1.4279435873031616\n",
            "Sentiment ratio for this batch:  1.4279893636703491\n",
            "Sentiment ratio for this batch:  1.4280569553375244\n",
            "Sentiment ratio for this batch:  1.4282028675079346\n",
            "Sentiment ratio for this batch:  1.428243637084961\n",
            "Sentiment ratio for this batch:  1.4282571077346802\n",
            "Sentiment ratio for this batch:  1.4283093214035034\n",
            "Epoch: 2, Batch: 340, Loss: 0.2353011667728424, Accuracy: 0.9274193548387096\n",
            "Sentiment ratio for this batch:  1.4283415079116821\n",
            "Sentiment ratio for this batch:  1.4284151792526245\n",
            "Sentiment ratio for this batch:  1.428411841392517\n",
            "Sentiment ratio for this batch:  1.428189992904663\n",
            "Sentiment ratio for this batch:  1.4279066324234009\n",
            "Sentiment ratio for this batch:  1.427667260169983\n",
            "Sentiment ratio for this batch:  1.427481770515442\n",
            "Sentiment ratio for this batch:  1.4273216724395752\n",
            "Sentiment ratio for this batch:  1.4271886348724365\n",
            "Sentiment ratio for this batch:  1.4270905256271362\n",
            "Epoch: 2, Batch: 350, Loss: 0.18648992478847504, Accuracy: 0.9280626780626781\n",
            "Sentiment ratio for this batch:  1.42714262008667\n",
            "Sentiment ratio for this batch:  1.4272197484970093\n",
            "Sentiment ratio for this batch:  1.4273066520690918\n",
            "Sentiment ratio for this batch:  1.4275014400482178\n",
            "Sentiment ratio for this batch:  1.427635669708252\n",
            "Sentiment ratio for this batch:  1.4276915788650513\n",
            "Sentiment ratio for this batch:  1.4276809692382812\n",
            "Sentiment ratio for this batch:  1.4275462627410889\n",
            "Sentiment ratio for this batch:  1.4273842573165894\n",
            "Sentiment ratio for this batch:  1.4271531105041504\n",
            "Epoch: 2, Batch: 360, Loss: 0.12286663800477982, Accuracy: 0.9278047091412742\n",
            "Sentiment ratio for this batch:  1.4268025159835815\n",
            "Sentiment ratio for this batch:  1.426171064376831\n",
            "Sentiment ratio for this batch:  1.4254577159881592\n",
            "Sentiment ratio for this batch:  1.424756407737732\n",
            "Sentiment ratio for this batch:  1.4240632057189941\n",
            "Sentiment ratio for this batch:  1.4233121871948242\n",
            "Sentiment ratio for this batch:  1.4226340055465698\n",
            "Sentiment ratio for this batch:  1.4215550422668457\n",
            "Sentiment ratio for this batch:  1.4205378293991089\n",
            "Sentiment ratio for this batch:  1.4196287393569946\n",
            "Epoch: 2, Batch: 370, Loss: 0.2790032923221588, Accuracy: 0.9275606469002695\n",
            "Sentiment ratio for this batch:  1.4188108444213867\n",
            "Sentiment ratio for this batch:  1.4180580377578735\n",
            "Sentiment ratio for this batch:  1.417330026626587\n",
            "Sentiment ratio for this batch:  1.4167098999023438\n",
            "Sentiment ratio for this batch:  1.4163362979888916\n",
            "Sentiment ratio for this batch:  1.4160773754119873\n",
            "Sentiment ratio for this batch:  1.4159722328186035\n",
            "Sentiment ratio for this batch:  1.415788173675537\n",
            "Sentiment ratio for this batch:  1.4158275127410889\n",
            "Sentiment ratio for this batch:  1.415793776512146\n",
            "Epoch: 2, Batch: 380, Loss: 0.02945375256240368, Accuracy: 0.9273293963254593\n",
            "Sentiment ratio for this batch:  1.4157708883285522\n",
            "Sentiment ratio for this batch:  1.4156407117843628\n",
            "Sentiment ratio for this batch:  1.4154492616653442\n",
            "Sentiment ratio for this batch:  1.4152387380599976\n",
            "Sentiment ratio for this batch:  1.4150742292404175\n",
            "Sentiment ratio for this batch:  1.4148238897323608\n",
            "Sentiment ratio for this batch:  1.4145512580871582\n",
            "Sentiment ratio for this batch:  1.4143084287643433\n",
            "Sentiment ratio for this batch:  1.4139530658721924\n",
            "Sentiment ratio for this batch:  1.41361665725708\n",
            "Epoch: 2, Batch: 390, Loss: 0.03962646424770355, Accuracy: 0.92806905370844\n",
            "Sentiment ratio for this batch:  1.4133447408676147\n",
            "Sentiment ratio for this batch:  1.4128788709640503\n",
            "Sentiment ratio for this batch:  1.4118924140930176\n",
            "Sentiment ratio for this batch:  1.4110186100006104\n",
            "Sentiment ratio for this batch:  1.4103405475616455\n",
            "Sentiment ratio for this batch:  1.4098560810089111\n",
            "Sentiment ratio for this batch:  1.4094524383544922\n",
            "Sentiment ratio for this batch:  1.4091763496398926\n",
            "Sentiment ratio for this batch:  1.4090197086334229\n",
            "Sentiment ratio for this batch:  1.408904790878296\n",
            "Epoch: 2, Batch: 400, Loss: 0.2038159966468811, Accuracy: 0.9278366583541147\n",
            "Sentiment ratio for this batch:  1.4088904857635498\n",
            "Sentiment ratio for this batch:  1.40899658203125\n",
            "Sentiment ratio for this batch:  1.4091243743896484\n",
            "Sentiment ratio for this batch:  1.4092562198638916\n",
            "Sentiment ratio for this batch:  1.4094253778457642\n",
            "Sentiment ratio for this batch:  1.4095282554626465\n",
            "Sentiment ratio for this batch:  1.4095898866653442\n",
            "Sentiment ratio for this batch:  1.4097180366516113\n",
            "Sentiment ratio for this batch:  1.409555196762085\n",
            "Sentiment ratio for this batch:  1.409421443939209\n",
            "Epoch: 2, Batch: 410, Loss: 0.24688994884490967, Accuracy: 0.9283759124087592\n",
            "Sentiment ratio for this batch:  1.4094194173812866\n",
            "Sentiment ratio for this batch:  1.4093409776687622\n",
            "Sentiment ratio for this batch:  1.4092333316802979\n",
            "Sentiment ratio for this batch:  1.4090940952301025\n",
            "Sentiment ratio for this batch:  1.408976674079895\n",
            "Sentiment ratio for this batch:  1.4089914560317993\n",
            "Sentiment ratio for this batch:  1.4090789556503296\n",
            "Sentiment ratio for this batch:  1.409191608428955\n",
            "Sentiment ratio for this batch:  1.4093519449234009\n",
            "Sentiment ratio for this batch:  1.4095064401626587\n",
            "Epoch: 2, Batch: 420, Loss: 0.25920721888542175, Accuracy: 0.9282957244655582\n",
            "Sentiment ratio for this batch:  1.409687876701355\n",
            "Sentiment ratio for this batch:  1.410078525543213\n",
            "Sentiment ratio for this batch:  1.410526990890503\n",
            "Sentiment ratio for this batch:  1.410836935043335\n",
            "Sentiment ratio for this batch:  1.411293625831604\n",
            "Sentiment ratio for this batch:  1.4118428230285645\n",
            "Sentiment ratio for this batch:  1.4123494625091553\n",
            "Sentiment ratio for this batch:  1.4131476879119873\n",
            "Sentiment ratio for this batch:  1.4138731956481934\n",
            "Sentiment ratio for this batch:  1.4142987728118896\n",
            "Epoch: 2, Batch: 430, Loss: 0.11666973680257797, Accuracy: 0.9289443155452436\n",
            "Sentiment ratio for this batch:  1.4147698879241943\n",
            "Sentiment ratio for this batch:  1.4152326583862305\n",
            "Sentiment ratio for this batch:  1.4156415462493896\n",
            "Sentiment ratio for this batch:  1.4160351753234863\n",
            "Sentiment ratio for this batch:  1.4162464141845703\n",
            "Sentiment ratio for this batch:  1.416408896446228\n",
            "Sentiment ratio for this batch:  1.4163895845413208\n",
            "Sentiment ratio for this batch:  1.4163810014724731\n",
            "Sentiment ratio for this batch:  1.416383981704712\n",
            "Sentiment ratio for this batch:  1.41635262966156\n",
            "Epoch: 2, Batch: 440, Loss: 0.1543613076210022, Accuracy: 0.9288548752834467\n",
            "Sentiment ratio for this batch:  1.4163105487823486\n",
            "Sentiment ratio for this batch:  1.4162119626998901\n",
            "Sentiment ratio for this batch:  1.4161070585250854\n",
            "Sentiment ratio for this batch:  1.4159600734710693\n",
            "Sentiment ratio for this batch:  1.415826439857483\n",
            "Sentiment ratio for this batch:  1.4156875610351562\n",
            "Sentiment ratio for this batch:  1.4156018495559692\n",
            "Sentiment ratio for this batch:  1.4155629873275757\n",
            "Sentiment ratio for this batch:  1.4152599573135376\n",
            "Sentiment ratio for this batch:  1.415009617805481\n",
            "Epoch: 2, Batch: 450, Loss: 0.27758097648620605, Accuracy: 0.9291851441241685\n",
            "Sentiment ratio for this batch:  1.414961576461792\n",
            "Sentiment ratio for this batch:  1.4151358604431152\n",
            "Sentiment ratio for this batch:  1.415327548980713\n",
            "Sentiment ratio for this batch:  1.4156922101974487\n",
            "Sentiment ratio for this batch:  1.4160783290863037\n",
            "Sentiment ratio for this batch:  1.4164094924926758\n",
            "Sentiment ratio for this batch:  1.416805386543274\n",
            "Sentiment ratio for this batch:  1.417136549949646\n",
            "Sentiment ratio for this batch:  1.4174025058746338\n",
            "Sentiment ratio for this batch:  1.4176369905471802\n",
            "Epoch: 2, Batch: 460, Loss: 0.10765525698661804, Accuracy: 0.9297722342733189\n",
            "Sentiment ratio for this batch:  1.4178745746612549\n",
            "Sentiment ratio for this batch:  1.4180277585983276\n",
            "Sentiment ratio for this batch:  1.418212890625\n",
            "Sentiment ratio for this batch:  1.4184842109680176\n",
            "Sentiment ratio for this batch:  1.418585181236267\n",
            "Sentiment ratio for this batch:  1.4186543226242065\n",
            "Sentiment ratio for this batch:  1.4187089204788208\n",
            "Sentiment ratio for this batch:  1.4187487363815308\n",
            "Sentiment ratio for this batch:  1.418787956237793\n",
            "Sentiment ratio for this batch:  1.4187849760055542\n",
            "Epoch: 2, Batch: 470, Loss: 0.197452113032341, Accuracy: 0.9304670912951167\n",
            "Sentiment ratio for this batch:  1.4189289808273315\n",
            "Sentiment ratio for this batch:  1.4193042516708374\n",
            "Sentiment ratio for this batch:  1.4196455478668213\n",
            "Sentiment ratio for this batch:  1.4201631546020508\n",
            "Sentiment ratio for this batch:  1.420740008354187\n",
            "Sentiment ratio for this batch:  1.4212297201156616\n",
            "Sentiment ratio for this batch:  1.4216727018356323\n",
            "Sentiment ratio for this batch:  1.4220480918884277\n",
            "Sentiment ratio for this batch:  1.4223484992980957\n",
            "Sentiment ratio for this batch:  1.4225908517837524\n",
            "Epoch: 2, Batch: 480, Loss: 0.3313716948032379, Accuracy: 0.930483367983368\n",
            "Sentiment ratio for this batch:  1.4224413633346558\n",
            "Sentiment ratio for this batch:  1.422261118888855\n",
            "Sentiment ratio for this batch:  1.4220620393753052\n",
            "Sentiment ratio for this batch:  1.421792984008789\n",
            "Sentiment ratio for this batch:  1.421282172203064\n",
            "Sentiment ratio for this batch:  1.4205864667892456\n",
            "Sentiment ratio for this batch:  1.41995370388031\n",
            "Sentiment ratio for this batch:  1.4191561937332153\n",
            "Sentiment ratio for this batch:  1.4184669256210327\n",
            "Sentiment ratio for this batch:  1.417906641960144\n",
            "Epoch: 2, Batch: 490, Loss: 0.11626717448234558, Accuracy: 0.9308808553971487\n",
            "Sentiment ratio for this batch:  1.4174081087112427\n",
            "Sentiment ratio for this batch:  1.4169633388519287\n",
            "Sentiment ratio for this batch:  1.416675090789795\n",
            "Sentiment ratio for this batch:  1.4164174795150757\n",
            "Sentiment ratio for this batch:  1.4162057638168335\n",
            "Sentiment ratio for this batch:  1.4160919189453125\n",
            "Sentiment ratio for this batch:  1.4161311388015747\n",
            "Sentiment ratio for this batch:  1.4162348508834839\n",
            "Sentiment ratio for this batch:  1.4160821437835693\n",
            "Sentiment ratio for this batch:  1.4157168865203857\n",
            "Epoch: 2, Batch: 500, Loss: 0.2276473343372345, Accuracy: 0.9307634730538922\n",
            "Sentiment ratio for this batch:  1.415395975112915\n",
            "Sentiment ratio for this batch:  1.4152623414993286\n",
            "Sentiment ratio for this batch:  1.415023684501648\n",
            "Sentiment ratio for this batch:  1.4146449565887451\n",
            "Sentiment ratio for this batch:  1.4143165349960327\n",
            "Sentiment ratio for this batch:  1.4139822721481323\n",
            "Sentiment ratio for this batch:  1.4137455224990845\n",
            "Sentiment ratio for this batch:  1.4134292602539062\n",
            "Sentiment ratio for this batch:  1.4131101369857788\n",
            "Sentiment ratio for this batch:  1.4129292964935303\n",
            "Epoch: 2, Batch: 510, Loss: 0.3842659592628479, Accuracy: 0.9310176125244618\n",
            "Sentiment ratio for this batch:  1.412658929824829\n",
            "Sentiment ratio for this batch:  1.4123696088790894\n",
            "Sentiment ratio for this batch:  1.4120547771453857\n",
            "Sentiment ratio for this batch:  1.41170072555542\n",
            "Sentiment ratio for this batch:  1.411502718925476\n",
            "Sentiment ratio for this batch:  1.411361575126648\n",
            "Sentiment ratio for this batch:  1.4112629890441895\n",
            "Sentiment ratio for this batch:  1.4111942052841187\n",
            "Sentiment ratio for this batch:  1.411386251449585\n",
            "Sentiment ratio for this batch:  1.4115800857543945\n",
            "Epoch: 2, Batch: 520, Loss: 0.09518090635538101, Accuracy: 0.9311420345489443\n",
            "Sentiment ratio for this batch:  1.4116811752319336\n",
            "Sentiment ratio for this batch:  1.4117498397827148\n",
            "Sentiment ratio for this batch:  1.4118549823760986\n",
            "Sentiment ratio for this batch:  1.4119598865509033\n",
            "Sentiment ratio for this batch:  1.4120110273361206\n",
            "Sentiment ratio for this batch:  1.4119714498519897\n",
            "Sentiment ratio for this batch:  1.4121105670928955\n",
            "Sentiment ratio for this batch:  1.412182331085205\n",
            "Sentiment ratio for this batch:  1.412447452545166\n",
            "Sentiment ratio for this batch:  1.4124938249588013\n",
            "Epoch: 2, Batch: 530, Loss: 0.3053557574748993, Accuracy: 0.9303201506591338\n",
            "Sentiment ratio for this batch:  1.4127477407455444\n",
            "Sentiment ratio for this batch:  1.4128637313842773\n",
            "Sentiment ratio for this batch:  1.4130332469940186\n",
            "Sentiment ratio for this batch:  1.4131988286972046\n",
            "Sentiment ratio for this batch:  1.4132981300354004\n",
            "Sentiment ratio for this batch:  1.4134584665298462\n",
            "Sentiment ratio for this batch:  1.413633108139038\n",
            "Sentiment ratio for this batch:  1.4138017892837524\n",
            "Sentiment ratio for this batch:  1.4139673709869385\n",
            "Sentiment ratio for this batch:  1.414219856262207\n",
            "Epoch: 2, Batch: 540, Loss: 0.3223847448825836, Accuracy: 0.9307994454713494\n",
            "Sentiment ratio for this batch:  1.4144465923309326\n",
            "Sentiment ratio for this batch:  1.4147658348083496\n",
            "Sentiment ratio for this batch:  1.4150537252426147\n",
            "Sentiment ratio for this batch:  1.4153858423233032\n",
            "Sentiment ratio for this batch:  1.415740966796875\n",
            "Sentiment ratio for this batch:  1.4160902500152588\n",
            "Sentiment ratio for this batch:  1.416354775428772\n",
            "Sentiment ratio for this batch:  1.4167240858078003\n",
            "Sentiment ratio for this batch:  1.417063593864441\n",
            "Sentiment ratio for this batch:  1.417345404624939\n",
            "Epoch: 2, Batch: 550, Loss: 0.18310989439487457, Accuracy: 0.9310344827586207\n",
            "Sentiment ratio for this batch:  1.4175843000411987\n",
            "Sentiment ratio for this batch:  1.417864203453064\n",
            "Sentiment ratio for this batch:  1.4181114435195923\n",
            "Sentiment ratio for this batch:  1.4183398485183716\n",
            "Sentiment ratio for this batch:  1.418546438217163\n",
            "Sentiment ratio for this batch:  1.4186429977416992\n",
            "Sentiment ratio for this batch:  1.4187320470809937\n",
            "Sentiment ratio for this batch:  1.4187862873077393\n",
            "Sentiment ratio for this batch:  1.4188199043273926\n",
            "Sentiment ratio for this batch:  1.4187347888946533\n",
            "Epoch: 2, Batch: 560, Loss: 0.03303609415888786, Accuracy: 0.9318181818181818\n",
            "Sentiment ratio for this batch:  1.4186744689941406\n",
            "Sentiment ratio for this batch:  1.4184376001358032\n",
            "Sentiment ratio for this batch:  1.4184948205947876\n",
            "Sentiment ratio for this batch:  1.4183772802352905\n",
            "Sentiment ratio for this batch:  1.418271780014038\n",
            "Sentiment ratio for this batch:  1.4183077812194824\n",
            "Sentiment ratio for this batch:  1.4182270765304565\n",
            "Sentiment ratio for this batch:  1.4181461334228516\n",
            "Sentiment ratio for this batch:  1.4180430173873901\n",
            "Sentiment ratio for this batch:  1.418027400970459\n",
            "Epoch: 2, Batch: 570, Loss: 0.09348724782466888, Accuracy: 0.9315893169877408\n",
            "Sentiment ratio for this batch:  1.4181008338928223\n",
            "Sentiment ratio for this batch:  1.4181605577468872\n",
            "Sentiment ratio for this batch:  1.4182621240615845\n",
            "Sentiment ratio for this batch:  1.418399691581726\n",
            "Sentiment ratio for this batch:  1.418541669845581\n",
            "Sentiment ratio for this batch:  1.4187463521957397\n",
            "Sentiment ratio for this batch:  1.4189019203186035\n",
            "Sentiment ratio for this batch:  1.4189558029174805\n",
            "Sentiment ratio for this batch:  1.418877124786377\n",
            "Sentiment ratio for this batch:  1.418792486190796\n",
            "Epoch: 2, Batch: 580, Loss: 0.10953200608491898, Accuracy: 0.9316910499139415\n",
            "Sentiment ratio for this batch:  1.418750524520874\n",
            "Sentiment ratio for this batch:  1.4184544086456299\n",
            "Sentiment ratio for this batch:  1.4181691408157349\n",
            "Sentiment ratio for this batch:  1.4179378747940063\n",
            "Sentiment ratio for this batch:  1.4177238941192627\n",
            "Sentiment ratio for this batch:  1.4174368381500244\n",
            "Sentiment ratio for this batch:  1.4171788692474365\n",
            "Sentiment ratio for this batch:  1.416825294494629\n",
            "Sentiment ratio for this batch:  1.4164721965789795\n",
            "Sentiment ratio for this batch:  1.4161311388015747\n",
            "Epoch: 2, Batch: 590, Loss: 0.15127071738243103, Accuracy: 0.9320008460236887\n",
            "Sentiment ratio for this batch:  1.4156898260116577\n",
            "Sentiment ratio for this batch:  1.41525137424469\n",
            "Sentiment ratio for this batch:  1.4149106740951538\n",
            "Sentiment ratio for this batch:  1.4145886898040771\n",
            "Sentiment ratio for this batch:  1.4144303798675537\n",
            "Sentiment ratio for this batch:  1.4142547845840454\n",
            "Sentiment ratio for this batch:  1.4141395092010498\n",
            "Sentiment ratio for this batch:  1.414023756980896\n",
            "Sentiment ratio for this batch:  1.413921594619751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [3:30:58<00:00, 4219.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2 finished with average loss: 0.18475949755404145, Accuracy: 0.9321875\n",
            "Sentiment ratio for this batch:  1.413800597190857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: TEST , Batch: 0, Loss: 0.2024640142917633, Accuracy: 0.9375\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Epoch: TEST , Batch: 10, Loss: 0.07230372726917267, Accuracy: 0.9034090909090909\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Epoch: TEST , Batch: 20, Loss: 0.29007211327552795, Accuracy: 0.9107142857142857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Epoch: TEST , Batch: 30, Loss: 0.18322692811489105, Accuracy: 0.8991935483870968\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Epoch: TEST , Batch: 40, Loss: 0.13682454824447632, Accuracy: 0.9100609756097561\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Epoch: TEST , Batch: 50, Loss: 0.36754146218299866, Accuracy: 0.9093137254901961\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Epoch: TEST , Batch: 60, Loss: 0.35918450355529785, Accuracy: 0.9077868852459017\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Epoch: TEST , Batch: 70, Loss: 0.1262206733226776, Accuracy: 0.9022887323943662\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Epoch: TEST , Batch: 80, Loss: 0.6859459280967712, Accuracy: 0.8981481481481481\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Epoch: TEST , Batch: 90, Loss: 0.10535543411970139, Accuracy: 0.9031593406593407\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Epoch: TEST , Batch: 100, Loss: 0.27517661452293396, Accuracy: 0.906559405940594\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Epoch: TEST , Batch: 110, Loss: 0.1579558104276657, Accuracy: 0.9065315315315315\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Epoch: TEST , Batch: 120, Loss: 0.3327634036540985, Accuracy: 0.9075413223140496\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Epoch: TEST , Batch: 130, Loss: 0.20935291051864624, Accuracy: 0.9074427480916031\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Epoch: TEST , Batch: 140, Loss: 0.27631524205207825, Accuracy: 0.9069148936170213\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Sentiment ratio for this batch:  1.413800597190857\n",
            "Test iteration finished with average loss: 0.24946735500668485, Accuracy: 0.9075\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertModel, BertConfig\n",
        "from tqdm import tqdm\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "# 위 구조를 취합하여 만든 이진 감정 분류를 위한 클래스\n",
        "class BertForSequenceClassification(nn.Module):\n",
        "    def __init__(self, config, num_labels):\n",
        "        super(BertForSequenceClassification, self).__init__()\n",
        "        self.bert = userBertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None, sentiment_tokens=None):\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            sentiment_tokens= sentiment_tokens,\n",
        "        )\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, 2), labels.view(-1))\n",
        "\n",
        "        return loss, logits\n",
        "\n",
        "# Pretrained BERT 모델 로드\n",
        "\n",
        "pretrained_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "pretrained_state_dict = pretrained_model.state_dict()\n",
        "\n",
        "# Custom 모델 초기화\n",
        "custom_config = BertConfig(\n",
        "    vocab_size=30522,\n",
        "    hidden_size=768,\n",
        "    num_hidden_layers=8,\n",
        "    num_attention_heads=12, # 수정된 부분\n",
        "    intermediate_size=3072, # 수정된 부분\n",
        "    hidden_act=\"gelu\",\n",
        "    hidden_dropout_prob=0.1,\n",
        "    attention_probs_dropout_prob=0.1,\n",
        "    max_position_embeddings=512,\n",
        "    type_vocab_size=2,\n",
        "    initializer_range=0.02,\n",
        "    layer_norm_eps=1e-12,\n",
        "    pad_token_id=0,\n",
        "    gradient_checkpointing=False,\n",
        "    position_embedding_type=\"absolute\",\n",
        "    use_cache=True\n",
        ")\n",
        "model = BertForSequenceClassification(custom_config, num_labels=2)\n",
        "\n",
        "# Pretrained 모델의 state_dict를 Custom 모델로 로드\n",
        "model.bert.load_state_dict(pretrained_state_dict, strict=False)\n",
        "\n",
        "# 파라미터 그룹화\n",
        "sentiment_params = []\n",
        "other_params = []\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    if 'sentiment_ratio' in name:\n",
        "        sentiment_params.append(param)\n",
        "    else:\n",
        "        other_params.append(param)\n",
        "\n",
        "# 옵티마이저 정의\n",
        "sentiment_optimizer = optim.AdamW(sentiment_params)\n",
        "other_optimizer = optim.AdamW(other_params, lr=5e-6)\n",
        "\n",
        "# ExponentialLR 스케줄러 정의\n",
        "scheduler = ExponentialLR(sentiment_optimizer, gamma=0.9)\n",
        "\n",
        "\n",
        "\n",
        "# 학습 진행\n",
        "model.train()\n",
        "for epoch in tqdm(range(3)):\n",
        "    epoch_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        sentiment_optimizer.zero_grad()\n",
        "        other_optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask'],\n",
        "            token_type_ids=batch['token_type_ids'],\n",
        "            labels=batch['labels'],\n",
        "            sentiment_tokens=batch['sentiment_tokens']\n",
        "        )\n",
        "        loss, logits = outputs\n",
        "        loss.backward()\n",
        "\n",
        "        sentiment_optimizer.step()\n",
        "        other_optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # 예측값 계산\n",
        "        _, predicted = torch.max(logits, 1)\n",
        "        correct_predictions += (predicted == batch['labels']).sum().item()\n",
        "        total_predictions += batch['labels'].size(0)\n",
        "\n",
        "        if batch_idx % 10 == 0:  # 10번째 배치마다 현황 출력\n",
        "            batch_accuracy = correct_predictions / total_predictions\n",
        "            print(f\"Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item()}, Accuracy: {batch_accuracy}\")\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / len(train_dataloader)\n",
        "    epoch_accuracy = correct_predictions / total_predictions\n",
        "    print(f\"Epoch: {epoch} finished with average loss: {avg_epoch_loss}, Accuracy: {epoch_accuracy}\")\n",
        "\n",
        "# 예측 확률 계산 및 평가 수행\n",
        "all_logits = []\n",
        "all_labels = []\n",
        "model.eval()\n",
        "epoch_loss = 0\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, batch in enumerate(val_dataloader):\n",
        "        outputs = model(\n",
        "            input_ids=batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask'],\n",
        "            token_type_ids=batch['token_type_ids'],\n",
        "            labels=batch['labels'],\n",
        "            sentiment_tokens=batch['sentiment_tokens']\n",
        "        )\n",
        "        loss, logits = outputs\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # 예측값 계산\n",
        "        _, predicted = torch.max(logits, 1)\n",
        "        correct_predictions += (predicted == batch['labels']).sum().item()\n",
        "        total_predictions += batch['labels'].size(0)\n",
        "\n",
        "        all_logits.append(logits)\n",
        "        all_labels.append(batch['labels'])\n",
        "\n",
        "        if batch_idx % 10 == 0:  # 10번째 배치마다 현황 출력\n",
        "            batch_accuracy = correct_predictions / total_predictions\n",
        "            print(f\"Epoch: TEST , Batch: {batch_idx}, Loss: {loss.item()}, Accuracy: {batch_accuracy}\")\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / len(val_dataloader)\n",
        "    epoch_accuracy = correct_predictions / total_predictions\n",
        "    print(f\"Test iteration finished with average loss: {avg_epoch_loss}, Accuracy: {epoch_accuracy}\")\n",
        "\n",
        "# 예측 확률 및 라벨 병합\n",
        "all_logits = torch.cat(all_logits).cpu().numpy()\n",
        "all_labels = torch.cat(all_labels).cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7z_SX7uiVul2",
        "outputId": "51b84e07-59a3-447a-947e-0102ee735918"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# ROC 곡선 및 AUC 계산\n",
        "lr_proba = torch.softmax(torch.tensor(all_logits), dim=1)[:, 1].numpy()\n",
        "fp_lr, tp_lr, _ = roc_curve(all_labels, lr_proba, pos_label=1)\n",
        "auroc_baseline = roc_auc_score(all_labels, lr_proba)\n",
        "\n",
        "# 예측값 계산\n",
        "y_pred = np.argmax(all_logits, axis=1)\n",
        "\n",
        "# 성능 지표 계산\n",
        "cm1 = confusion_matrix(all_labels, y_pred)\n",
        "f1_1 = f1_score(all_labels, y_pred, pos_label=1)\n",
        "precision_1 = precision_score(all_labels, y_pred, pos_label=1)\n",
        "recall_1 = recall_score(all_labels, y_pred, pos_label=1)\n",
        "\n",
        "# 혼동 행렬 및 성능 지표 시각화\n",
        "fig, axes = plt.subplots(figsize=(16, 6))\n",
        "sns.heatmap(cm1, annot=True, cmap='Blues', fmt='d', ax=axes)\n",
        "axes.set_title('Confusion Matrix', fontsize=14)\n",
        "axes.set_xlabel('Predicted Label', fontsize=12)\n",
        "axes.set_ylabel('True Label', fontsize=12)\n",
        "axes.text(0.5, -0.15, f'F1 Score: {f1_1:.4f} Precision: {precision_1:.4f} Recall: {recall_1:.4f}',\n",
        "          horizontalalignment='center', verticalalignment='center', transform=axes.transAxes, fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "# ROC 곡선 그리기\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fp_lr, tp_lr, label=f'BERT Sequence Classification (area = {auroc_baseline:.3f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsualEUMGMgq"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "be946dbf8eea4895a9971a24f18a40cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_637ccc8734664877819d97f1b4519061",
              "IPY_MODEL_1807253a9188400a89aa4653c0401319",
              "IPY_MODEL_2c6e8ccb76e54b319d15d563b33ac629"
            ],
            "layout": "IPY_MODEL_36f8816c0d834a18a1cc1400fd769e25"
          }
        },
        "637ccc8734664877819d97f1b4519061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c28744a2ae848fcae8bd837579f07b3",
            "placeholder": "​",
            "style": "IPY_MODEL_dc9acfa22c6649fbb2bdc3ef2564dc97",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1807253a9188400a89aa4653c0401319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85f58d528ac542dd8252a1b9c928478d",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e921f70094fb4d0f82a85d470c09f823",
            "value": 48
          }
        },
        "2c6e8ccb76e54b319d15d563b33ac629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd766b48d84147b88bbc3a8729f9810c",
            "placeholder": "​",
            "style": "IPY_MODEL_e62297d2a1c14f249c6725c44227c68e",
            "value": " 48.0/48.0 [00:00&lt;00:00, 4.67kB/s]"
          }
        },
        "36f8816c0d834a18a1cc1400fd769e25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c28744a2ae848fcae8bd837579f07b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc9acfa22c6649fbb2bdc3ef2564dc97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85f58d528ac542dd8252a1b9c928478d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e921f70094fb4d0f82a85d470c09f823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd766b48d84147b88bbc3a8729f9810c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e62297d2a1c14f249c6725c44227c68e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db19d6c49d494039bc3e93a6ef3054a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_849d3880b87c418a9473d07690335c3d",
              "IPY_MODEL_ccfb21ba8e1441848bcf6a678abd3863",
              "IPY_MODEL_ea5c368baca44632b98aff25ec1ffe0f"
            ],
            "layout": "IPY_MODEL_e633b32f8c224295b98c63f02fdffc9d"
          }
        },
        "849d3880b87c418a9473d07690335c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3acd0f1491454a7181634612612be0b6",
            "placeholder": "​",
            "style": "IPY_MODEL_a8665cd421634275ac0d83451d9846d7",
            "value": "vocab.txt: 100%"
          }
        },
        "ccfb21ba8e1441848bcf6a678abd3863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f42b7fb4a7b74dcab80e2892a7f01feb",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a30bebcc79bc4e43be2d42e44e1bfc1a",
            "value": 231508
          }
        },
        "ea5c368baca44632b98aff25ec1ffe0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee5329ebd97342b4a496fda3304249e6",
            "placeholder": "​",
            "style": "IPY_MODEL_fc93f8c6011c4625a2e8e2ee4154fd51",
            "value": " 232k/232k [00:00&lt;00:00, 5.01MB/s]"
          }
        },
        "e633b32f8c224295b98c63f02fdffc9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3acd0f1491454a7181634612612be0b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8665cd421634275ac0d83451d9846d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f42b7fb4a7b74dcab80e2892a7f01feb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a30bebcc79bc4e43be2d42e44e1bfc1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee5329ebd97342b4a496fda3304249e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc93f8c6011c4625a2e8e2ee4154fd51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c15208ae697e46bfa92732c9d1e29f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_deb706245dfc4685bd964c42f33ebef4",
              "IPY_MODEL_efee37703456456984ac8903a8d596bf",
              "IPY_MODEL_672a7cbcaa59493f9195153a1737498d"
            ],
            "layout": "IPY_MODEL_59d7c97b205c4a1a9d219e6f8e43fd00"
          }
        },
        "deb706245dfc4685bd964c42f33ebef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_259fd8592ab34d14b4b5b1e1c7b6c85a",
            "placeholder": "​",
            "style": "IPY_MODEL_aa38bbaf62c44438b922e4dd4349d74d",
            "value": "tokenizer.json: 100%"
          }
        },
        "efee37703456456984ac8903a8d596bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca96e9a826144004888b272a998a5304",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_912cc447ac5f4fce9d31a13732a75478",
            "value": 466062
          }
        },
        "672a7cbcaa59493f9195153a1737498d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29f124f9e67d45ed8e7ecc1b2d5cdf9e",
            "placeholder": "​",
            "style": "IPY_MODEL_0ebf2753b23745079dab2a7fb72211bc",
            "value": " 466k/466k [00:00&lt;00:00, 18.1MB/s]"
          }
        },
        "59d7c97b205c4a1a9d219e6f8e43fd00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "259fd8592ab34d14b4b5b1e1c7b6c85a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa38bbaf62c44438b922e4dd4349d74d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca96e9a826144004888b272a998a5304": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "912cc447ac5f4fce9d31a13732a75478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29f124f9e67d45ed8e7ecc1b2d5cdf9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ebf2753b23745079dab2a7fb72211bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a8e0f01621b4e10bd9bec34952ccb95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65d4737b70e54817a0b3a666c2a957cd",
              "IPY_MODEL_aa93eda1590548a38898315eee07c58d",
              "IPY_MODEL_9f33d34b938342d1ba9b56654285a6a9"
            ],
            "layout": "IPY_MODEL_7011d9e310994e39b2d84321d8360c7e"
          }
        },
        "65d4737b70e54817a0b3a666c2a957cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b55a3c6f079545caabe7c9c4eed65bc9",
            "placeholder": "​",
            "style": "IPY_MODEL_f6b94d7571494ff4b8b48778241c9e84",
            "value": "config.json: 100%"
          }
        },
        "aa93eda1590548a38898315eee07c58d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7b5e0c9042e448b900b550a4b307513",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ba66f6a9aa54cae919ce690eab9e101",
            "value": 570
          }
        },
        "9f33d34b938342d1ba9b56654285a6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b01aac93372427a99a777c9d7903db0",
            "placeholder": "​",
            "style": "IPY_MODEL_8ef4d97255ce40dea3126022e6e46a40",
            "value": " 570/570 [00:00&lt;00:00, 56.5kB/s]"
          }
        },
        "7011d9e310994e39b2d84321d8360c7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b55a3c6f079545caabe7c9c4eed65bc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6b94d7571494ff4b8b48778241c9e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7b5e0c9042e448b900b550a4b307513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ba66f6a9aa54cae919ce690eab9e101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b01aac93372427a99a777c9d7903db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ef4d97255ce40dea3126022e6e46a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}