{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kwonjihan/ML-teamproject/blob/developtemp/Embedding/Test_rs38_ratio2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfRNbEvV-8tp",
        "outputId": "5885bb7b-bc57-4b2e-ccd1-80dda74b5248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path='/content/drive/MyDrive/Colab Notebooks/12K IMDB Dataset.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "woLaLsvCPFAi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from typing import Optional, Tuple\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgRXfpJiLsAz",
        "outputId": "bacde5d9-afdf-4509-b13c-7bf750876534"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: NRCLex in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (from NRCLex) (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob->NRCLex) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->NRCLex) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->NRCLex) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->NRCLex) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->NRCLex) (4.66.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "!pip install NRCLex\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px00_B1UNyv1"
      },
      "source": [
        "## 감정에 해당하는 토큰 임베딩에 큰 포션을 취하는 방법\n",
        "- 1. 우선 문장을 토큰화하기 전에 감정이 드러난 단어를 찾는다\n",
        "- 2. 해당 단어를 버트 토크나이저를 통해 토크나이즈 된 결과를 저장해둔다\n",
        "- 3. 만약 감정이 있다면 해당 단어가 벡터로 표현되고 합해져서 임베딩 될 때 더 크게 영향을 주도록 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGZfCrtcI7Ba",
        "outputId": "0f2940cf-eb07-4f9f-c532-f424ca970a5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive words: []\n",
            "Negative words: []\n"
          ]
        }
      ],
      "source": [
        "## 문장에서 단어 감정 추출 예시 ##\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def analyze_sentence(sentence):\n",
        "    # 문장을 토큰화\n",
        "    words = word_tokenize(sentence)\n",
        "\n",
        "    # VADER 초기화\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # 감정이 포함된 단어들 저장\n",
        "    positive_words = []\n",
        "    negative_words = []\n",
        "\n",
        "    # 각 단어의 감정 점수 분석\n",
        "    for word in words:\n",
        "        score = analyzer.polarity_scores(word)['compound']\n",
        "        if score > 0:\n",
        "            positive_words.append(word)\n",
        "        elif score < 0:\n",
        "            negative_words.append(word)\n",
        "\n",
        "    return positive_words, negative_words\n",
        "\n",
        "# 테스트 문장\n",
        "sentence = \"i wouldn't rent this one even on dollar rental night.\"\n",
        "positive_words, negative_words = analyze_sentence(sentence)\n",
        "\n",
        "print(\"Positive words:\", positive_words)\n",
        "print(\"Negative words:\", negative_words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzetDrS4Op6t"
      },
      "source": [
        "\n",
        "## 1.우선 문장을 토큰화하기 전에 감정이 드러난 단어를 찾는다\n",
        "## 2.해당 단어를 버트 토크나이저를 통해 토크나이즈 된 결과를 저장해둔다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CIQbjs9wOs-p"
      },
      "outputs": [],
      "source": [
        "# 데이터 전처리 #\n",
        "import itertools\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = re.sub(r'<[^>]+>', ' ', self.texts[idx])  # HTML 태그 제거\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # 문장을 토큰화하고 감정 점수를 분석\n",
        "        words = word_tokenize(text)\n",
        "        sentiment_words = []\n",
        "        for word in words:\n",
        "            score = self.analyzer.polarity_scores(word)['compound']\n",
        "            if score > 0:\n",
        "                sentiment_words.append(word)\n",
        "            elif score < 0:\n",
        "                sentiment_words.append(word)\n",
        "\n",
        "\n",
        "        # 감정 단어들을 토큰화\n",
        "        tokenized_sentiment_words = []\n",
        "        for word in sentiment_words:\n",
        "            tokenized = self.tokenizer(word, add_special_tokens=False)['input_ids']\n",
        "            tokenized_sentiment_words.append(tokenized) # 토큰화된 감정단어들\n",
        "\n",
        "        # '##' 붙은 서브워드 제거\n",
        "        filtered_tokens = []\n",
        "        for token_ids in tokenized_sentiment_words:\n",
        "            tokens = self.tokenizer.convert_ids_to_tokens(token_ids)\n",
        "            filtered_tokens.extend([token for token in tokens if not token.startswith('##')])\n",
        "\n",
        "        # 토큰들을 하나의 텍스트로 이어붙이기\n",
        "        result_text = ' '.join(filtered_tokens)\n",
        "\n",
        "        # 토큰화 및 인코딩\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze()\n",
        "        attention_mask = encoding['attention_mask'].squeeze()\n",
        "        token_type_ids = encoding['token_type_ids'].squeeze()\n",
        "\n",
        "        if not result_text:\n",
        "            result_text = \"[PAD]\"\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            result_text,\n",
        "            add_special_tokens=False,\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        sentiment_tokens = encoding['input_ids'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'token_type_ids': token_type_ids,\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "            #'sentiment_words' :  sentiment_words,\n",
        "            #'tokenized_sentiment_words' : tokenized_sentiment_words,\n",
        "            \"sentiment_tokens\" :  sentiment_tokens,\n",
        "        }\n",
        "\n",
        "def load_data(file_path, tokenizer, max_length=512):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "    texts = df['review'].tolist()   # 리스트 요소 하나에 풀 문장이 들어있음\n",
        "    labels = df['sentiment'].tolist()\n",
        "    print(texts[0])\n",
        "    train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=38)\n",
        "    print(train_texts[0])\n",
        "\n",
        "    train_dataset = SentimentDataset(train_texts, train_labels, tokenizer, max_length)\n",
        "    val_dataset = SentimentDataset(val_texts, val_labels, tokenizer, max_length)\n",
        "\n",
        "    return train_dataset, val_dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPKCGzikOsnP"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuK6Nz5JO1ip",
        "outputId": "7e018858-8763-4076-d79e-5712d3a84f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
            "as a former TV editor, I can say this is as authentic as it gets. It even led to Letterman's producer (thought to be a source) resigning (eventually) in real life. Letterman was outraged (OK, so one goofy thing is it has him throwing softballs at a tire swing on his estate; total fabrication) but the main information is hilariously true, from the silly bidding war for Letterman once he decided to leave NBC to Leno's problems with an agent who was not ready for big time, but who he let run the show (almost to a disastrous exit) out of his famed loyalty. If any of you kids don't grasp the idea of why Letterman is jealous to this day, see this tape.\n"
          ]
        }
      ],
      "source": [
        "# 토크나이저 초기화\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# 데이터 로드\n",
        "train_dataset, val_dataset = load_data(file_path, tokenizer)\n",
        "\n",
        "# 데이터 로더 생성\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIJy9bbke-7H",
        "outputId": "5b8bf833-6eb2-444f-b9d6-5a6f6f0adca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([  101,  1045,  1005,  1049,  1037,  5187,  2095,  1011,  2214,  2267,\n",
            "         2934,  1012,  1045,  2253,  2007,  2026,  2564,  1998,  2260,  2095,\n",
            "         2214,  2684,  1012,  2057,  2035,  5632,  1996,  3185,  1012,  1996,\n",
            "         2143,  2003,  2434,  1010, 25591,  1010,  3435,  1011, 13823,  1998,\n",
            "         6135, 11951,  1012,  1996,  5436,  2001,  3733,  2438,  2005,  1037,\n",
            "         2184,  2095,  2214,  2000,  3582,  1010,  2021,  9792,  2100,  2438,\n",
            "         2000,  2562,  2019,  4639,  4699,  1012,  1045,  2245,  5616,  7031,\n",
            "         2106,  1037, 21688,  3105,  1998,  1996,  2717,  1997,  1996,  3459,\n",
            "         2001,  2074,  2986,  1012,  2026,  2069,  6256,  2003,  2008,  1996,\n",
            "         3050,  3349,  4520,  2020,  2025,  2004,  5875,  2004,  2027,  2323,\n",
            "         2031,  2042,  1012,  2027,  2020,  8360,  1010,  2021,  2498,  2768,\n",
            "         2041,  1012,  2006,  1996,  2060,  2192,  1010,  2191,  1011,  2039,\n",
            "         1010,  9427,  1010,  7497,  1010, 16434,  1010,  9260,  1998,  9855,\n",
            "         2020,  6581,  1012, 10462,  1010,  1045,  2245,  2009,  2001,  1037,\n",
            "         6135, 22249,  3325,  1012,  1045,  2572,  9364,  2008,  1996,  2658,\n",
            "         4401,  1006,  2471,  2035,  4639,  3767,  1007,  9576,  2135,  4457,\n",
            "         1996,  2143,  1012,  4593,  1010,  2027,  2031,  2242,  2114,  3152,\n",
            "         2008, 17279,  2844,  1010,  9414,  1998,  2981,  2402,  2308,  1012,\n",
            "         2037,  7896,  7487,  2062,  2055,  2037,  2219,  3348,  2923,  3267,\n",
            "         2015,  2084,  2505,  2055,  2023,  6919,  2155,  2143,  1012,  1045,\n",
            "        16755,  2009,  6118,  2000,  2296,  2775,  1998,  2296,  6687,  1012,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(1), 'sentiment_tokens': tensor([ 5632,  2434, 11951,  3733,  4699, 21688,  2986,  6256,  5875,  2192,\n",
            "         6581, 22249,  9364,  4401,  9576,  4457,  2844,  9414,  6919, 16755,\n",
            "         6118,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])}\n",
            "i wouldn't rent this one even on dollar rental night.\n"
          ]
        }
      ],
      "source": [
        "# 데이터셋 전체에서 가장 짧은 길이를 찾는 코드\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# 사전 학습된 BERT 토크나이저 로드\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "# 각 항목의 길이를 저장할 딕셔너리 초기화\n",
        "\n",
        "\n",
        "\n",
        "print(train_dataset[4891])\n",
        "input_ids = torch.tensor([101, 1045, 2876, 1005, 1056, 9278, 2023, 2028, 2130, 2006,\n",
        "                          7922, 12635, 2305, 1012, 102, 0, 0, 0, 0, 0,])\n",
        "decoded_text = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
        "\n",
        "# 결과 출력\n",
        "print(decoded_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "xnF-HxEmERu7",
        "outputId": "99dd3c64-e0e8-47f6-8b36-3d7310aeb180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample text: Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.<br /><br />The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.<br /><br />The acting is good under Mr. Mattei's direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.<br /><br />We wish Mr. Mattei good luck and await anxiously for his next work.\n",
            "Tokenized input IDs: [101, 2023, 3185, 2003, 2241, 2006, 1996, 2338, 1010, 1000, 1037, 2116, 11867, 7770, 7983, 2098, 2518, 1000, 2011, 7658, 10514, 25811, 1998, 10455, 3314, 1997, 2679, 4262, 2090, 4004, 2015, 1998, 12461, 1010, 1037, 8476, 2008, 3310, 2013, 7658, 1005, 1055, 3167, 6322, 2004, 2019, 23399, 3652, 2039, 1999, 2859, 1012, 2008, 4281, 1010, 1998, 1996, 3376, 4291, 4290, 10906, 1010, 3957, 2023, 2293, 2466, 1037, 4310, 1998, 2738, 15236, 7224, 2005, 2049, 2051, 1012, 2060, 2084, 2008, 1010, 1996, 2466, 2003, 1037, 12991, 27086, 7472, 2007, 1037, 13432, 2299, 2008, 2003, 3383, 2062, 4622, 2084, 1996, 3185, 2993, 1012, 1996, 3376, 7673, 3557, 3504, 1996, 2112, 1998, 3957, 1037, 6919, 1010, 7436, 4222, 2836, 2004, 1037, 3460, 1997, 3816, 8843, 2076, 1996, 13896, 1997, 15523, 1999, 8240, 2859, 1012, 2520, 9988, 2196, 2246, 2488, 2652, 1037, 6298, 2599, 2004, 1037, 4988, 5266, 2162, 7950, 4655, 1999, 1996, 2088, 1012, 1996, 3772, 2003, 2327, 18624, 1010, 1998, 1996, 6370, 2090, 1996, 2048, 10205, 3640, 2005, 2070, 10218, 5312, 1997, 3165, 3898, 12242, 2469, 2000, 14899, 1996, 8072, 1997, 2216, 2040, 2024, 6298, 3973, 13050, 1012, 1996, 16434, 2428, 7545, 2041, 5595, 1005, 1055, 4291, 4290, 1010, 2926, 1996, 25566, 12549, 1996, 6496, 2073, 1996, 2048, 10205, 5247, 2037, 2087, 10305, 5312, 1012, 1996, 4566, 2003, 1037, 2613, 7697, 1011, 12181, 2121, 1012, 2070, 2089, 5136, 23069, 7472, 2015, 3413, 2063, 1010, 2021, 1010, 2005, 2216, 2040, 5959, 4438, 5365, 2293, 3441, 1010, 2023, 2003, 1037, 9716, 2742, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Tokenized tokens: ['[CLS]', 'this', 'movie', 'is', 'based', 'on', 'the', 'book', ',', '\"', 'a', 'many', 'sp', '##len', '##dor', '##ed', 'thing', '\"', 'by', 'han', 'su', '##yin', 'and', 'tackles', 'issues', 'of', 'race', 'relations', 'between', 'asian', '##s', 'and', 'whites', ',', 'a', 'topic', 'that', 'comes', 'from', 'han', \"'\", 's', 'personal', 'experiences', 'as', 'an', 'eurasian', 'growing', 'up', 'in', 'china', '.', 'that', 'background', ',', 'and', 'the', 'beautiful', 'hong', 'kong', 'settings', ',', 'gives', 'this', 'love', 'story', 'a', 'unique', 'and', 'rather', 'daring', 'atmosphere', 'for', 'its', 'time', '.', 'other', 'than', 'that', ',', 'the', 'story', 'is', 'a', 'stereo', '##typical', 'romance', 'with', 'a', 'memorable', 'song', 'that', 'is', 'perhaps', 'more', 'remembered', 'than', 'the', 'movie', 'itself', '.', 'the', 'beautiful', 'jennifer', 'jones', 'looks', 'the', 'part', 'and', 'gives', 'a', 'wonderful', ',', 'oscar', 'nominated', 'performance', 'as', 'a', 'doctor', 'of', 'mixed', 'breed', 'during', 'the', 'advent', 'of', 'communism', 'in', 'mainland', 'china', '.', 'william', 'holden', 'never', 'looked', 'better', 'playing', 'a', 'romantic', 'lead', 'as', 'a', 'journalist', 'covering', 'war', 'torn', 'regions', 'in', 'the', 'world', '.', 'the', 'acting', 'is', 'top', 'notch', ',', 'and', 'the', 'chemistry', 'between', 'the', 'two', 'lovers', 'provides', 'for', 'some', 'genuine', 'moments', 'of', 'silver', 'screen', 'affection', 'sure', 'to', 'melt', 'the', 'hearts', 'of', 'those', 'who', 'are', 'romantic', '##ally', 'inclined', '.', 'the', 'cinematography', 'really', 'brings', 'out', 'fifty', \"'\", 's', 'hong', 'kong', ',', 'especially', 'the', 'hilltop', 'overlooking', 'the', 'harbor', 'where', 'the', 'two', 'lovers', 'spend', 'their', 'most', 'intimate', 'moments', '.', 'the', 'ending', 'is', 'a', 'real', 'tear', '-', 'jerk', '##er', '.', 'some', 'may', 'consider', 'sentimental', 'romance', '##s', 'pass', '##e', ',', 'but', ',', 'for', 'those', 'who', 'enjoy', 'classic', 'hollywood', 'love', 'stories', ',', 'this', 'is', 'a', 'shining', 'example', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "Tokenized attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Tokenized token type IDs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Label: 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'sentiment_words'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-2a3d077dada6>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tokenized token type IDs:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Label:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sentiment_words:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment_words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tokenized sentiment words:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized_sentiment_words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'sentiment_words'"
          ]
        }
      ],
      "source": [
        "    ## 예시 확인하기 ##\n",
        "df = pd.read_csv(file_path)\n",
        "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "texts = df['review'].tolist()\n",
        "labels = df['sentiment'].tolist()\n",
        "dataset = SentimentDataset(texts, labels, tokenizer, 512)\n",
        "\"\"\"\n",
        "            input_ids=batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask'],\n",
        "            token_type_ids=batch['token_type_ids'],\n",
        "            labels=batch['labels'],\n",
        "            sentiment_tokens=batch['sentiment_tokens']\n",
        "\"\"\"\n",
        "print(\"Sample text:\", texts[3])\n",
        "sample_item = dataset[19]\n",
        "print(\"Tokenized input IDs:\", sample_item['input_ids'].tolist())\n",
        "print(\"Tokenized tokens:\", tokenizer.convert_ids_to_tokens(sample_item['input_ids'].tolist()))\n",
        "print(\"Tokenized attention mask:\", sample_item['attention_mask'].tolist())\n",
        "print(\"Tokenized token type IDs:\", sample_item['token_type_ids'].tolist())\n",
        "print(\"Label:\", sample_item['labels'].item())\n",
        "print('sentiment_words:', sample_item['sentiment_words'])\n",
        "print('Tokenized sentiment words:',sample_item['tokenized_sentiment_words'])\n",
        "\n",
        "# 토큰화된 감정 단어들 출력\n",
        "tokenized_sentiment_words = sample_item['tokenized_sentiment_words']\n",
        "all_tokens = []\n",
        "filtered_all_tokens = []\n",
        "\n",
        "for token_ids in tokenized_sentiment_words:\n",
        "        tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
        "        filtered_tokens = [token for token in tokens if not token.startswith('##')]\n",
        "        filtered_all_tokens.append(filtered_tokens)\n",
        "        all_tokens.append(tokens)\n",
        "\n",
        "print('## removed Tokenized sentiment words :', filtered_all_tokens)\n",
        "print(len(sample_item['input_ids']))\n",
        "print(len(sample_item['attention_mask']))\n",
        "print(len(sample_item['token_type_ids']))\n",
        "print(len(sample_item[\"attention_mask\"]))\n",
        "print(len(sample_item[\"sentiment_tokens\"]))\n",
        "    ##===============##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8RxEd2bIQyQ1"
      },
      "outputs": [],
      "source": [
        "# [모델 준비] #\n",
        "\n",
        "# 활성화 함수\n",
        "def gelu(x):\n",
        "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
        "\n",
        "# 활성화 함수 매핑\n",
        "ACT2FN = {\"gelu\": gelu, \"relu\": torch.nn.functional.relu, \"swish\": torch.nn.functional.silu}\n",
        "\n",
        "# 모델 설정\n",
        "\n",
        "class BertEmbeddings(nn.Module):\n",
        "    def __init__(self, config):\n",
        "    #def __init__(self, config: Config, sentiment_ratio_init: float = 1.5):\n",
        "        super().__init__()\n",
        "        # 단어 임베딩, 위치 임베딩, 토큰 타입 임베딩\n",
        "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)\n",
        "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
        "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
        "\n",
        "        # 레이어 정규화와 드롭아웃\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.position_embedding_type = getattr(config, \"position_embedding_type\", \"absolute\")\n",
        "        self.register_buffer(\"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)), persistent=False)\n",
        "        self.register_buffer(\"token_type_ids\", torch.zeros(self.position_ids.size(), dtype=torch.long), persistent=False)\n",
        "\n",
        "        # 학습 가능한 sentiment_ratio 파라미터 추가 및 초기값 설정\n",
        "        #self.sentiment_ratio = nn.Parameter(torch.tensor(sentiment_ratio_init))\n",
        "\n",
        "    def forward(self, input_ids=None, token_type_ids=None, position_ids=None, inputs_embeds=None, past_key_values_length=0, sentiment_tokens=None):\n",
        "        if input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "        else:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "\n",
        "        seq_length = input_shape[1]\n",
        "\n",
        "        if position_ids is None:\n",
        "            position_ids = self.position_ids[:, past_key_values_length: seq_length + past_key_values_length]\n",
        "\n",
        "        if token_type_ids is None:\n",
        "            if hasattr(self, \"token_type_ids\"):\n",
        "                buffered_token_type_ids = self.token_type_ids[:, :seq_length]\n",
        "                buffered_token_type_ids_expanded = buffered_token_type_ids.expand(input_shape[0], seq_length)\n",
        "                token_type_ids = buffered_token_type_ids_expanded\n",
        "            else:\n",
        "                token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.position_ids.device)\n",
        "\n",
        "        if inputs_embeds is None:\n",
        "            inputs_embeds = self.word_embeddings(input_ids)\n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "\n",
        "        # 입력 임베딩 생성\n",
        "        embeddings = inputs_embeds + token_type_embeddings\n",
        "\n",
        "        for i in range(input_ids.size(0)):  # 배치의 각 문장에 대해\n",
        "            sentiment_token = sentiment_tokens[i]\n",
        "            sentiment_token_filtered = sentiment_token[(sentiment_token != 0) & (sentiment_token != 101) & (sentiment_token != 102)]\n",
        "            for j in range(input_ids.size(1)):  # 각 문장의 각 토큰에 대해\n",
        "                if input_ids[i, j] in sentiment_token_filtered:\n",
        "                    # 파라미터로 사용시\n",
        "                    #embeddings[i, j] = self.sentiment_ratio * inputs_embeds[i, j] + token_type_embeddings[i, j]\n",
        "                    #print(\"sentiment token ratio : \",self.sentiment_ratio)\n",
        "                #if j == 0 and i == 0:\n",
        "                    #print(\"Sentiment ratio for this batch: \", self.sentiment_ratio.item())\n",
        "                    # 정해줄 때\n",
        "                    embeddings[i, j] = 2 * inputs_embeds[i, j] + token_type_embeddings[i, j]\n",
        "\n",
        "        if self.position_embedding_type == \"absolute\":\n",
        "            position_embeddings = self.position_embeddings(position_ids)\n",
        "            embeddings += position_embeddings\n",
        "\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "# 셀프 어텐션 구현 클래스\n",
        "class BertSelfAttention(nn.Module):\n",
        "    def __init__(self, config, position_embedding_type=None):\n",
        "        super().__init__()\n",
        "        # hidden_size가 num_attention_heads의 배수가 아니면 오류 발생\n",
        "        if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n",
        "                f\"heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "\n",
        "        # 어텐션 헤드의 수와 각 헤드의 크기, 전체 헤드 크기 설정\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(\n",
        "            config.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        # Query, Key, Value 행렬 정의\n",
        "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "\n",
        "        # 드롭아웃 레이어 정의\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        # 위치 임베딩 유형 설정\n",
        "        self.position_embedding_type = position_embedding_type or getattr(\n",
        "            config, \"position_embedding_type\", \"absolute\"\n",
        "        )\n",
        "        # 상대적 위치 임베딩을 사용하는 경우, 위치 임베딩 레이어 정의\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            self.max_position_embeddings = config.max_position_embeddings\n",
        "            self.distance_embedding = nn.Embedding(\n",
        "                2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
        "\n",
        "        # 디코더인지 여부 설정\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # 텐서의 크기 변환\n",
        "        new_x_shape = x.size()[\n",
        "            :-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(new_x_shape)\n",
        "        # 텐서의 차원 변경 [batch_size, num_heads, seq_len, head_size]\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        # Query 레이어 계산\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        # 크로스 어텐션인지 여부 확인\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention and past_key_value is not None:\n",
        "            # 과거의 k, v 값을 재사용 (크로스 어텐션)\n",
        "            key_layer = past_key_value[0]\n",
        "            value_layer = past_key_value[1]\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif is_cross_attention:\n",
        "            # 인코더의 키와 값을 사용하여 크로스 어텐션 수행\n",
        "            key_layer = self.transpose_for_scores(\n",
        "                self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(\n",
        "                self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif past_key_value is not None:\n",
        "            # 과거의 k, v 값을 현재의 k, v와 결합 (디코더의 셀프 어텐션)\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "            key_layer = torch.cat([past_key_value[0], key_layer], dim=2)\n",
        "            value_layer = torch.cat([past_key_value[1], value_layer], dim=2)\n",
        "        else:\n",
        "            # 현재의 히든 스테이트에서 키와 값을 계산 (셀프 어텐션)\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        # Query 레이어 변환\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # 캐시를 사용할지 여부 설정\n",
        "        use_cache = past_key_value is not None\n",
        "        if self.is_decoder:\n",
        "            # 디코더인 경우, 키와 값을 캐싱\n",
        "            past_key_value = (key_layer, value_layer)\n",
        "\n",
        "        # Query와 Key의 내적(dot product)을 통해 어텐션 스코어 계산\n",
        "        attention_scores = torch.matmul(\n",
        "            query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            # 상대적 위치 임베딩을 사용하는 경우\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(\n",
        "                    query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(\n",
        "                key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            # 거리 임베딩 계산\n",
        "            positional_embedding = self.distance_embedding(\n",
        "                distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(\n",
        "                dtype=query_layer.dtype)  # fp16 호환성\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                # 상대적 위치 임베딩을 쿼리에 적용\n",
        "                relative_position_scores = torch.einsum(\n",
        "                    \"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                # 상대적 위치 임베딩을 쿼리와 키에 적용\n",
        "                relative_position_scores_query = torch.einsum(\n",
        "                    \"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\n",
        "                    \"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + \\\n",
        "                    relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        # 어텐션 스코어를 정규화\n",
        "        attention_scores = attention_scores / \\\n",
        "            math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            # 어텐션 마스크 적용\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # 어텐션 스코어를 확률로 변환\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # 드롭아웃 적용\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # 헤드 마스크 적용\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        # 컨텍스트 레이어 계산\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        # 텐서의 크기 변환 및 재배치\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[\n",
        "            :-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        # 출력 생성\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (\n",
        "            context_layer,)\n",
        "\n",
        "        # 디코더인 경우, past_key_value를 출력에 포함\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "# 셀프 어텐션 출력 처리 클래스\n",
        "class BertSelfOutput(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        # 드롭아웃, 레이어 정규화, 잔차 연결 적용\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "\n",
        "# 어텐션 메커니즘 클래스\n",
        "class BertAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.self = BertSelfAttention(config)\n",
        "        self.output = BertSelfOutput(config)\n",
        "\n",
        "    def forward(self, input_tensor, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_value=None, output_attentions=False):\n",
        "        # 셀프 어텐션 및 출력 계산\n",
        "        self_outputs = self.self(\n",
        "            input_tensor,\n",
        "            attention_mask,\n",
        "            head_mask,\n",
        "            encoder_hidden_states,\n",
        "            encoder_attention_mask,\n",
        "            past_key_value,\n",
        "            output_attentions,\n",
        "        )\n",
        "        attention_output = self.output(self_outputs[0], input_tensor)\n",
        "        outputs = (attention_output,) + self_outputs[1:]\n",
        "        return outputs\n",
        "\n",
        "# 중간 레이어 활성화 함수 클래스\n",
        "class BertIntermediate(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
        "        self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        # 중간 레이어 활성화 함수 적용\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "# 중간 레이어 출력 처리 클래스\n",
        "class BertOutput(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        # 드롭아웃, 레이어 정규화, 잔차 연결 적용\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.Layer\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        # 드롭아웃, 레이어 정규화, 잔차 연결 적용\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "\n",
        "# 하나의 BERT 레이어를 구현하는 클래스\n",
        "class BertLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.attention = BertAttention(config)\n",
        "        self.intermediate = BertIntermediate(config)\n",
        "        self.output = BertOutput(config)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_value=None, output_attentions=False):\n",
        "        # 어텐션과 출력 계산\n",
        "        self_attention_outputs = self.attention(\n",
        "            hidden_states,\n",
        "            attention_mask,\n",
        "            head_mask,\n",
        "            encoder_hidden_states,\n",
        "            encoder_attention_mask,\n",
        "            past_key_value,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        attention_output = self_attention_outputs[0]\n",
        "        layer_output = self.output(self.intermediate(attention_output), attention_output)\n",
        "        outputs = (layer_output,) + self_attention_outputs[1:]\n",
        "        return outputs\n",
        "\n",
        "# 여러 BERT 레이어를 포함하는 인코더 클래스\n",
        "class BertEncoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_values=None, use_cache=None, output_attentions=False, output_hidden_states=False, return_dict=True):\n",
        "        all_hidden_states = () if output_hidden_states else None\n",
        "        all_attentions = () if output_attentions else None\n",
        "        for i, layer_module in enumerate(self.layer):\n",
        "            layer_head_mask = head_mask[i] if head_mask is not None else None\n",
        "            past_key_value = past_key_values[i] if past_key_values is not None else None\n",
        "\n",
        "            if output_hidden_states:\n",
        "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "            layer_outputs = layer_module(\n",
        "                hidden_states,\n",
        "                attention_mask,\n",
        "                layer_head_mask,\n",
        "                encoder_hidden_states,\n",
        "                encoder_attention_mask,\n",
        "                past_key_value,\n",
        "                output_attentions,\n",
        "            )\n",
        "            hidden_states = layer_outputs[0]\n",
        "\n",
        "            if output_attentions:\n",
        "                all_attentions = all_attentions + (layer_outputs[1],)\n",
        "\n",
        "        return (hidden_states, all_hidden_states, all_attentions)\n",
        "\n",
        "# 첫 번째 토큰의 출력을 풀링하는 클래스\n",
        "class BertPooler(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        # 첫 번째 토큰의 텐서를 사용해 풀링 출력 생성\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        pooled_output = self.dense(first_token_tensor)\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "        return pooled_output\n",
        "\n",
        "# 전체 BERT 모델을 구현하는 클래스\n",
        "class  userBertModel(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.embeddings = BertEmbeddings(config)\n",
        "        self.encoder = BertEncoder(config)\n",
        "        self.pooler = BertPooler(config)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_values=None, use_cache=None, output_attentions=None, output_hidden_states=None, return_dict=None, sentiment_tokens=None):\n",
        "        # 입력 텐서의 크기 확인\n",
        "        if input_ids is not None and inputs_embeds is not None:\n",
        "            raise ValueError(\"input_ids 혹은 inputs_embeds 둘 중 하나의 형식으로만 입력해야 합니다.\")\n",
        "        elif input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "        elif inputs_embeds is not None:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "        else:\n",
        "            raise ValueError(\"input_ids 또는 inputs_embeds의 형식이어야 합니다.\")\n",
        "\n",
        "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones(input_shape, device=device)\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "\n",
        "        extended_attention_mask = attention_mask[:, None, None, :]\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype)\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "\n",
        "        head_mask = [None] * self.config.num_hidden_layers\n",
        "\n",
        "        # 임베딩 출력 계산\n",
        "        embedding_output = self.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            position_ids=position_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            sentiment_tokens= sentiment_tokens,\n",
        "        )\n",
        "        # 인코더 출력 계산\n",
        "        encoder_outputs = self.encoder(\n",
        "            embedding_output,\n",
        "            attention_mask=extended_attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states=encoder_hidden_states,\n",
        "            encoder_attention_mask=encoder_attention_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        sequence_output = encoder_outputs[0]\n",
        "        pooled_output = self.pooler(sequence_output)\n",
        "        return sequence_output, pooled_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAXhMfNkYbth"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "94d00694401d41f58f2a5f03c7b8139f",
            "efe9921f88924088bd22a79bf43c75b8",
            "a66a24be74144c948e0b7bc02602caf5",
            "00cf4a2c1b164735a92d7e744ba1e357",
            "bda6df433b9d4509b6cde476b7e9b577",
            "3b4987e1ed6441b2b647bf7ae75895ae",
            "ea01c634fe6945fca4429136823111be",
            "908f512331534b81ac65b5087b10855c",
            "2697617546794945a35dc123a2aca62c",
            "0073179d5f194c2f825c9ab7384cadf1",
            "23984d212de04b00915f585ebb2f41fa"
          ]
        },
        "id": "5aTojxNkPIxO",
        "outputId": "1b5722b2-24fb-40e7-c7bb-876868a619f3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94d00694401d41f58f2a5f03c7b8139f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, Batch: 0, Loss: 0.679661214351654, Accuracy: 0.5625\n",
            "Epoch: 0, Batch: 10, Loss: 0.7008840441703796, Accuracy: 0.5056818181818182\n",
            "Epoch: 0, Batch: 20, Loss: 0.6519335508346558, Accuracy: 0.5267857142857143\n",
            "Epoch: 0, Batch: 30, Loss: 0.7410391569137573, Accuracy: 0.5100806451612904\n",
            "Epoch: 0, Batch: 40, Loss: 0.7059527039527893, Accuracy: 0.5030487804878049\n",
            "Epoch: 0, Batch: 50, Loss: 0.6866894364356995, Accuracy: 0.5171568627450981\n",
            "Epoch: 0, Batch: 60, Loss: 0.679564356803894, Accuracy: 0.5276639344262295\n",
            "Epoch: 0, Batch: 70, Loss: 0.6668288707733154, Accuracy: 0.534330985915493\n",
            "Epoch: 0, Batch: 80, Loss: 0.6639005541801453, Accuracy: 0.5439814814814815\n",
            "Epoch: 0, Batch: 90, Loss: 0.6206547617912292, Accuracy: 0.5508241758241759\n",
            "Epoch: 0, Batch: 100, Loss: 0.6593377590179443, Accuracy: 0.5618811881188119\n",
            "Epoch: 0, Batch: 110, Loss: 0.6594498157501221, Accuracy: 0.5675675675675675\n",
            "Epoch: 0, Batch: 120, Loss: 0.5725579261779785, Accuracy: 0.5769628099173554\n",
            "Epoch: 0, Batch: 130, Loss: 0.5526071190834045, Accuracy: 0.5858778625954199\n",
            "Epoch: 0, Batch: 140, Loss: 0.6578570008277893, Accuracy: 0.5944148936170213\n",
            "Epoch: 0, Batch: 150, Loss: 0.6410568356513977, Accuracy: 0.5972682119205298\n",
            "Epoch: 0, Batch: 160, Loss: 0.5445268750190735, Accuracy: 0.6028726708074534\n",
            "Epoch: 0, Batch: 170, Loss: 0.710801362991333, Accuracy: 0.6118421052631579\n",
            "Epoch: 0, Batch: 180, Loss: 0.5769819617271423, Accuracy: 0.6215469613259669\n",
            "Epoch: 0, Batch: 190, Loss: 0.45924097299575806, Accuracy: 0.6282722513089005\n",
            "Epoch: 0, Batch: 200, Loss: 0.3716064691543579, Accuracy: 0.6383706467661692\n",
            "Epoch: 0, Batch: 210, Loss: 0.4003288447856903, Accuracy: 0.6442535545023697\n",
            "Epoch: 0, Batch: 220, Loss: 0.4630070626735687, Accuracy: 0.6515837104072398\n",
            "Epoch: 0, Batch: 230, Loss: 0.3772852420806885, Accuracy: 0.6601731601731602\n",
            "Epoch: 0, Batch: 240, Loss: 0.25088441371917725, Accuracy: 0.6664937759336099\n",
            "Epoch: 0, Batch: 250, Loss: 0.6090992093086243, Accuracy: 0.670816733067729\n",
            "Epoch: 0, Batch: 260, Loss: 0.6927843689918518, Accuracy: 0.6745689655172413\n",
            "Epoch: 0, Batch: 270, Loss: 0.4923195540904999, Accuracy: 0.6805811808118081\n",
            "Epoch: 0, Batch: 280, Loss: 0.24170000851154327, Accuracy: 0.6861654804270463\n",
            "Epoch: 0, Batch: 290, Loss: 0.37075158953666687, Accuracy: 0.6928694158075601\n",
            "Epoch: 0, Batch: 300, Loss: 0.3713214099407196, Accuracy: 0.6972591362126246\n",
            "Epoch: 0, Batch: 310, Loss: 0.3646436333656311, Accuracy: 0.7007636655948553\n",
            "Epoch: 0, Batch: 320, Loss: 0.40692299604415894, Accuracy: 0.705607476635514\n",
            "Epoch: 0, Batch: 330, Loss: 0.20281048119068146, Accuracy: 0.7082703927492447\n",
            "Epoch: 0, Batch: 340, Loss: 0.2926410138607025, Accuracy: 0.7131598240469208\n",
            "Epoch: 0, Batch: 350, Loss: 0.27389517426490784, Accuracy: 0.7167022792022792\n",
            "Epoch: 0, Batch: 360, Loss: 0.20939478278160095, Accuracy: 0.7221260387811634\n",
            "Epoch: 0, Batch: 370, Loss: 0.6606806516647339, Accuracy: 0.7247304582210242\n",
            "Epoch: 0, Batch: 380, Loss: 0.36107295751571655, Accuracy: 0.7276902887139107\n",
            "Epoch: 0, Batch: 390, Loss: 0.18875068426132202, Accuracy: 0.731457800511509\n",
            "Epoch: 0, Batch: 400, Loss: 0.26661771535873413, Accuracy: 0.7359725685785536\n",
            "Epoch: 0, Batch: 410, Loss: 0.29609134793281555, Accuracy: 0.7387469586374696\n",
            "Epoch: 0, Batch: 420, Loss: 0.17801986634731293, Accuracy: 0.7415380047505938\n",
            "Epoch: 0, Batch: 430, Loss: 0.30147436261177063, Accuracy: 0.7434744779582366\n",
            "Epoch: 0, Batch: 440, Loss: 0.3537937104701996, Accuracy: 0.7461734693877551\n",
            "Epoch: 0, Batch: 450, Loss: 0.2398720383644104, Accuracy: 0.7477827050997783\n",
            "Epoch: 0, Batch: 460, Loss: 0.26336467266082764, Accuracy: 0.7504067245119306\n",
            "Epoch: 0, Batch: 470, Loss: 0.500090479850769, Accuracy: 0.7525212314225053\n",
            "Epoch: 0, Batch: 480, Loss: 0.39225560426712036, Accuracy: 0.7548076923076923\n",
            "Epoch: 0, Batch: 490, Loss: 0.5104867815971375, Accuracy: 0.757764765784114\n",
            "Epoch: 0, Batch: 500, Loss: 0.3391000032424927, Accuracy: 0.7601047904191617\n",
            "Epoch: 0, Batch: 510, Loss: 0.1975737065076828, Accuracy: 0.7625978473581213\n",
            "Epoch: 0, Batch: 520, Loss: 0.2893356680870056, Accuracy: 0.7651151631477927\n",
            "Epoch: 0, Batch: 530, Loss: 0.3898584246635437, Accuracy: 0.7675376647834274\n",
            "Epoch: 0, Batch: 540, Loss: 0.5693665146827698, Accuracy: 0.7688308687615527\n",
            "Epoch: 0, Batch: 550, Loss: 0.1982673555612564, Accuracy: 0.7708711433756806\n",
            "Epoch: 0, Batch: 560, Loss: 0.23520323634147644, Accuracy: 0.7725044563279857\n",
            "Epoch: 0, Batch: 570, Loss: 0.2066543847322464, Accuracy: 0.7740805604203153\n",
            "Epoch: 0, Batch: 580, Loss: 0.691223680973053, Accuracy: 0.7757099827882961\n",
            "Epoch: 0, Batch: 590, Loss: 0.23628896474838257, Accuracy: 0.7773900169204738\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 1/3 [3:22:01<6:44:02, 12121.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 finished with average loss: 0.4495629571129878, Accuracy: 0.7785416666666667\n",
            "Epoch: 1, Batch: 0, Loss: 0.582271933555603, Accuracy: 0.75\n",
            "Epoch: 1, Batch: 10, Loss: 0.12640482187271118, Accuracy: 0.8977272727272727\n",
            "Epoch: 1, Batch: 20, Loss: 0.38699817657470703, Accuracy: 0.8928571428571429\n",
            "Epoch: 1, Batch: 30, Loss: 0.145876944065094, Accuracy: 0.8931451612903226\n",
            "Epoch: 1, Batch: 40, Loss: 0.3985311686992645, Accuracy: 0.8826219512195121\n",
            "Epoch: 1, Batch: 50, Loss: 0.22949635982513428, Accuracy: 0.883578431372549\n",
            "Epoch: 1, Batch: 60, Loss: 0.2248372584581375, Accuracy: 0.8842213114754098\n",
            "Epoch: 1, Batch: 70, Loss: 0.2869960069656372, Accuracy: 0.8802816901408451\n",
            "Epoch: 1, Batch: 80, Loss: 0.19169826805591583, Accuracy: 0.8842592592592593\n",
            "Epoch: 1, Batch: 90, Loss: 0.23804934322834015, Accuracy: 0.8887362637362637\n",
            "Epoch: 1, Batch: 100, Loss: 0.09635545313358307, Accuracy: 0.8873762376237624\n",
            "Epoch: 1, Batch: 110, Loss: 0.41928941011428833, Accuracy: 0.8885135135135135\n",
            "Epoch: 1, Batch: 120, Loss: 0.3030090928077698, Accuracy: 0.8920454545454546\n",
            "Epoch: 1, Batch: 130, Loss: 0.052868038415908813, Accuracy: 0.8912213740458015\n",
            "Epoch: 1, Batch: 140, Loss: 0.2108645737171173, Accuracy: 0.8940602836879432\n",
            "Epoch: 1, Batch: 150, Loss: 0.22636722028255463, Accuracy: 0.8927980132450332\n",
            "Epoch: 1, Batch: 160, Loss: 0.46771174669265747, Accuracy: 0.8893633540372671\n",
            "Epoch: 1, Batch: 170, Loss: 0.6133041381835938, Accuracy: 0.8863304093567251\n",
            "Epoch: 1, Batch: 180, Loss: 0.5052301287651062, Accuracy: 0.8867403314917127\n",
            "Epoch: 1, Batch: 190, Loss: 0.31819355487823486, Accuracy: 0.8890706806282722\n",
            "Epoch: 1, Batch: 200, Loss: 0.17651498317718506, Accuracy: 0.8905472636815921\n",
            "Epoch: 1, Batch: 210, Loss: 0.16882185637950897, Accuracy: 0.8877369668246445\n",
            "Epoch: 1, Batch: 220, Loss: 0.39277294278144836, Accuracy: 0.8880090497737556\n",
            "Epoch: 1, Batch: 230, Loss: 0.42577123641967773, Accuracy: 0.8887987012987013\n",
            "Epoch: 1, Batch: 240, Loss: 0.10485281050205231, Accuracy: 0.8892634854771784\n",
            "Epoch: 1, Batch: 250, Loss: 0.42460596561431885, Accuracy: 0.889691235059761\n",
            "Epoch: 1, Batch: 260, Loss: 0.3558618724346161, Accuracy: 0.8896072796934866\n",
            "Epoch: 1, Batch: 270, Loss: 0.24394284188747406, Accuracy: 0.889990774907749\n",
            "Epoch: 1, Batch: 280, Loss: 0.1384449303150177, Accuracy: 0.8894572953736655\n",
            "Epoch: 1, Batch: 290, Loss: 0.19567398726940155, Accuracy: 0.8902491408934707\n",
            "Epoch: 1, Batch: 300, Loss: 0.12494976818561554, Accuracy: 0.8916112956810631\n",
            "Epoch: 1, Batch: 310, Loss: 0.19492945075035095, Accuracy: 0.8928858520900321\n",
            "Epoch: 1, Batch: 320, Loss: 0.3140377700328827, Accuracy: 0.8940809968847352\n",
            "Epoch: 1, Batch: 330, Loss: 0.1297612190246582, Accuracy: 0.8935045317220544\n",
            "Epoch: 1, Batch: 340, Loss: 0.2671487331390381, Accuracy: 0.8942448680351907\n",
            "Epoch: 1, Batch: 350, Loss: 0.0815703272819519, Accuracy: 0.8938746438746439\n",
            "Epoch: 1, Batch: 360, Loss: 0.09747669845819473, Accuracy: 0.8952562326869806\n",
            "Epoch: 1, Batch: 370, Loss: 0.4946099519729614, Accuracy: 0.8947102425876011\n",
            "Epoch: 1, Batch: 380, Loss: 0.12151029706001282, Accuracy: 0.8948490813648294\n",
            "Epoch: 1, Batch: 390, Loss: 0.14787888526916504, Accuracy: 0.8949808184143222\n",
            "Epoch: 1, Batch: 400, Loss: 0.2145570069551468, Accuracy: 0.8961970074812967\n",
            "Epoch: 1, Batch: 410, Loss: 0.27557504177093506, Accuracy: 0.8972019464720195\n",
            "Epoch: 1, Batch: 420, Loss: 0.06416328996419907, Accuracy: 0.8980106888361045\n",
            "Epoch: 1, Batch: 430, Loss: 0.1382482349872589, Accuracy: 0.8979118329466357\n",
            "Epoch: 1, Batch: 440, Loss: 0.13323627412319183, Accuracy: 0.8981009070294784\n",
            "Epoch: 1, Batch: 450, Loss: 0.04968917369842529, Accuracy: 0.8982815964523282\n",
            "Epoch: 1, Batch: 460, Loss: 0.054129697382450104, Accuracy: 0.898590021691974\n",
            "Epoch: 1, Batch: 470, Loss: 0.3977399468421936, Accuracy: 0.8982218683651805\n",
            "Epoch: 1, Batch: 480, Loss: 0.31716710329055786, Accuracy: 0.8978690228690228\n",
            "Epoch: 1, Batch: 490, Loss: 0.2647037208080292, Accuracy: 0.8989307535641547\n",
            "Epoch: 1, Batch: 500, Loss: 0.2727137506008148, Accuracy: 0.8998253493013972\n",
            "Epoch: 1, Batch: 510, Loss: 0.13887421786785126, Accuracy: 0.9003180039138943\n",
            "Epoch: 1, Batch: 520, Loss: 0.20655538141727448, Accuracy: 0.9006717850287908\n",
            "Epoch: 1, Batch: 530, Loss: 0.26875007152557373, Accuracy: 0.9011299435028248\n",
            "Epoch: 1, Batch: 540, Loss: 0.4610944390296936, Accuracy: 0.9009935304990758\n",
            "Epoch: 1, Batch: 550, Loss: 0.08695527911186218, Accuracy: 0.9015426497277677\n",
            "Epoch: 1, Batch: 560, Loss: 0.1731080859899521, Accuracy: 0.901403743315508\n",
            "Epoch: 1, Batch: 570, Loss: 0.17661915719509125, Accuracy: 0.9018169877408057\n",
            "Epoch: 1, Batch: 580, Loss: 0.700279951095581, Accuracy: 0.9017857142857143\n",
            "Epoch: 1, Batch: 590, Loss: 0.2218032330274582, Accuracy: 0.9020727580372251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [6:53:52<3:27:48, 12468.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 finished with average loss: 0.25273128585889937, Accuracy: 0.9020833333333333\n",
            "Epoch: 2, Batch: 0, Loss: 0.36636263132095337, Accuracy: 0.8125\n",
            "Epoch: 2, Batch: 10, Loss: 0.05968813598155975, Accuracy: 0.9431818181818182\n",
            "Epoch: 2, Batch: 20, Loss: 0.17464806139469147, Accuracy: 0.9285714285714286\n",
            "Epoch: 2, Batch: 30, Loss: 0.08094462752342224, Accuracy: 0.9314516129032258\n",
            "Epoch: 2, Batch: 40, Loss: 0.4593467712402344, Accuracy: 0.9253048780487805\n",
            "Epoch: 2, Batch: 50, Loss: 0.09575161337852478, Accuracy: 0.9252450980392157\n",
            "Epoch: 2, Batch: 60, Loss: 0.1776050627231598, Accuracy: 0.9211065573770492\n",
            "Epoch: 2, Batch: 70, Loss: 0.2388554960489273, Accuracy: 0.9154929577464789\n",
            "Epoch: 2, Batch: 80, Loss: 0.1837209165096283, Accuracy: 0.9174382716049383\n",
            "Epoch: 2, Batch: 90, Loss: 0.21246148645877838, Accuracy: 0.9210164835164835\n",
            "Epoch: 2, Batch: 100, Loss: 0.06325816363096237, Accuracy: 0.9207920792079208\n",
            "Epoch: 2, Batch: 110, Loss: 0.23108860850334167, Accuracy: 0.9228603603603603\n",
            "Epoch: 2, Batch: 120, Loss: 0.2999519109725952, Accuracy: 0.925103305785124\n",
            "Epoch: 2, Batch: 130, Loss: 0.03863565996289253, Accuracy: 0.9250954198473282\n",
            "Epoch: 2, Batch: 140, Loss: 0.08963452279567719, Accuracy: 0.9264184397163121\n",
            "Epoch: 2, Batch: 150, Loss: 0.19211284816265106, Accuracy: 0.9271523178807947\n",
            "Epoch: 2, Batch: 160, Loss: 0.2108607143163681, Accuracy: 0.9270186335403726\n",
            "Epoch: 2, Batch: 170, Loss: 0.4947769343852997, Accuracy: 0.9236111111111112\n",
            "Epoch: 2, Batch: 180, Loss: 0.4102881848812103, Accuracy: 0.9233425414364641\n",
            "Epoch: 2, Batch: 190, Loss: 0.2962968051433563, Accuracy: 0.9247382198952879\n",
            "Epoch: 2, Batch: 200, Loss: 0.10879979282617569, Accuracy: 0.9247512437810945\n",
            "Epoch: 2, Batch: 210, Loss: 0.07600606977939606, Accuracy: 0.9235781990521327\n",
            "Epoch: 2, Batch: 220, Loss: 0.2586817443370819, Accuracy: 0.9227941176470589\n",
            "Epoch: 2, Batch: 230, Loss: 0.4313565492630005, Accuracy: 0.9228896103896104\n",
            "Epoch: 2, Batch: 240, Loss: 0.04957890138030052, Accuracy: 0.9237551867219918\n",
            "Epoch: 2, Batch: 250, Loss: 0.3198300898075104, Accuracy: 0.9245517928286853\n",
            "Epoch: 2, Batch: 260, Loss: 0.164600670337677, Accuracy: 0.9243295019157088\n",
            "Epoch: 2, Batch: 270, Loss: 0.12650489807128906, Accuracy: 0.9245848708487084\n",
            "Epoch: 2, Batch: 280, Loss: 0.041270457208156586, Accuracy: 0.9241548042704626\n",
            "Epoch: 2, Batch: 290, Loss: 0.15409371256828308, Accuracy: 0.9243986254295533\n",
            "Epoch: 2, Batch: 300, Loss: 0.08486312627792358, Accuracy: 0.9246262458471761\n",
            "Epoch: 2, Batch: 310, Loss: 0.13773174583911896, Accuracy: 0.9248392282958199\n",
            "Epoch: 2, Batch: 320, Loss: 0.2536069452762604, Accuracy: 0.9248442367601246\n",
            "Epoch: 2, Batch: 330, Loss: 0.10693869739770889, Accuracy: 0.9250377643504532\n",
            "Epoch: 2, Batch: 340, Loss: 0.24907836318016052, Accuracy: 0.9257697947214076\n",
            "Epoch: 2, Batch: 350, Loss: 0.07094808667898178, Accuracy: 0.9255698005698005\n",
            "Epoch: 2, Batch: 360, Loss: 0.053230345249176025, Accuracy: 0.9265927977839336\n",
            "Epoch: 2, Batch: 370, Loss: 0.22695907950401306, Accuracy: 0.9270552560646901\n",
            "Epoch: 2, Batch: 380, Loss: 0.11506526172161102, Accuracy: 0.927001312335958\n",
            "Epoch: 2, Batch: 390, Loss: 0.07944174855947495, Accuracy: 0.9267902813299232\n",
            "Epoch: 2, Batch: 400, Loss: 0.13928639888763428, Accuracy: 0.9275249376558603\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertModel, BertConfig\n",
        "from tqdm import tqdm\n",
        "# 위 구조를 취합하여 만든 이진 감정 분류를 위한 클래스\n",
        "class BertForSequenceClassification(nn.Module):\n",
        "    def __init__(self, config, num_labels):\n",
        "        super(BertForSequenceClassification, self).__init__()\n",
        "        self.bert = userBertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None, sentiment_tokens=None):\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            sentiment_tokens= sentiment_tokens,\n",
        "        )\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, 2), labels.view(-1))\n",
        "\n",
        "        return loss, logits\n",
        "\n",
        "# Pretrained BERT 모델 로드\n",
        "\n",
        "pretrained_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "pretrained_state_dict = pretrained_model.state_dict()\n",
        "\n",
        "# Custom 모델 초기화\n",
        "custom_config = BertConfig(\n",
        "    vocab_size=30522,\n",
        "    hidden_size=768,\n",
        "    num_hidden_layers=8,\n",
        "    num_attention_heads=12, # 수정된 부분\n",
        "    intermediate_size=3072, # 수정된 부분\n",
        "    hidden_act=\"gelu\",\n",
        "    hidden_dropout_prob=0.1,\n",
        "    attention_probs_dropout_prob=0.1,\n",
        "    max_position_embeddings=512,\n",
        "    type_vocab_size=2,\n",
        "    initializer_range=0.02,\n",
        "    layer_norm_eps=1e-12,\n",
        "    pad_token_id=0,\n",
        "    gradient_checkpointing=False,\n",
        "    position_embedding_type=\"absolute\",\n",
        "    use_cache=True\n",
        ")\n",
        "model = BertForSequenceClassification(custom_config, num_labels=2)\n",
        "\n",
        "# Pretrained 모델의 state_dict를 Custom 모델로 로드\n",
        "model.bert.load_state_dict(pretrained_state_dict, strict=False)\n",
        "\n",
        "\n",
        "\n",
        "# 옵티마이저 설정\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-6)\n",
        "\n",
        "# 학습 진행\n",
        "model.train()\n",
        "for epoch in tqdm(range(3)):\n",
        "    epoch_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(\n",
        "            input_ids=batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask'],\n",
        "            token_type_ids=batch['token_type_ids'],\n",
        "            labels=batch['labels'],\n",
        "            sentiment_tokens=batch['sentiment_tokens']\n",
        "        )\n",
        "        loss, logits = outputs\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # 예측값 계산\n",
        "        _, predicted = torch.max(logits, 1)\n",
        "        correct_predictions += (predicted == batch['labels']).sum().item()\n",
        "        total_predictions += batch['labels'].size(0)\n",
        "\n",
        "        if batch_idx % 10 == 0:  # 10번째 배치마다 현황 출력\n",
        "            batch_accuracy = correct_predictions / total_predictions\n",
        "            print(f\"Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item()}, Accuracy: {batch_accuracy}\")\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / len(train_dataloader)\n",
        "    epoch_accuracy = correct_predictions / total_predictions\n",
        "    print(f\"Epoch: {epoch} finished with average loss: {avg_epoch_loss}, Accuracy: {epoch_accuracy}\")\n",
        "\n",
        "# 예측 확률 계산 및 평가 수행\n",
        "all_logits = []\n",
        "all_labels = []\n",
        "model.eval()\n",
        "epoch_loss = 0\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, batch in enumerate(val_dataloader):\n",
        "        outputs = model(\n",
        "            input_ids=batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask'],\n",
        "            token_type_ids=batch['token_type_ids'],\n",
        "            labels=batch['labels'],\n",
        "            sentiment_tokens=batch['sentiment_tokens']\n",
        "        )\n",
        "        loss, logits = outputs\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # 예측값 계산\n",
        "        _, predicted = torch.max(logits, 1)\n",
        "        correct_predictions += (predicted == batch['labels']).sum().item()\n",
        "        total_predictions += batch['labels'].size(0)\n",
        "\n",
        "        all_logits.append(logits)\n",
        "        all_labels.append(batch['labels'])\n",
        "\n",
        "        if batch_idx % 10 == 0:  # 10번째 배치마다 현황 출력\n",
        "            batch_accuracy = correct_predictions / total_predictions\n",
        "            print(f\"Epoch: TEST , Batch: {batch_idx}, Loss: {loss.item()}, Accuracy: {batch_accuracy}\")\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / len(val_dataloader)\n",
        "    epoch_accuracy = correct_predictions / total_predictions\n",
        "    print(f\"Test iteration finished with average loss: {avg_epoch_loss}, Accuracy: {epoch_accuracy}\")\n",
        "\n",
        "# 예측 확률 및 라벨 병합\n",
        "all_logits = torch.cat(all_logits).cpu().numpy()\n",
        "all_labels = torch.cat(all_labels).cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# ROC 곡선 및 AUC 계산\n",
        "lr_proba = torch.softmax(torch.tensor(all_logits), dim=1)[:, 1].numpy()\n",
        "fp_lr, tp_lr, _ = roc_curve(all_labels, lr_proba, pos_label=1)\n",
        "auroc_baseline = roc_auc_score(all_labels, lr_proba)\n",
        "\n",
        "# 예측값 계산\n",
        "y_pred = np.argmax(all_logits, axis=1)\n",
        "\n",
        "# 성능 지표 계산\n",
        "cm1 = confusion_matrix(all_labels, y_pred)\n",
        "f1_1 = f1_score(all_labels, y_pred, pos_label=1)\n",
        "precision_1 = precision_score(all_labels, y_pred, pos_label=1)\n",
        "recall_1 = recall_score(all_labels, y_pred, pos_label=1)\n",
        "\n",
        "# 혼동 행렬 및 성능 지표 시각화\n",
        "fig, axes = plt.subplots(figsize=(16, 6))\n",
        "sns.heatmap(cm1, annot=True, cmap='Blues', fmt='d', ax=axes)\n",
        "axes.set_title('Confusion Matrix', fontsize=14)\n",
        "axes.set_xlabel('Predicted Label', fontsize=12)\n",
        "axes.set_ylabel('True Label', fontsize=12)\n",
        "axes.text(0.5, -0.15, f'F1 Score: {f1_1:.4f} Precision: {precision_1:.4f} Recall: {recall_1:.4f}',\n",
        "          horizontalalignment='center', verticalalignment='center', transform=axes.transAxes, fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "# ROC 곡선 그리기\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fp_lr, tp_lr, label=f'BERT Sequence Classification (area = {auroc_baseline:.3f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "7z_SX7uiVul2",
        "outputId": "71655da7-2f07-4c48-f34c-d17c2c360785"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'all_logits' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a7d4be85d06b>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ROC 곡선 및 AUC 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlr_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mfp_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mauroc_baseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_logits' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsualEUMGMgq"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "94d00694401d41f58f2a5f03c7b8139f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efe9921f88924088bd22a79bf43c75b8",
              "IPY_MODEL_a66a24be74144c948e0b7bc02602caf5",
              "IPY_MODEL_00cf4a2c1b164735a92d7e744ba1e357"
            ],
            "layout": "IPY_MODEL_bda6df433b9d4509b6cde476b7e9b577"
          }
        },
        "efe9921f88924088bd22a79bf43c75b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b4987e1ed6441b2b647bf7ae75895ae",
            "placeholder": "​",
            "style": "IPY_MODEL_ea01c634fe6945fca4429136823111be",
            "value": "model.safetensors: 100%"
          }
        },
        "a66a24be74144c948e0b7bc02602caf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_908f512331534b81ac65b5087b10855c",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2697617546794945a35dc123a2aca62c",
            "value": 440449768
          }
        },
        "00cf4a2c1b164735a92d7e744ba1e357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0073179d5f194c2f825c9ab7384cadf1",
            "placeholder": "​",
            "style": "IPY_MODEL_23984d212de04b00915f585ebb2f41fa",
            "value": " 440M/440M [00:03&lt;00:00, 135MB/s]"
          }
        },
        "bda6df433b9d4509b6cde476b7e9b577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b4987e1ed6441b2b647bf7ae75895ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea01c634fe6945fca4429136823111be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "908f512331534b81ac65b5087b10855c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2697617546794945a35dc123a2aca62c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0073179d5f194c2f825c9ab7384cadf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23984d212de04b00915f585ebb2f41fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}