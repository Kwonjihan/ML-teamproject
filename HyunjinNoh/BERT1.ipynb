{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kwonjihan/ML-teamproject/blob/develop/HyunjinNoh/BERT1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frTuJbGRF2KS",
        "outputId": "c1d54ccf-882e-4402-d822-a1adf9c2449a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = '/content/drive/MyDrive/ML/TP/6000 IMDB Dataset.csv'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd #dataframe 관한 함수 사용\n",
        "\n",
        "review_df = pd.read_csv(path)\n",
        "review_df #dataframe 미리보기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "iDgzsP5kTyUk",
        "outputId": "6b77d0a5-cda5-49d2-dfcb-7592917f7099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 review sentiment\n",
              "0     One of the other reviewers has mentioned that ...  positive\n",
              "1     A wonderful little production. <br /><br />The...  positive\n",
              "2     I thought this was a wonderful way to spend ti...  positive\n",
              "3     Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "4     Probably my all-time favorite movie, a story o...  positive\n",
              "...                                                 ...       ...\n",
              "5995  Something somewhere must have terribly gone wr...  negative\n",
              "5996  This was the next to last film appearance by J...  negative\n",
              "5997  I give this movie a 4 cause I'm a die hard fan...  negative\n",
              "5998  Are we serious??? I mean wow ... just, wow. I ...  negative\n",
              "5999  I have no respect for IMDb ratings anymore. I ...  negative\n",
              "\n",
              "[6000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7c831eb-6d0d-4fef-8570-0cd6aef1f127\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Probably my all-time favorite movie, a story o...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5995</th>\n",
              "      <td>Something somewhere must have terribly gone wr...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5996</th>\n",
              "      <td>This was the next to last film appearance by J...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5997</th>\n",
              "      <td>I give this movie a 4 cause I'm a die hard fan...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5998</th>\n",
              "      <td>Are we serious??? I mean wow ... just, wow. I ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>I have no respect for IMDb ratings anymore. I ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7c831eb-6d0d-4fef-8570-0cd6aef1f127')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c7c831eb-6d0d-4fef-8570-0cd6aef1f127 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c7c831eb-6d0d-4fef-8570-0cd6aef1f127');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4762c85a-91bb-4ea6-bf71-270bce456e08\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4762c85a-91bb-4ea6-bf71-270bce456e08')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4762c85a-91bb-4ea6-bf71-270bce456e08 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "review_df",
              "summary": "{\n  \"name\": \"review_df\",\n  \"rows\": 6000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5997,\n        \"samples\": [\n          \"If you keep rigid historical perspective out of it, this film is actually quite entertaining. It's got action, adventure and romance, and one of the premiere casting match-ups of the era with Errol Flynn and Olivia de Havilland in the lead roles. As evident on this board, the picture doesn't pass muster with purists who look for one hundred percent accuracy in their story telling. To get beyond that, one need only put aside the history book, and enjoy the story as if it were a work of fiction. I know, I know, that's hard to do when you consider Custer's Last Stand at the Little Big Horn and it's prominence in the history of post Civil War America. So I guess there's an unresolved quandary with the picture, no matter how you look at it.<br /><br />There's a lot to take in here though for the picture's two hour plus run time. Custer's arrival at West Point is probably the first head scratcher, riding up as he does in full military regalia. The practical joke by Sharp (Arthur Kennedy) putting him up in the Major's headquarters probably should have gotten them both in trouble.<br /><br />Ironically, a lot of scenes in this military film play for comedy, as in Custer's first meeting with Libby Bacon, and subsequent encounters that include tea reader Callie (Hattie McDaniel). I hadn't noticed it before in other films, but McDaniel reminded me an awful lot of another favorite character actor of mine from the Forties, Mantan Moreland. So much so that in one scene it looked like it might have been Moreland hamming it up in a dress. With that in mind, the owl scene was a hoot too.<br /><br />As for Flynn, it's interesting to note that a year earlier, he portrayed J.E.B. Stuart opposite Ronald Reagan's depiction of General Custer in \\\"Santa Fe Trail\\\", both vying for the attention of none other than Olivia de Havilland. In that film, Reagan put none of the arrogance and flamboyance into the character of Custer that history remembers, while in Flynn's portrayal here it's more than evident. But it doesn't come close to that of Richard Mulligan's take on the military hero in 1970's \\\"Little Big Man\\\". Let's just say that one was a bit over the top.<br /><br />The better take away the picture had for me was the manner in which Custer persevered to maintain his good name and not gamble it away on a risky business venture. That and his loyalty to the men he led in battle along with the discipline he developed over the course of the story. Most poignant was that final confrontation with arch rival Sharp just before riding into the Little Big Horn, in which he declared that hell or glory was entirely dependent on one's point of view. Earlier, a similar remark might have given us the best insight of all into Custer's character, when he stated - \\\"You take glory with you when it's your time to go\\\".\",\n          \"Americans have the attention span of a fruit fly and if something does not happen within the span of a typical commercial, we tend to lose interest really fast.<br /><br />I found out an exciting fact from this film: someone has to paint high tension utility poles and do it on a schedule! And guess what, they really would like to be doing something else (the viewer has similar feelings).<br /><br />Surprisingly, when I was bored watching late night infomercials and decided to actually watch this film, I found the characters to be interesting and highly engaging.<br /><br />I just don't usually watch that much late night TV, so I can't recommend this film, unless watching paint dry is your idea of an exciting two hours out of your life.\",\n          \"<br /><br />I saw The Glacier Fox in the theatre when I was nine years old - I bugged my parents to take me back three times. I began looking for it on video about five years ago, finally uncovering a copy on an online auction site, but I would love to see it either picked up by a new distributor and rereleased (I understand the original video run was small), or have the rights purchased by The Family Channel, Disney, etc. and shown regularly. It is a fascinating film that draws you into the story of the life struggle of a family of foxes in northern Japan, narrated by a wise old tree. The excellent soundtrack compliments the film well. It would be a good seller today, better than many of the weak offerings to children's movies today.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1LEU_nYHgq1"
      },
      "outputs": [],
      "source": [
        "#import pandas as pd #dataframe 관한 함수 사용\n",
        "from sklearn.model_selection import train_test_split #train_test_split 함수 사용\n",
        "\n",
        "feature = review_df['review'].tolist() #review_df의 review 열을 list로 만들어서 feature로 정의\n",
        "label = review_df['sentiment'].tolist() #review_df의 sentiment 열을 list로 만들어서 label로 정의\n",
        "\n",
        "#positive label을 1로 인코딩\n",
        "for i in range(len(label)):\n",
        "    if label[i] == 'positive':\n",
        "        label[i] = 1\n",
        "    else :\n",
        "        label[i] = 0\n",
        "\n",
        "#train_test_split 함수 https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "#sklearn.model_selection.train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)[source]\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(feature, label, train_size=0.7, random_state=42) #test_size는 0.3비율로 자동으로 설정됨, random seed 값은 임의로 42로 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실험해볼 수 있는 것: random seed 다르게"
      ],
      "metadata": {
        "id": "mLr7NjKFEbB0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "s8HtEk5pFmcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194cae13-07f8-4d7c-ee36-98020d106cfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  2023,  3185,  ...,     0,     0,     0],\n",
              "        [  101,  2145,  1996,  ...,  2162,  2003,   102],\n",
              "        [  101, 21660,  2066,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101,  1045,  2123,  ...,     0,     0,     0],\n",
              "        [  101,  2023,  2003,  ...,     0,     0,     0],\n",
              "        [  101,  2009,  1005,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "\n",
        "# 텍스트 토큰화\n",
        "#bert-base-uncased 모델은 pretrain된 BERT 토크나이저 모델인데, 모든 텍스트를 소문자로 만들어준다음 토큰화시킨다.\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') #cased 로 실험해보기\n",
        "\n",
        "#인코딩 시 필요한 max_length 결정=>600까지 해본 결과: 512로 설정\n",
        "'''\n",
        "token_lens = []\n",
        "for text in feature:\n",
        "  tokens = tokenizer.encode(text, truncation=True) #truncation은 최대길이보다 긴 시퀀스(문장이나 문단을 칭함)를 잘려지도록 함\n",
        "  token_lens.append(len(tokens)) #각 텍스트를 토큰화했을 때 생성된 토큰의 개수를 배열에 저장\n",
        "sns.displot(token_lens)\n",
        "plt.xlim([0, 512]);\n",
        "plt.xlabel('Token count') #x축은 각 텍스트의 토큰 수, y축은 그 토큰 수를 가진 텍스트들이 얼마나 있는지\n",
        "'''\n",
        "\n",
        "#참고: BertTokenizer의 special token\n",
        "'''\n",
        "#[CLS]: 문장의 시작에 들어감 [SEP]: 문장의 끝에 들어감  [PAD]: padding에 들어감 [UNK]: training set 에 없던 토큰\n",
        "#id값: 101, 102, 0, 100 코드: print(tokenizer.cls_token_id, tokenizer.sep_token_id, tokenizer.pad_token_id, tokenizer.unk_token_id)\n",
        "'''\n",
        "\n",
        "#인코딩\n",
        "train_encodings = tokenizer.batch_encode_plus( #train_texts 리스트를 처리해야 해서 batch_encode_plus\n",
        "  train_texts,\n",
        "  max_length=512,\n",
        "  truncation=True, #truncation은 최대길이보다 긴 시퀀스(문장이나 문단을 칭함)를 잘려지도록 함\n",
        "  padding='max_length', #padding은 최대길이보다 짧은 시퀀스에 패딩 토큰을 삽입하여 모든 시퀀스를 동일한 길이로 만듦\n",
        "  add_special_tokens=True,\n",
        "  return_attention_mask=True, #padding된 건 0으로 반환\n",
        "  return_tensors='pt' #토크나이저가 반환하는 것은 pt라는 PyTorch 텐서\n",
        ")\n",
        "\n",
        "test_encodings = tokenizer.batch_encode_plus( #test_texts 리스트를 처리해야 해서 batch_encode_plus\n",
        "  test_texts,\n",
        "  max_length=512,\n",
        "  truncation=True, #truncation은 최대길이보다 긴 시퀀스(문장이나 문단을 칭함)를 잘려지도록 함\n",
        "  padding='max_length', #padding은 최대길이보다 짧은 시퀀스에 패딩 토큰을 삽입하여 모든 시퀀스를 동일한 길이로 만듦\n",
        "  add_special_tokens=True,\n",
        "  return_attention_mask=True, #padding된 건 0으로 반환\n",
        "  return_tensors='pt' #토크나이저가 반환하는 것은 pt라는 PyTorch 텐서\n",
        ")\n",
        "\n",
        "train_encodings\n",
        "#참고: train_encodings, test_encodings는 input_ids, token_type_ids, attention_mask 세 종류를 반환\n",
        "'''\n",
        "input_ids는 각 문장별 token들의 인코딩값\n",
        "token_type_ids는 input_ids의 어느 부분이 첫번째 문장(0)이고 어느 부분이 두 번째 문장(1)인지 알려줌 #왜 다 0???\n",
        "attention_mask는 padding 여부(padding 처리 되었다면 0)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실험해볼 수 있는 것: 'bert-base-cased'"
      ],
      "metadata": {
        "id": "egX-4CDHD5Tb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k32bmKWbLpqq",
        "outputId": "c057fa0e-ebd9-4044-bb32-b261dd6ba3d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "100%|██████████| 263/263 [26:15<00:00,  5.99s/it]\n",
            "100%|██████████| 263/263 [26:36<00:00,  6.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 정확도: 0.905\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertForSequenceClassification, AdamW\n",
        "from tqdm import tqdm #진행도 시각화\n",
        "\n",
        "# 데이터셋 텐서로 생성\n",
        "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(train_labels))\n",
        "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], torch.tensor(test_labels))\n",
        "# 데이터로더 생성: 데이터셋들을 미니배치로 나누어 모델에 공급.\n",
        "##하이퍼파라미터 batch_size: 후보 16, 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# 모델 준비\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "# 훈련 설정\n",
        "##하이퍼파라미터 learning rate: 후보 5e-5, 3e-5, 2e-5\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "# epoch 횟수 설정\n",
        "##하이퍼파라미터 epoch_num: 후보 2, 3, 4\n",
        "epoch_num = 2\n",
        "\n",
        "model.train()\n",
        "for epoch in range(epoch_num): #epoch은 전체 훈련 데이터셋을 한 번 통과하는 것을 의미\n",
        "    for batch in tqdm(train_loader):\n",
        "        optimizer.zero_grad() #optimizer의 gradient를 초기화. 각 미니배치마다 새로운 그래디언트 계산 위해.\n",
        "\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# 평가\n",
        "model.eval()\n",
        "\n",
        "#변수 초기화\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predicted_labels = torch.argmax(logits, dim=1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted_labels == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'테스트 정확도: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실험해볼 수 있는 것: BERT의 다른 classification 모델, BERTAdam 등 다른 optimizer"
      ],
      "metadata": {
        "id": "BlCux31qD9e2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "#Grid Search\n",
        "#하이퍼파라미터는 BERT 논문 작성자가 파인튜닝으로 권장하는 것들(BERT 논문 부록 A.3) + medium post https://medium.com/distributed-computing-with-ray/hyperparameter-optimization-for-transformers-a-guide-c4e32c6c989b\n",
        "param_grid = {\n",
        "    'lerning_rate': [5e-5, 3e-5, 2e-5],\n",
        "    'batch_size': [16, 32], #늘리면 훈련시간이 줄어들지만 정확도는 낮아짐.\n",
        "    'number_of_epochs': [2, 3, 4],\n",
        "\n",
        "    'weight_decay': [0, 0.3], #weight_decay값이 커질수록 weight로 인한 오버피팅 방지\n",
        "    'warmup_steps': [0, 500]  #medium 포스트 참고\n",
        "}\n",
        "\n",
        "#참고 코드\n",
        "'''\n",
        "grid_cv = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5) #뒤의 문제에서 최적의 파라미터로 다시 전체 train set에 대해 학습시킬 것이기 때문에, refit=True 옵션은 굳이 쓰지 않았음\n",
        "grid_cv.fit(X_train, y_train) #grid_cv 작동시킴\n",
        "\n",
        "best_parameters = grid_cv.best_params_ #best parameter 찾음\n",
        "best_score = grid_cv.best_score_ #best validation score 찾음\n",
        "\n",
        "print(f\"Best parameters: {best_parameters}\")\n",
        "print(f\"Best score: {best_score}\")\n",
        "'''"
      ],
      "metadata": {
        "id": "4Hp5lsBiB74O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "실험해볼 수 있는 것: grid search 수행해보기, grid search의 발전 버전 Improving Grid Search with Bayesian Optimization도 수행해보기\n",
        "\n"
      ],
      "metadata": {
        "id": "uA1Iy2GLEM5L"
      }
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}