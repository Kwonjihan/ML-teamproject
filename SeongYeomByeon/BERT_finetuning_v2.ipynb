{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kwonjihan/ML-teamproject/blob/develop/SeongYeomByeon/BERT_finetuning_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path='/content/drive/MyDrive/6000_IMDB_Dataset.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfRNbEvV-8tp",
        "outputId": "3644f9f2-a938-4082-cce3-cc362ced33f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from typing import Optional, Tuple"
      ],
      "metadata": {
        "id": "woLaLsvCPFAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuK6Nz5JO1ip"
      },
      "outputs": [],
      "source": [
        "# 데이터 전처리 #\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze()\n",
        "        attention_mask = encoding['attention_mask'].squeeze()\n",
        "        token_type_ids = encoding['token_type_ids'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'token_type_ids': token_type_ids,\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "def load_data(file_path, tokenizer, max_length=128):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "    texts = df['review'].tolist()\n",
        "    labels = df['sentiment'].tolist()\n",
        "\n",
        "    train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2)\n",
        "\n",
        "    train_dataset = SentimentDataset(train_texts, train_labels, tokenizer, max_length)\n",
        "    val_dataset = SentimentDataset(val_texts, val_labels, tokenizer, max_length)\n",
        "\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "# 토크나이저 초기화\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# 데이터 로드\n",
        "train_dataset, val_dataset = load_data(file_path, tokenizer)\n",
        "\n",
        "# 데이터 로더 생성\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# [모델 준비] #\n",
        "\n",
        "# 활성화 함수\n",
        "def gelu(x):\n",
        "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
        "\n",
        "# 활성화 함수 매핑\n",
        "ACT2FN = {\"gelu\": gelu, \"relu\": torch.nn.functional.relu, \"swish\": torch.nn.functional.silu}\n",
        "\n",
        "# 모델 설정\n",
        "\n",
        "# BERT 입력 임베딩 생성 클래스\n",
        "class BertEmbeddings(nn.Module):\n",
        "    def __init__(self, config: Config):\n",
        "        super().__init__()\n",
        "        # 단어 임베딩, 위치 임베딩, 토큰 타입 임베딩\n",
        "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)\n",
        "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
        "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
        "        # 레이어 정규화와 드롭아웃\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.position_embedding_type = getattr(config, \"position_embedding_type\", \"absolute\")\n",
        "        self.register_buffer(\"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)), persistent=False)\n",
        "        self.register_buffer(\"token_type_ids\", torch.zeros(self.position_ids.size(), dtype=torch.long), persistent=False)\n",
        "\n",
        "    def forward(self, input_ids=None, token_type_ids=None, position_ids=None, inputs_embeds=None, past_key_values_length=0):\n",
        "        if input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "        else:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "\n",
        "        seq_length = input_shape[1]\n",
        "\n",
        "        if position_ids is None:\n",
        "            position_ids = self.position_ids[:, past_key_values_length: seq_length + past_key_values_length]\n",
        "\n",
        "        if token_type_ids is None:\n",
        "            if hasattr(self, \"token_type_ids\"):\n",
        "                buffered_token_type_ids = self.token_type_ids[:, :seq_length]\n",
        "                buffered_token_type_ids_expanded = buffered_token_type_ids.expand(input_shape[0], seq_length)\n",
        "                token_type_ids = buffered_token_type_ids_expanded\n",
        "            else:\n",
        "                token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.position_ids.device)\n",
        "\n",
        "        if inputs_embeds is None:\n",
        "            inputs_embeds = self.word_embeddings(input_ids)\n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "\n",
        "        # 입력 임베딩 생성\n",
        "        embeddings = inputs_embeds + token_type_embeddings\n",
        "        if self.position_embedding_type == \"absolute\":\n",
        "            position_embeddings = self.position_embeddings(position_ids)\n",
        "            embeddings += position_embeddings\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        return embeddings\n",
        "\n",
        "# 셀프 어텐션 구현 클래스\n",
        "class BertSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        if config.hidden_size % config.num_attention_heads != 0:\n",
        "            raise ValueError(\n",
        "                \"The hidden size (%d) is not a multiple of the number of attention heads (%d)\" %\n",
        "                (config.hidden_size, config.num_attention_heads))\n",
        "\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "\n",
        "        #################################\n",
        "        self.keyword_scale = nn.Parameter(torch.ones(1))# 키워드 스코어에 대한 스케일링 파라미터를 학습 가능하도록 추가\n",
        "        #################################\n",
        "\n",
        "    def transpose_for_scores(self, x):\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(*new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        mixed_key_layer = self.key(hidden_states)\n",
        "        mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
        "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
        "\n",
        "        #################################\n",
        "        # 어텐션 스코어 계산\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "\n",
        "        # 키워드 스코어 계산\n",
        "        cls_token = hidden_states[:, 0, :]  # CLS 토큰 추출\n",
        "        token_similarities = F.cosine_similarity(hidden_states, cls_token.unsqueeze(1).expand_as(hidden_states), dim=-1)  # 각 토큰과 CLS토큰의 cosine similarity 계산\n",
        "        keyword_scores = (token_similarities + 1) / 2  # 0~1사이로 매핑\n",
        "\n",
        "        # 어텐션 스코어에 키워드 스코어 반영\n",
        "        attention_scores = attention_scores * keyword_scores.unsqueeze(1).unsqueeze(1) * self.keyword_scale # 키워드 스코어를 attention score에 곱한 후, 스케일링 파라미터를 적용\n",
        "        #################################\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "# 셀프 어텐션 출력 처리 클래스\n",
        "class BertSelfOutput(nn.Module):\n",
        "    def __init__(self, config: Config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        # 드롭아웃, 레이어 정규화, 잔차 연결 적용\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "\n",
        "# 어텐션 메커니즘 클래스\n",
        "class BertAttention(nn.Module):\n",
        "    def __init__(self, config: Config):\n",
        "        super().__init__()\n",
        "        self.self = BertSelfAttention(config)\n",
        "        self.output = BertSelfOutput(config)\n",
        "\n",
        "    def forward(self, input_tensor, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_value=None, output_attentions=False):\n",
        "        # 셀프 어텐션 및 출력 계산\n",
        "        self_outputs = self.self(\n",
        "            input_tensor,\n",
        "            attention_mask,\n",
        "            head_mask,\n",
        "            encoder_hidden_states,\n",
        "            encoder_attention_mask,\n",
        "            past_key_value,\n",
        "            output_attentions,\n",
        "        )\n",
        "        attention_output = self.output(self_outputs[0], input_tensor)\n",
        "        outputs = (attention_output,) + self_outputs[1:]\n",
        "        return outputs\n",
        "\n",
        "# 중간 레이어 활성화 함수 클래스\n",
        "class BertIntermediate(nn.Module):\n",
        "    def __init__(self, config: Config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
        "        self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        # 중간 레이어 활성화 함수 적용\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "# 중간 레이어 출력 처리 클래스\n",
        "class BertOutput(nn.Module):\n",
        "    def __init__(self, config: Config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        # 드롭아웃, 레이어 정규화, 잔차 연결 적용\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.Layer\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        # 드롭아웃, 레이어 정규화, 잔차 연결 적용\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "\n",
        "# 하나의 BERT 레이어를 구현하는 클래스\n",
        "class BertLayer(nn.Module):\n",
        "    def __init__(self, config: Config):\n",
        "        super().__init__()\n",
        "        self.attention = BertAttention(config)\n",
        "        self.intermediate = BertIntermediate(config)\n",
        "        self.output = BertOutput(config)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_value=None, output_attentions=False):\n",
        "        # 어텐션과 출력 계산\n",
        "        self_attention_outputs = self.attention(\n",
        "            hidden_states,\n",
        "            attention_mask,\n",
        "            head_mask,\n",
        "            encoder_hidden_states,\n",
        "            encoder_attention_mask,\n",
        "            past_key_value,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        attention_output = self_attention_outputs[0]\n",
        "        layer_output = self.output(self.intermediate(attention_output), attention_output)\n",
        "        outputs = (layer_output,) + self_attention_outputs[1:]\n",
        "        return outputs\n",
        "\n",
        "# 여러 BERT 레이어를 포함하는 인코더 클래스\n",
        "class BertEncoder(nn.Module):\n",
        "    def __init__(self, config: Config):\n",
        "        super().__init__()\n",
        "        self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_values=None, use_cache=None, output_attentions=False, output_hidden_states=False, return_dict=True):\n",
        "        all_hidden_states = () if output_hidden_states else None\n",
        "        all_attentions = () if output_attentions else None\n",
        "        for i, layer_module in enumerate(self.layer):\n",
        "            layer_head_mask = head_mask[i] if head_mask is not None else None\n",
        "            past_key_value = past_key_values[i] if past_key_values is not None else None\n",
        "\n",
        "            if output_hidden_states:\n",
        "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "            layer_outputs = layer_module(\n",
        "                hidden_states,\n",
        "                attention_mask,\n",
        "                layer_head_mask,\n",
        "                encoder_hidden_states,\n",
        "                encoder_attention_mask,\n",
        "                past_key_value,\n",
        "                output_attentions,\n",
        "            )\n",
        "            hidden_states = layer_outputs[0]\n",
        "\n",
        "            if output_attentions:\n",
        "                all_attentions = all_attentions + (layer_outputs[1],)\n",
        "\n",
        "        return (hidden_states, all_hidden_states, all_attentions)\n",
        "\n",
        "# 첫 번째 토큰의 출력을 풀링하는 클래스\n",
        "class BertPooler(nn.Module):\n",
        "    def __init__(self, config: Config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        # 첫 번째 토큰의 텐서를 사용해 풀링 출력 생성\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        pooled_output = self.dense(first_token_tensor)\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "        return pooled_output\n",
        "\n",
        "# 전체 BERT 모델을 구현하는 클래스\n",
        "class  userBertModel(nn.Module):\n",
        "    def __init__(self, config: Config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.embeddings = BertEmbeddings(config)\n",
        "        self.encoder = BertEncoder(config)\n",
        "        self.pooler = BertPooler(config)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_values=None, use_cache=None, output_attentions=None, output_hidden_states=None, return_dict=None):\n",
        "        # 입력 텐서의 크기 확인\n",
        "        if input_ids is not None and inputs_embeds is not None:\n",
        "            raise ValueError(\"input_ids 혹은 inputs_embeds 둘 중 하나의 형식으로만 입력해야 합니다.\")\n",
        "        elif input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "        elif inputs_embeds is not None:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "        else:\n",
        "            raise ValueError(\"input_ids 또는 inputs_embeds의 형식이어야 합니다.\")\n",
        "\n",
        "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones(input_shape, device=device)\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "\n",
        "        extended_attention_mask = attention_mask[:, None, None, :]\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype)\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "\n",
        "        head_mask = [None] * self.config.num_hidden_layers\n",
        "\n",
        "        # 임베딩 출력 계산\n",
        "        embedding_output = self.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            position_ids=position_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "        # 인코더 출력 계산\n",
        "        encoder_outputs = self.encoder(\n",
        "            embedding_output,\n",
        "            attention_mask=extended_attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states=encoder_hidden_states,\n",
        "            encoder_attention_mask=encoder_attention_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        sequence_output = encoder_outputs[0]\n",
        "        pooled_output = self.pooler(sequence_output)\n",
        "        return sequence_output, pooled_output"
      ],
      "metadata": {
        "id": "8RxEd2bIQyQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nAXhMfNkYbth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, BertConfig\n",
        "# 위 구조를 취합하여 만든 이진 감정 분류를 위한 클래스\n",
        "class BertForSequenceClassification(nn.Module):\n",
        "    def __init__(self, config, num_labels):\n",
        "        super(BertForSequenceClassification, self).__init__()\n",
        "        self.bert = userBertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, 2), labels.view(-1))\n",
        "\n",
        "        return loss, logits\n",
        "\n",
        "# Pretrained BERT 모델 로드\n",
        "\n",
        "pretrained_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "pretrained_state_dict = pretrained_model.state_dict()\n",
        "\n",
        "# Custom 모델 초기화\n",
        "custom_config = BertConfig(\n",
        "    vocab_size=30522,\n",
        "    hidden_size=768,\n",
        "    num_hidden_layers=8,\n",
        "    num_attention_heads=12, # 수정된 부분\n",
        "    intermediate_size=3072, # 수정된 부분\n",
        "    hidden_act=\"gelu\",\n",
        "    hidden_dropout_prob=0.1,\n",
        "    attention_probs_dropout_prob=0.1,\n",
        "    max_position_embeddings=512,\n",
        "    type_vocab_size=2,\n",
        "    initializer_range=0.02,\n",
        "    layer_norm_eps=1e-12,\n",
        "    pad_token_id=0,\n",
        "    gradient_checkpointing=False,\n",
        "    position_embedding_type=\"absolute\",\n",
        "    use_cache=True\n",
        ")\n",
        "model = BertForSequenceClassification(custom_config, num_labels=2)\n",
        "\n",
        "# Pretrained 모델의 state_dict를 Custom 모델로 로드\n",
        "model.bert.load_state_dict(pretrained_state_dict, strict=False)\n",
        "\n",
        "\n",
        "\n",
        "# 옵티마이저 설정\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-6)\n",
        "\n",
        "# 학습 진행\n",
        "model.train()\n",
        "for epoch in range(3):\n",
        "    epoch_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(\n",
        "            input_ids=batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask'],\n",
        "            token_type_ids=batch['token_type_ids'],\n",
        "            labels=batch['labels']\n",
        "        )\n",
        "        loss, logits = outputs\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # 예측값 계산\n",
        "        _, predicted = torch.max(logits, 1)\n",
        "        correct_predictions += (predicted == batch['labels']).sum().item()\n",
        "        total_predictions += batch['labels'].size(0)\n",
        "\n",
        "        if batch_idx % 10 == 0:  # 10번째 배치마다 현황 출력\n",
        "            batch_accuracy = correct_predictions / total_predictions\n",
        "            print(f\"Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item()}, Accuracy: {batch_accuracy}\")\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / len(train_dataloader)\n",
        "    epoch_accuracy = correct_predictions / total_predictions\n",
        "    print(f\"Epoch: {epoch} finished with average loss: {avg_epoch_loss}, Accuracy: {epoch_accuracy}\")\n",
        "\n",
        "model.eval()\n",
        "epoch_loss = 0\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, batch in enumerate(val_dataloader):\n",
        "        outputs = model(\n",
        "            input_ids=batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask'],\n",
        "            token_type_ids=batch['token_type_ids'],\n",
        "            labels=batch['labels']\n",
        "        )\n",
        "        loss, logits = outputs\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # 예측값 계산\n",
        "        _, predicted = torch.max(logits, 1)\n",
        "        correct_predictions += (predicted == batch['labels']).sum().item()\n",
        "        total_predictions += batch['labels'].size(0)\n",
        "\n",
        "        if batch_idx % 10 == 0:  # 10번째 배치마다 현황 출력\n",
        "            batch_accuracy = correct_predictions / total_predictions\n",
        "            print(f\"Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item()}, Accuracy: {batch_accuracy}\")\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / len(train_dataloader)\n",
        "    epoch_accuracy = correct_predictions / total_predictions\n",
        "    print(f\"Epoch: {epoch} finished with average loss: {avg_epoch_loss}, Accuracy: {epoch_accuracy}\")\n",
        "\n",
        "# 모델 저장 경로 설정\n",
        "save_path = './my_finetuned_bert_model.pth'\n",
        "\n",
        "# 모델 저장\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"Model saved to {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aTojxNkPIxO",
        "outputId": "e4dd2ffe-6192-4b7d-dcb5-a0fb943394e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Batch: 0, Loss: 0.7050905823707581, Accuracy: 0.5\n",
            "Epoch: 0, Batch: 10, Loss: 0.6754403114318848, Accuracy: 0.48295454545454547\n",
            "Epoch: 0, Batch: 20, Loss: 0.6989350318908691, Accuracy: 0.5238095238095238\n",
            "Epoch: 0, Batch: 30, Loss: 0.7212773561477661, Accuracy: 0.49798387096774194\n",
            "Epoch: 0, Batch: 40, Loss: 0.6942081451416016, Accuracy: 0.5076219512195121\n",
            "Epoch: 0, Batch: 50, Loss: 0.7025318145751953, Accuracy: 0.5318627450980392\n",
            "Epoch: 0, Batch: 60, Loss: 0.6889368295669556, Accuracy: 0.5286885245901639\n",
            "Epoch: 0, Batch: 70, Loss: 0.6404345631599426, Accuracy: 0.5202464788732394\n",
            "Epoch: 0, Batch: 80, Loss: 0.7049887776374817, Accuracy: 0.5223765432098766\n",
            "Epoch: 0, Batch: 90, Loss: 0.6390503644943237, Accuracy: 0.5199175824175825\n",
            "Epoch: 0, Batch: 100, Loss: 0.6099302768707275, Accuracy: 0.5204207920792079\n",
            "Epoch: 0, Batch: 110, Loss: 0.6992814540863037, Accuracy: 0.5208333333333334\n",
            "Epoch: 0, Batch: 120, Loss: 0.6674126982688904, Accuracy: 0.5232438016528925\n",
            "Epoch: 0, Batch: 130, Loss: 0.6398168802261353, Accuracy: 0.5286259541984732\n",
            "Epoch: 0, Batch: 140, Loss: 0.6337077617645264, Accuracy: 0.5336879432624113\n",
            "Epoch: 0, Batch: 150, Loss: 0.6939776539802551, Accuracy: 0.535182119205298\n",
            "Epoch: 0, Batch: 160, Loss: 0.6434003114700317, Accuracy: 0.5438664596273292\n",
            "Epoch: 0, Batch: 170, Loss: 0.6459919810295105, Accuracy: 0.5500730994152047\n",
            "Epoch: 0, Batch: 180, Loss: 0.6480240821838379, Accuracy: 0.5552486187845304\n",
            "Epoch: 0, Batch: 190, Loss: 0.4746483564376831, Accuracy: 0.56282722513089\n",
            "Epoch: 0, Batch: 200, Loss: 0.6852319240570068, Accuracy: 0.5674751243781094\n",
            "Epoch: 0, Batch: 210, Loss: 0.5109188556671143, Accuracy: 0.5716824644549763\n",
            "Epoch: 0, Batch: 220, Loss: 0.5007895231246948, Accuracy: 0.5774886877828054\n",
            "Epoch: 0, Batch: 230, Loss: 0.7112441062927246, Accuracy: 0.5792748917748918\n",
            "Epoch: 0, Batch: 240, Loss: 0.5907622575759888, Accuracy: 0.5848029045643154\n",
            "Epoch: 0, Batch: 250, Loss: 0.46171247959136963, Accuracy: 0.5906374501992032\n",
            "Epoch: 0, Batch: 260, Loss: 0.6872830390930176, Accuracy: 0.5969827586206896\n",
            "Epoch: 0, Batch: 270, Loss: 0.48880505561828613, Accuracy: 0.6040129151291513\n",
            "Epoch: 0, Batch: 280, Loss: 0.4537663757801056, Accuracy: 0.608540925266904\n",
            "Epoch: 0, Batch: 290, Loss: 0.3682534992694855, Accuracy: 0.6161941580756014\n",
            "Epoch: 0 finished with average loss: 0.6268244373798371, Accuracy: 0.6208333333333333\n",
            "Epoch: 1, Batch: 0, Loss: 0.6452881097793579, Accuracy: 0.625\n",
            "Epoch: 1, Batch: 10, Loss: 0.5177088379859924, Accuracy: 0.7670454545454546\n",
            "Epoch: 1, Batch: 20, Loss: 0.30531662702560425, Accuracy: 0.7946428571428571\n",
            "Epoch: 1, Batch: 30, Loss: 0.5155186653137207, Accuracy: 0.7983870967741935\n",
            "Epoch: 1, Batch: 40, Loss: 0.49439454078674316, Accuracy: 0.7896341463414634\n",
            "Epoch: 1, Batch: 50, Loss: 0.4673061966896057, Accuracy: 0.7965686274509803\n",
            "Epoch: 1, Batch: 60, Loss: 0.33895307779312134, Accuracy: 0.7909836065573771\n",
            "Epoch: 1, Batch: 70, Loss: 0.5511078238487244, Accuracy: 0.7940140845070423\n",
            "Epoch: 1, Batch: 80, Loss: 0.3796638250350952, Accuracy: 0.7932098765432098\n",
            "Epoch: 1, Batch: 90, Loss: 0.349751353263855, Accuracy: 0.7891483516483516\n",
            "Epoch: 1, Batch: 100, Loss: 0.2607632577419281, Accuracy: 0.7939356435643564\n",
            "Epoch: 1, Batch: 110, Loss: 0.278780996799469, Accuracy: 0.7927927927927928\n",
            "Epoch: 1, Batch: 120, Loss: 0.4371541142463684, Accuracy: 0.7892561983471075\n",
            "Epoch: 1, Batch: 130, Loss: 0.2360231727361679, Accuracy: 0.7891221374045801\n",
            "Epoch: 1, Batch: 140, Loss: 0.45249924063682556, Accuracy: 0.7898936170212766\n",
            "Epoch: 1, Batch: 150, Loss: 0.6103359460830688, Accuracy: 0.7868377483443708\n",
            "Epoch: 1, Batch: 160, Loss: 0.4016208052635193, Accuracy: 0.7884316770186336\n",
            "Epoch: 1, Batch: 170, Loss: 0.35411083698272705, Accuracy: 0.7909356725146199\n",
            "Epoch: 1, Batch: 180, Loss: 0.21754145622253418, Accuracy: 0.7921270718232044\n",
            "Epoch: 1, Batch: 190, Loss: 0.15096008777618408, Accuracy: 0.7948298429319371\n",
            "Epoch: 1, Batch: 200, Loss: 0.520936131477356, Accuracy: 0.7975746268656716\n",
            "Epoch: 1, Batch: 210, Loss: 0.28130897879600525, Accuracy: 0.8000592417061612\n",
            "Epoch: 1, Batch: 220, Loss: 0.33456602692604065, Accuracy: 0.8031674208144797\n",
            "Epoch: 1, Batch: 230, Loss: 0.3549807369709015, Accuracy: 0.8027597402597403\n",
            "Epoch: 1, Batch: 240, Loss: 0.5430415868759155, Accuracy: 0.8026452282157677\n",
            "Epoch: 1, Batch: 250, Loss: 0.24930909276008606, Accuracy: 0.8032868525896414\n",
            "Epoch: 1, Batch: 260, Loss: 0.6992608904838562, Accuracy: 0.8060344827586207\n",
            "Epoch: 1, Batch: 270, Loss: 0.420700341463089, Accuracy: 0.8074261992619927\n",
            "Epoch: 1, Batch: 280, Loss: 0.2084917426109314, Accuracy: 0.8093861209964412\n",
            "Epoch: 1, Batch: 290, Loss: 0.36648237705230713, Accuracy: 0.8101374570446735\n",
            "Epoch: 1 finished with average loss: 0.41012421416739625, Accuracy: 0.8114583333333333\n",
            "Epoch: 2, Batch: 0, Loss: 0.5334736704826355, Accuracy: 0.6875\n",
            "Epoch: 2, Batch: 10, Loss: 0.2935439646244049, Accuracy: 0.875\n",
            "Epoch: 2, Batch: 20, Loss: 0.1523144692182541, Accuracy: 0.8898809523809523\n",
            "Epoch: 2, Batch: 30, Loss: 0.5358117818832397, Accuracy: 0.8850806451612904\n",
            "Epoch: 2, Batch: 40, Loss: 0.5170572400093079, Accuracy: 0.8719512195121951\n",
            "Epoch: 2, Batch: 50, Loss: 0.4054985046386719, Accuracy: 0.8737745098039216\n",
            "Epoch: 2, Batch: 60, Loss: 0.27183306217193604, Accuracy: 0.8709016393442623\n",
            "Epoch: 2, Batch: 70, Loss: 0.5039414167404175, Accuracy: 0.8714788732394366\n",
            "Epoch: 2, Batch: 80, Loss: 0.2901153564453125, Accuracy: 0.8665123456790124\n",
            "Epoch: 2, Batch: 90, Loss: 0.33131861686706543, Accuracy: 0.8653846153846154\n",
            "Epoch: 2, Batch: 100, Loss: 0.23012976348400116, Accuracy: 0.8650990099009901\n",
            "Epoch: 2, Batch: 110, Loss: 0.18878735601902008, Accuracy: 0.8597972972972973\n",
            "Epoch: 2, Batch: 120, Loss: 0.3106377124786377, Accuracy: 0.8584710743801653\n",
            "Epoch: 2, Batch: 130, Loss: 0.15520021319389343, Accuracy: 0.8583015267175572\n",
            "Epoch: 2, Batch: 140, Loss: 0.24519111216068268, Accuracy: 0.8590425531914894\n",
            "Epoch: 2, Batch: 150, Loss: 0.5628892183303833, Accuracy: 0.8559602649006622\n",
            "Epoch: 2, Batch: 160, Loss: 0.28568074107170105, Accuracy: 0.8583074534161491\n",
            "Epoch: 2, Batch: 170, Loss: 0.23228880763053894, Accuracy: 0.8614766081871345\n",
            "Epoch: 2, Batch: 180, Loss: 0.11685805767774582, Accuracy: 0.8615331491712708\n",
            "Epoch: 2, Batch: 190, Loss: 0.088910773396492, Accuracy: 0.8635471204188482\n",
            "Epoch: 2, Batch: 200, Loss: 0.3709620535373688, Accuracy: 0.8662935323383084\n",
            "Epoch: 2, Batch: 210, Loss: 0.14345107972621918, Accuracy: 0.8670023696682464\n",
            "Epoch: 2, Batch: 220, Loss: 0.19726483523845673, Accuracy: 0.869343891402715\n",
            "Epoch: 2, Batch: 230, Loss: 0.40049079060554504, Accuracy: 0.8706709956709957\n",
            "Epoch: 2, Batch: 240, Loss: 0.3875531256198883, Accuracy: 0.870591286307054\n",
            "Epoch: 2, Batch: 250, Loss: 0.2811421751976013, Accuracy: 0.8715139442231076\n",
            "Epoch: 2, Batch: 260, Loss: 0.6415461301803589, Accuracy: 0.8728448275862069\n",
            "Epoch: 2, Batch: 270, Loss: 0.3261406421661377, Accuracy: 0.8736162361623616\n",
            "Epoch: 2, Batch: 280, Loss: 0.1861708015203476, Accuracy: 0.8752224199288257\n",
            "Epoch: 2, Batch: 290, Loss: 0.3458559811115265, Accuracy: 0.8754295532646048\n",
            "Epoch: 2 finished with average loss: 0.3106341330955426, Accuracy: 0.8764583333333333\n",
            "Epoch: 2, Batch: 0, Loss: 0.4083902835845947, Accuracy: 0.875\n",
            "Epoch: 2, Batch: 10, Loss: 0.4939141273498535, Accuracy: 0.7897727272727273\n",
            "Epoch: 2, Batch: 20, Loss: 0.35940980911254883, Accuracy: 0.8244047619047619\n",
            "Epoch: 2, Batch: 30, Loss: 1.0877634286880493, Accuracy: 0.8185483870967742\n",
            "Epoch: 2, Batch: 40, Loss: 0.41692864894866943, Accuracy: 0.8246951219512195\n",
            "Epoch: 2, Batch: 50, Loss: 0.3381761312484741, Accuracy: 0.8259803921568627\n",
            "Epoch: 2, Batch: 60, Loss: 0.4589462876319885, Accuracy: 0.819672131147541\n",
            "Epoch: 2, Batch: 70, Loss: 0.38106250762939453, Accuracy: 0.8221830985915493\n",
            "Epoch: 2 finished with average loss: 0.101237889478604, Accuracy: 0.8191666666666667\n",
            "Model saved to ./my_finetuned_bert_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZsualEUMGMgq"
      }
    }
  ]
}