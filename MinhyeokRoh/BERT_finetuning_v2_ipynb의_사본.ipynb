{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kwonjihan/ML-teamproject/blob/develop/MinhyeokRoh/BERT_finetuning_v2_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfRNbEvV-8tp",
        "outputId": "f6eefcc8-73e4-42e0-992c-cbb6bcf2f11a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path='/content/drive/MyDrive/12K IMDB Dataset.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woLaLsvCPFAi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from typing import Optional, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuK6Nz5JO1ip"
      },
      "outputs": [],
      "source": [
        "# 데이터 전처리 #\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze()\n",
        "        attention_mask = encoding['attention_mask'].squeeze()\n",
        "        token_type_ids = encoding['token_type_ids'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'token_type_ids': token_type_ids,\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "def load_data(file_path, tokenizer, max_length=512):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "    texts = df['review'].tolist()\n",
        "    labels = df['sentiment'].tolist()\n",
        "\n",
        "    train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_dataset = SentimentDataset(train_texts, train_labels, tokenizer, max_length)\n",
        "    val_dataset = SentimentDataset(val_texts, val_labels, tokenizer, max_length)\n",
        "\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "# 토크나이저 초기화\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# 데이터 로드\n",
        "train_dataset, val_dataset = load_data(file_path, tokenizer)\n",
        "\n",
        "# 데이터 로더 생성\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RxEd2bIQyQ1"
      },
      "outputs": [],
      "source": [
        "# [모델 준비] #\n",
        "import torch.nn.functional as F\n",
        "# 활성화 함수\n",
        "def gelu(x):\n",
        "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
        "\n",
        "# 활성화 함수 매핑\n",
        "ACT2FN = {\"gelu\": gelu, \"relu\": torch.nn.functional.relu, \"swish\": torch.nn.functional.silu}\n",
        "\n",
        "# 모델 설정\n",
        "\n",
        "# BERT 입력 임베딩 생성 클래스\n",
        "class BertEmbeddings(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        # 단어 임베딩, 위치 임베딩, 토큰 타입 임베딩\n",
        "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)\n",
        "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
        "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
        "        # 레이어 정규화와 드롭아웃\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.position_embedding_type = getattr(config, \"position_embedding_type\", \"absolute\")\n",
        "        self.register_buffer(\"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)), persistent=False)\n",
        "        self.register_buffer(\"token_type_ids\", torch.zeros(self.position_ids.size(), dtype=torch.long), persistent=False)\n",
        "\n",
        "    def forward(self, input_ids=None, token_type_ids=None, position_ids=None, inputs_embeds=None, past_key_values_length=0):\n",
        "        if input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "        else:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "\n",
        "        seq_length = input_shape[1]\n",
        "\n",
        "        if position_ids is None:\n",
        "            position_ids = self.position_ids[:, past_key_values_length: seq_length + past_key_values_length]\n",
        "\n",
        "        if token_type_ids is None:\n",
        "            if hasattr(self, \"token_type_ids\"):\n",
        "                buffered_token_type_ids = self.token_type_ids[:, :seq_length]\n",
        "                buffered_token_type_ids_expanded = buffered_token_type_ids.expand(input_shape[0], seq_length)\n",
        "                token_type_ids = buffered_token_type_ids_expanded\n",
        "            else:\n",
        "                token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.position_ids.device)\n",
        "\n",
        "        if inputs_embeds is None:\n",
        "            inputs_embeds = self.word_embeddings(input_ids)\n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "\n",
        "        # 입력 임베딩 생성\n",
        "        embeddings = inputs_embeds + token_type_embeddings\n",
        "        if self.position_embedding_type == \"absolute\":\n",
        "            position_embeddings = self.position_embeddings(position_ids)\n",
        "            embeddings += position_embeddings\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        return embeddings\n",
        "\n",
        "# 셀프 어텐션 구현 클래스\n",
        "class BertSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        if config.hidden_size % config.num_attention_heads != 0:\n",
        "            raise ValueError(\n",
        "                \"The hidden size (%d) is not a multiple of the number of attention heads (%d)\" %\n",
        "                (config.hidden_size, config.num_attention_heads))\n",
        "\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "\n",
        "        #################################\n",
        "        self.keyword_scale = nn.Parameter(torch.ones(1))# 키워드 스코어에 대한 스케일링 파라미터를 학습 가능하도록 추가\n",
        "        #################################\n",
        "\n",
        "    def transpose_for_scores(self, x):\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(*new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        mixed_key_layer = self.key(hidden_states)\n",
        "        mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
        "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
        "\n",
        "        #################################\n",
        "        # 어텐션 스코어 계산\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "\n",
        "        # 키워드 스코어 계산\n",
        "        cls_token = hidden_states[:, 0, :]  # CLS 토큰 추출\n",
        "        token_similarities = F.cosine_similarity(hidden_states, cls_token.unsqueeze(1).expand_as(hidden_states), dim=-1)  # 각 토큰과 CLS토큰의 cosine similarity 계산\n",
        "        keyword_scores = (token_similarities + 1) / 2  # 0~1사이로 매핑\n",
        "\n",
        "        # 어텐션 스코어에 키워드 스코어 반영\n",
        "        attention_scores = attention_scores * keyword_scores.unsqueeze(1).unsqueeze(1) * self.keyword_scale # 키워드 스코어를 attention score에 곱한 후, 스케일링 파라미터를 적용\n",
        "        #################################\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "# 셀프 어텐션 출력 처리 클래스\n",
        "class BertSelfOutput(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        # 드롭아웃, 레이어 정규화, 잔차 연결 적용\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "\n",
        "# 어텐션 메커니즘 클래스\n",
        "class BertAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.self = BertSelfAttention(config)\n",
        "        self.output = BertSelfOutput(config)\n",
        "\n",
        "    def forward(self, input_tensor, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_value=None, output_attentions=False):\n",
        "        # 셀프 어텐션 및 출력 계산\n",
        "        self_outputs = self.self(\n",
        "            input_tensor,\n",
        "            attention_mask,\n",
        "            head_mask,\n",
        "            encoder_hidden_states,\n",
        "            encoder_attention_mask,\n",
        "            past_key_value,\n",
        "            output_attentions,\n",
        "        )\n",
        "        attention_output = self.output(self_outputs[0], input_tensor)\n",
        "        outputs = (attention_output,) + self_outputs[1:]\n",
        "        return outputs\n",
        "\n",
        "# 중간 레이어 활성화 함수 클래스\n",
        "class BertIntermediate(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
        "        self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        # 중간 레이어 활성화 함수 적용\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "# 중간 레이어 출력 처리 클래스\n",
        "class BertOutput(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        # 드롭아웃, 레이어 정규화, 잔차 연결 적용\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.Layer\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        # 드롭아웃, 레이어 정규화, 잔차 연결 적용\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "\n",
        "# 하나의 BERT 레이어를 구현하는 클래스\n",
        "class BertLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.attention = BertAttention(config)\n",
        "        self.intermediate = BertIntermediate(config)\n",
        "        self.output = BertOutput(config)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_value=None, output_attentions=False):\n",
        "        # 어텐션과 출력 계산\n",
        "        self_attention_outputs = self.attention(\n",
        "            hidden_states,\n",
        "            attention_mask,\n",
        "            head_mask,\n",
        "            encoder_hidden_states,\n",
        "            encoder_attention_mask,\n",
        "            past_key_value,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        attention_output = self_attention_outputs[0]\n",
        "        layer_output = self.output(self.intermediate(attention_output), attention_output)\n",
        "        outputs = (layer_output,) + self_attention_outputs[1:]\n",
        "        return outputs\n",
        "\n",
        "# 여러 BERT 레이어를 포함하는 인코더 클래스\n",
        "class BertEncoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_values=None, use_cache=None, output_attentions=False, output_hidden_states=False, return_dict=True):\n",
        "        all_hidden_states = () if output_hidden_states else None\n",
        "        all_attentions = () if output_attentions else None\n",
        "        for i, layer_module in enumerate(self.layer):\n",
        "            layer_head_mask = head_mask[i] if head_mask is not None else None\n",
        "            past_key_value = past_key_values[i] if past_key_values is not None else None\n",
        "\n",
        "            if output_hidden_states:\n",
        "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "            layer_outputs = layer_module(\n",
        "                hidden_states,\n",
        "                attention_mask,\n",
        "                layer_head_mask,\n",
        "                encoder_hidden_states,\n",
        "                encoder_attention_mask,\n",
        "                past_key_value,\n",
        "                output_attentions,\n",
        "            )\n",
        "            hidden_states = layer_outputs[0]\n",
        "\n",
        "            if output_attentions:\n",
        "                all_attentions = all_attentions + (layer_outputs[1],)\n",
        "\n",
        "        return (hidden_states, all_hidden_states, all_attentions)\n",
        "\n",
        "# 첫 번째 토큰의 출력을 풀링하는 클래스\n",
        "class BertPooler(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        # 첫 번째 토큰의 텐서를 사용해 풀링 출력 생성\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        pooled_output = self.dense(first_token_tensor)\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "        return pooled_output\n",
        "\n",
        "# 전체 BERT 모델을 구현하는 클래스\n",
        "class  userBertModel(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.embeddings = BertEmbeddings(config)\n",
        "        self.encoder = BertEncoder(config)\n",
        "        self.pooler = BertPooler(config)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, encoder_hidden_states=None, encoder_attention_mask=None, past_key_values=None, use_cache=None, output_attentions=None, output_hidden_states=None, return_dict=None):\n",
        "        # 입력 텐서의 크기 확인\n",
        "        if input_ids is not None and inputs_embeds is not None:\n",
        "            raise ValueError(\"input_ids 혹은 inputs_embeds 둘 중 하나의 형식으로만 입력해야 합니다.\")\n",
        "        elif input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "        elif inputs_embeds is not None:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "        else:\n",
        "            raise ValueError(\"input_ids 또는 inputs_embeds의 형식이어야 합니다.\")\n",
        "\n",
        "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones(input_shape, device=device)\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "\n",
        "        extended_attention_mask = attention_mask[:, None, None, :]\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype)\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "\n",
        "        head_mask = [None] * self.config.num_hidden_layers\n",
        "\n",
        "        # 임베딩 출력 계산\n",
        "        embedding_output = self.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            position_ids=position_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "        # 인코더 출력 계산\n",
        "        encoder_outputs = self.encoder(\n",
        "            embedding_output,\n",
        "            attention_mask=extended_attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states=encoder_hidden_states,\n",
        "            encoder_attention_mask=encoder_attention_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        sequence_output = encoder_outputs[0]\n",
        "        pooled_output = self.pooler(sequence_output)\n",
        "        return sequence_output, pooled_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAXhMfNkYbth"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aTojxNkPIxO",
        "outputId": "644c5820-076b-45b6-fc55-596c15bac5aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, Batch: 0, Loss: 0.7218005061149597, Accuracy: 0.4375\n",
            "Epoch: 0, Batch: 10, Loss: 0.7180731892585754, Accuracy: 0.5\n",
            "Epoch: 0, Batch: 20, Loss: 0.7241774797439575, Accuracy: 0.5208333333333334\n",
            "Epoch: 0, Batch: 30, Loss: 0.6761768460273743, Accuracy: 0.530241935483871\n",
            "Epoch: 0, Batch: 40, Loss: 0.667255699634552, Accuracy: 0.538109756097561\n",
            "Epoch: 0, Batch: 50, Loss: 0.6888106465339661, Accuracy: 0.5416666666666666\n",
            "Epoch: 0, Batch: 60, Loss: 0.6721405982971191, Accuracy: 0.5543032786885246\n",
            "Epoch: 0, Batch: 70, Loss: 0.6303560137748718, Accuracy: 0.5721830985915493\n",
            "Epoch: 0, Batch: 80, Loss: 0.586635410785675, Accuracy: 0.5810185185185185\n",
            "Epoch: 0, Batch: 90, Loss: 0.5819013118743896, Accuracy: 0.5899725274725275\n",
            "Epoch: 0, Batch: 100, Loss: 0.5867515802383423, Accuracy: 0.5983910891089109\n",
            "Epoch: 0, Batch: 110, Loss: 0.633612871170044, Accuracy: 0.606418918918919\n",
            "Epoch: 0, Batch: 120, Loss: 0.5968360900878906, Accuracy: 0.6157024793388429\n",
            "Epoch: 0, Batch: 130, Loss: 0.4554211497306824, Accuracy: 0.6273854961832062\n",
            "Epoch: 0, Batch: 140, Loss: 0.6563376188278198, Accuracy: 0.6343085106382979\n",
            "Epoch: 0, Batch: 150, Loss: 0.5182461738586426, Accuracy: 0.6411423841059603\n",
            "Epoch: 0, Batch: 160, Loss: 0.5923036932945251, Accuracy: 0.6451863354037267\n",
            "Epoch: 0, Batch: 170, Loss: 0.4031173586845398, Accuracy: 0.6505847953216374\n",
            "Epoch: 0, Batch: 180, Loss: 0.4221247136592865, Accuracy: 0.6553867403314917\n",
            "Epoch: 0, Batch: 190, Loss: 0.39430317282676697, Accuracy: 0.6609947643979057\n",
            "Epoch: 0, Batch: 200, Loss: 0.5749009251594543, Accuracy: 0.6669776119402985\n",
            "Epoch: 0, Batch: 210, Loss: 0.5497323870658875, Accuracy: 0.6712085308056872\n",
            "Epoch: 0, Batch: 220, Loss: 0.5380814075469971, Accuracy: 0.6753393665158371\n",
            "Epoch: 0, Batch: 230, Loss: 0.501885712146759, Accuracy: 0.6807359307359307\n",
            "Epoch: 0, Batch: 240, Loss: 0.4393467903137207, Accuracy: 0.6859439834024896\n",
            "Epoch: 0, Batch: 250, Loss: 0.4542388916015625, Accuracy: 0.6902390438247012\n",
            "Epoch: 0, Batch: 260, Loss: 0.41234561800956726, Accuracy: 0.6954022988505747\n",
            "Epoch: 0, Batch: 270, Loss: 0.43359771370887756, Accuracy: 0.6990313653136532\n",
            "Epoch: 0, Batch: 280, Loss: 0.34720340371131897, Accuracy: 0.7019572953736655\n",
            "Epoch: 0, Batch: 290, Loss: 0.22397948801517487, Accuracy: 0.7048969072164949\n",
            "Epoch: 0, Batch: 300, Loss: 0.7422608137130737, Accuracy: 0.7068106312292359\n",
            "Epoch: 0, Batch: 310, Loss: 0.35244566202163696, Accuracy: 0.7110128617363344\n",
            "Epoch: 0, Batch: 320, Loss: 0.6305758953094482, Accuracy: 0.7147585669781932\n",
            "Epoch: 0, Batch: 330, Loss: 0.31972554326057434, Accuracy: 0.7188444108761329\n",
            "Epoch: 0, Batch: 340, Loss: 0.4289850890636444, Accuracy: 0.7206744868035191\n",
            "Epoch: 0, Batch: 350, Loss: 0.3395520746707916, Accuracy: 0.7252492877492878\n",
            "Epoch: 0, Batch: 360, Loss: 0.4300565719604492, Accuracy: 0.7288781163434903\n",
            "Epoch: 0, Batch: 370, Loss: 0.34538573026657104, Accuracy: 0.7318059299191375\n",
            "Epoch: 0, Batch: 380, Loss: 0.26823580265045166, Accuracy: 0.7349081364829396\n",
            "Epoch: 0, Batch: 390, Loss: 0.30501431226730347, Accuracy: 0.7378516624040921\n",
            "Epoch: 0, Batch: 400, Loss: 0.47843095660209656, Accuracy: 0.7400249376558603\n",
            "Epoch: 0, Batch: 410, Loss: 0.33346131443977356, Accuracy: 0.7420924574209246\n",
            "Epoch: 0, Batch: 420, Loss: 0.3342982232570648, Accuracy: 0.7434679334916865\n",
            "Epoch: 0, Batch: 430, Loss: 0.3321157991886139, Accuracy: 0.7453596287703016\n",
            "Epoch: 0, Batch: 440, Loss: 0.2991766631603241, Accuracy: 0.7481575963718821\n",
            "Epoch: 0, Batch: 450, Loss: 0.353316068649292, Accuracy: 0.7506929046563193\n",
            "Epoch: 0, Batch: 460, Loss: 0.21104632318019867, Accuracy: 0.7523047722342733\n",
            "Epoch: 0, Batch: 470, Loss: 0.16011330485343933, Accuracy: 0.7541135881104034\n",
            "Epoch: 0, Batch: 480, Loss: 0.564699113368988, Accuracy: 0.7554573804573804\n",
            "Epoch: 0, Batch: 490, Loss: 0.4062093198299408, Accuracy: 0.7572556008146639\n",
            "Epoch: 0, Batch: 500, Loss: 0.30275386571884155, Accuracy: 0.7593562874251497\n",
            "Epoch: 0, Batch: 510, Loss: 0.32702121138572693, Accuracy: 0.761252446183953\n",
            "Epoch: 0, Batch: 520, Loss: 0.3032737970352173, Accuracy: 0.7624760076775432\n",
            "Epoch: 0, Batch: 530, Loss: 0.44977623224258423, Accuracy: 0.763653483992467\n",
            "Epoch: 0, Batch: 540, Loss: 0.4569733738899231, Accuracy: 0.7643253234750462\n",
            "Epoch: 0, Batch: 550, Loss: 0.4262789487838745, Accuracy: 0.7657667876588021\n",
            "Epoch: 0, Batch: 560, Loss: 0.1783442199230194, Accuracy: 0.768048128342246\n",
            "Epoch: 0, Batch: 570, Loss: 0.27064040303230286, Accuracy: 0.7691549912434326\n",
            "Epoch: 0, Batch: 580, Loss: 0.17902985215187073, Accuracy: 0.7699010327022375\n",
            "Epoch: 0, Batch: 590, Loss: 0.3843645751476288, Accuracy: 0.7707275803722504\n",
            "Epoch: 0 finished with average loss: 0.46614085994660853, Accuracy: 0.7719791666666667\n",
            "Epoch: 1, Batch: 0, Loss: 0.18296043574810028, Accuracy: 1.0\n",
            "Epoch: 1, Batch: 10, Loss: 0.3127914369106293, Accuracy: 0.8863636363636364\n",
            "Epoch: 1, Batch: 20, Loss: 0.1928214728832245, Accuracy: 0.8928571428571429\n",
            "Epoch: 1, Batch: 30, Loss: 0.3236505091190338, Accuracy: 0.8891129032258065\n",
            "Epoch: 1, Batch: 40, Loss: 0.16200290620326996, Accuracy: 0.8719512195121951\n",
            "Epoch: 1, Batch: 50, Loss: 0.30919575691223145, Accuracy: 0.8639705882352942\n",
            "Epoch: 1, Batch: 60, Loss: 0.41139280796051025, Accuracy: 0.8586065573770492\n",
            "Epoch: 1, Batch: 70, Loss: 0.588483989238739, Accuracy: 0.8529929577464789\n",
            "Epoch: 1, Batch: 80, Loss: 0.10980220139026642, Accuracy: 0.8572530864197531\n",
            "Epoch: 1, Batch: 90, Loss: 0.21073991060256958, Accuracy: 0.8619505494505495\n",
            "Epoch: 1, Batch: 100, Loss: 0.10067284107208252, Accuracy: 0.8626237623762376\n",
            "Epoch: 1, Batch: 110, Loss: 0.3207719326019287, Accuracy: 0.8614864864864865\n",
            "Epoch: 1, Batch: 120, Loss: 0.3804602324962616, Accuracy: 0.8610537190082644\n",
            "Epoch: 1, Batch: 130, Loss: 0.059800390154123306, Accuracy: 0.8659351145038168\n",
            "Epoch: 1, Batch: 140, Loss: 0.2275468111038208, Accuracy: 0.8674645390070922\n",
            "Epoch: 1, Batch: 150, Loss: 0.3737545609474182, Accuracy: 0.8696192052980133\n",
            "Epoch: 1, Batch: 160, Loss: 0.4544696509838104, Accuracy: 0.8680124223602484\n",
            "Epoch: 1, Batch: 170, Loss: 0.2537494897842407, Accuracy: 0.8654970760233918\n",
            "Epoch: 1, Batch: 180, Loss: 0.2000124305486679, Accuracy: 0.868439226519337\n",
            "Epoch: 1, Batch: 190, Loss: 0.14404217898845673, Accuracy: 0.8694371727748691\n",
            "Epoch: 1, Batch: 200, Loss: 0.4666542410850525, Accuracy: 0.8715796019900498\n",
            "Epoch: 1, Batch: 210, Loss: 0.13273563981056213, Accuracy: 0.8741113744075829\n",
            "Epoch: 1, Batch: 220, Loss: 0.32166150212287903, Accuracy: 0.8752828054298643\n",
            "Epoch: 1, Batch: 230, Loss: 0.1993112564086914, Accuracy: 0.8755411255411255\n",
            "Epoch: 1, Batch: 240, Loss: 0.20495131611824036, Accuracy: 0.8765560165975104\n",
            "Epoch: 1, Batch: 250, Loss: 0.41310355067253113, Accuracy: 0.8752490039840638\n",
            "Epoch: 1, Batch: 260, Loss: 0.2579349875450134, Accuracy: 0.8761973180076629\n",
            "Epoch: 1, Batch: 270, Loss: 0.22065065801143646, Accuracy: 0.8766143911439115\n",
            "Epoch: 1, Batch: 280, Loss: 0.3751978874206543, Accuracy: 0.8756672597864769\n",
            "Epoch: 1, Batch: 290, Loss: 0.09315939992666245, Accuracy: 0.8769329896907216\n",
            "Epoch: 1, Batch: 300, Loss: 0.22038933634757996, Accuracy: 0.8774916943521595\n",
            "Epoch: 1, Batch: 310, Loss: 0.14127226173877716, Accuracy: 0.8780144694533762\n",
            "Epoch: 1, Batch: 320, Loss: 0.5745698809623718, Accuracy: 0.8785046728971962\n",
            "Epoch: 1, Batch: 330, Loss: 0.3325618505477905, Accuracy: 0.8785876132930514\n",
            "Epoch: 1, Batch: 340, Loss: 0.3612186014652252, Accuracy: 0.8786656891495601\n",
            "Epoch: 1, Batch: 350, Loss: 0.22118641436100006, Accuracy: 0.8794515669515669\n",
            "Epoch: 1, Batch: 360, Loss: 0.3939201533794403, Accuracy: 0.8784626038781164\n",
            "Epoch: 1, Batch: 370, Loss: 0.3406651020050049, Accuracy: 0.8797169811320755\n",
            "Epoch: 1, Batch: 380, Loss: 0.10934721678495407, Accuracy: 0.8805774278215223\n",
            "Epoch: 1, Batch: 390, Loss: 0.10249723494052887, Accuracy: 0.8802749360613811\n",
            "Epoch: 1, Batch: 400, Loss: 0.1700747013092041, Accuracy: 0.8799875311720698\n",
            "Epoch: 1, Batch: 410, Loss: 0.2420540601015091, Accuracy: 0.8794099756690997\n",
            "Epoch: 1, Batch: 420, Loss: 0.3297733962535858, Accuracy: 0.8790083135391924\n",
            "Epoch: 1, Batch: 430, Loss: 0.24268707633018494, Accuracy: 0.87877030162413\n",
            "Epoch: 1, Batch: 440, Loss: 0.35021570324897766, Accuracy: 0.8786848072562359\n",
            "Epoch: 1, Batch: 450, Loss: 0.2990485727787018, Accuracy: 0.8790188470066519\n",
            "Epoch: 1, Batch: 460, Loss: 0.13323581218719482, Accuracy: 0.8793383947939263\n",
            "Epoch: 1, Batch: 470, Loss: 0.11438120901584625, Accuracy: 0.8797770700636943\n",
            "Epoch: 1, Batch: 480, Loss: 0.45938190817832947, Accuracy: 0.8801975051975052\n",
            "Epoch: 1, Batch: 490, Loss: 0.25690269470214844, Accuracy: 0.880346232179226\n",
            "Epoch: 1, Batch: 500, Loss: 0.18034684658050537, Accuracy: 0.8807385229540918\n",
            "Epoch: 1, Batch: 510, Loss: 0.5218104124069214, Accuracy: 0.8808708414872799\n",
            "Epoch: 1, Batch: 520, Loss: 0.2727130055427551, Accuracy: 0.8809980806142035\n",
            "Epoch: 1, Batch: 530, Loss: 0.24590694904327393, Accuracy: 0.881120527306968\n",
            "Epoch: 1, Batch: 540, Loss: 0.39188143610954285, Accuracy: 0.8804297597042514\n",
            "Epoch: 1, Batch: 550, Loss: 0.4189303517341614, Accuracy: 0.8804446460980037\n",
            "Epoch: 1, Batch: 560, Loss: 0.1153230369091034, Accuracy: 0.8816844919786097\n",
            "Epoch: 1, Batch: 570, Loss: 0.12950409948825836, Accuracy: 0.8815674255691769\n",
            "Epoch: 1, Batch: 580, Loss: 0.13233743607997894, Accuracy: 0.881131669535284\n",
            "Epoch: 1, Batch: 590, Loss: 0.29553133249282837, Accuracy: 0.8810279187817259\n",
            "Epoch: 1 finished with average loss: 0.29282506086553134, Accuracy: 0.8811458333333333\n",
            "Epoch: 2, Batch: 0, Loss: 0.10873137414455414, Accuracy: 1.0\n",
            "Epoch: 2, Batch: 10, Loss: 0.19621114432811737, Accuracy: 0.8977272727272727\n",
            "Epoch: 2, Batch: 20, Loss: 0.08181256055831909, Accuracy: 0.9107142857142857\n",
            "Epoch: 2, Batch: 30, Loss: 0.26467978954315186, Accuracy: 0.9112903225806451\n",
            "Epoch: 2, Batch: 40, Loss: 0.08721083402633667, Accuracy: 0.899390243902439\n",
            "Epoch: 2, Batch: 50, Loss: 0.20567552745342255, Accuracy: 0.8872549019607843\n",
            "Epoch: 2, Batch: 60, Loss: 0.21601368486881256, Accuracy: 0.8801229508196722\n",
            "Epoch: 2, Batch: 70, Loss: 0.4279826879501343, Accuracy: 0.8811619718309859\n",
            "Epoch: 2, Batch: 80, Loss: 0.10691499710083008, Accuracy: 0.8865740740740741\n",
            "Epoch: 2, Batch: 90, Loss: 0.20950183272361755, Accuracy: 0.8894230769230769\n",
            "Epoch: 2, Batch: 100, Loss: 0.1215011477470398, Accuracy: 0.8886138613861386\n",
            "Epoch: 2, Batch: 110, Loss: 0.18891172111034393, Accuracy: 0.8868243243243243\n",
            "Epoch: 2, Batch: 120, Loss: 0.2560316026210785, Accuracy: 0.890495867768595\n",
            "Epoch: 2, Batch: 130, Loss: 0.04517812281847, Accuracy: 0.8931297709923665\n",
            "Epoch: 2, Batch: 140, Loss: 0.14321433007717133, Accuracy: 0.8962765957446809\n",
            "Epoch: 2, Batch: 150, Loss: 0.36846089363098145, Accuracy: 0.8981788079470199\n",
            "Epoch: 2, Batch: 160, Loss: 0.39037325978279114, Accuracy: 0.8951863354037267\n",
            "Epoch: 2, Batch: 170, Loss: 0.12789520621299744, Accuracy: 0.893640350877193\n",
            "Epoch: 2, Batch: 180, Loss: 0.1394142210483551, Accuracy: 0.8960635359116023\n",
            "Epoch: 2, Batch: 190, Loss: 0.1151658371090889, Accuracy: 0.8965968586387435\n",
            "Epoch: 2, Batch: 200, Loss: 0.39733341336250305, Accuracy: 0.8989427860696517\n",
            "Epoch: 2, Batch: 210, Loss: 0.08301892131567001, Accuracy: 0.9001777251184834\n",
            "Epoch: 2, Batch: 220, Loss: 0.3361239731311798, Accuracy: 0.9007352941176471\n",
            "Epoch: 2, Batch: 230, Loss: 0.16763439774513245, Accuracy: 0.9007034632034632\n",
            "Epoch: 2, Batch: 240, Loss: 0.06578235328197479, Accuracy: 0.9024896265560166\n",
            "Epoch: 2, Batch: 250, Loss: 0.4461982250213623, Accuracy: 0.9011454183266933\n",
            "Epoch: 2, Batch: 260, Loss: 0.20078201591968536, Accuracy: 0.9015804597701149\n",
            "Epoch: 2, Batch: 270, Loss: 0.10750289261341095, Accuracy: 0.9029059040590406\n",
            "Epoch: 2, Batch: 280, Loss: 0.30402275919914246, Accuracy: 0.902135231316726\n",
            "Epoch: 2, Batch: 290, Loss: 0.052707407623529434, Accuracy: 0.9029209621993127\n",
            "Epoch: 2, Batch: 300, Loss: 0.11772459000349045, Accuracy: 0.9040697674418605\n",
            "Epoch: 2, Batch: 310, Loss: 0.11699537932872772, Accuracy: 0.9047427652733119\n",
            "Epoch: 2, Batch: 320, Loss: 0.5135653018951416, Accuracy: 0.9047897196261683\n",
            "Epoch: 2, Batch: 330, Loss: 0.3394264280796051, Accuracy: 0.9052114803625377\n",
            "Epoch: 2, Batch: 340, Loss: 0.2767750024795532, Accuracy: 0.9046920821114369\n",
            "Epoch: 2, Batch: 350, Loss: 0.2386915236711502, Accuracy: 0.9052706552706553\n",
            "Epoch: 2, Batch: 360, Loss: 0.2705358564853668, Accuracy: 0.9044321329639889\n",
            "Epoch: 2, Batch: 370, Loss: 0.4174450635910034, Accuracy: 0.9044811320754716\n",
            "Epoch: 2, Batch: 380, Loss: 0.08360401540994644, Accuracy: 0.9041994750656168\n",
            "Epoch: 2, Batch: 390, Loss: 0.052265774458646774, Accuracy: 0.9044117647058824\n",
            "Epoch: 2, Batch: 400, Loss: 0.16641879081726074, Accuracy: 0.9043017456359103\n",
            "Epoch: 2, Batch: 410, Loss: 0.23318541049957275, Accuracy: 0.9043491484184915\n",
            "Epoch: 2, Batch: 420, Loss: 0.3611510396003723, Accuracy: 0.9046912114014252\n",
            "Epoch: 2, Batch: 430, Loss: 0.18515965342521667, Accuracy: 0.904292343387471\n",
            "Epoch: 2, Batch: 440, Loss: 0.34297850728034973, Accuracy: 0.9044784580498866\n",
            "Epoch: 2, Batch: 450, Loss: 0.31136205792427063, Accuracy: 0.9046563192904656\n",
            "Epoch: 2, Batch: 460, Loss: 0.0884919986128807, Accuracy: 0.9056399132321041\n",
            "Epoch: 2, Batch: 470, Loss: 0.1713772416114807, Accuracy: 0.9055201698513801\n",
            "Epoch: 2, Batch: 480, Loss: 0.41150474548339844, Accuracy: 0.9056652806652806\n",
            "Epoch: 2, Batch: 490, Loss: 0.29634758830070496, Accuracy: 0.9059317718940937\n",
            "Epoch: 2, Batch: 500, Loss: 0.1454824060201645, Accuracy: 0.906686626746507\n",
            "Epoch: 2, Batch: 510, Loss: 0.44853585958480835, Accuracy: 0.9066780821917808\n",
            "Epoch: 2, Batch: 520, Loss: 0.17520184814929962, Accuracy: 0.906309980806142\n",
            "Epoch: 2, Batch: 530, Loss: 0.24983608722686768, Accuracy: 0.9061911487758946\n",
            "Epoch: 2, Batch: 540, Loss: 0.38708123564720154, Accuracy: 0.9057301293900185\n",
            "Epoch: 2, Batch: 550, Loss: 0.3719950318336487, Accuracy: 0.9057395644283122\n",
            "Epoch: 2, Batch: 560, Loss: 0.04416205361485481, Accuracy: 0.9063057040998217\n",
            "Epoch: 2, Batch: 570, Loss: 0.06951656937599182, Accuracy: 0.9060858143607706\n",
            "Epoch: 2, Batch: 580, Loss: 0.1889127641916275, Accuracy: 0.9058734939759037\n",
            "Epoch: 2, Batch: 590, Loss: 0.26620998978614807, Accuracy: 0.9055626057529611\n",
            "Epoch: 2 finished with average loss: 0.23976473717329402, Accuracy: 0.9055208333333333\n",
            "Epoch: 2, Batch: 0, Loss: 0.10953700542449951, Accuracy: 1.0\n",
            "Epoch: 2, Batch: 10, Loss: 0.13787423074245453, Accuracy: 0.9034090909090909\n",
            "Epoch: 2, Batch: 20, Loss: 0.270795613527298, Accuracy: 0.8928571428571429\n",
            "Epoch: 2, Batch: 30, Loss: 0.23003502190113068, Accuracy: 0.8870967741935484\n",
            "Epoch: 2, Batch: 40, Loss: 0.23247584700584412, Accuracy: 0.8948170731707317\n",
            "Epoch: 2, Batch: 50, Loss: 0.3508763611316681, Accuracy: 0.8933823529411765\n",
            "Epoch: 2, Batch: 60, Loss: 0.41077351570129395, Accuracy: 0.889344262295082\n",
            "Epoch: 2, Batch: 70, Loss: 0.12681493163108826, Accuracy: 0.8846830985915493\n",
            "Epoch: 2, Batch: 80, Loss: 0.645691454410553, Accuracy: 0.8804012345679012\n",
            "Epoch: 2, Batch: 90, Loss: 0.16400639712810516, Accuracy: 0.8791208791208791\n",
            "Epoch: 2, Batch: 100, Loss: 0.2791811525821686, Accuracy: 0.8811881188118812\n",
            "Epoch: 2, Batch: 110, Loss: 0.25543054938316345, Accuracy: 0.8834459459459459\n",
            "Epoch: 2, Batch: 120, Loss: 0.313583642244339, Accuracy: 0.8848140495867769\n",
            "Epoch: 2, Batch: 130, Loss: 0.13765281438827515, Accuracy: 0.8854961832061069\n",
            "Epoch: 2, Batch: 140, Loss: 0.3013302683830261, Accuracy: 0.8847517730496454\n",
            "Epoch: 2 finished with average loss: 0.0692362801109751, Accuracy: 0.8866666666666667\n",
            "Model saved to ./my_finetuned_bert_model.pth\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertModel, BertConfig\n",
        "# 위 구조를 취합하여 만든 이진 감정 분류를 위한 클래스\n",
        "class BertForSequenceClassification(nn.Module):\n",
        "    def __init__(self, config, num_labels):\n",
        "        super(BertForSequenceClassification, self).__init__()\n",
        "        self.bert = userBertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, 2), labels.view(-1))\n",
        "\n",
        "        return loss, logits\n",
        "\n",
        "# Pretrained BERT 모델 로드\n",
        "\n",
        "pretrained_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "pretrained_state_dict = pretrained_model.state_dict()\n",
        "\n",
        "# Custom 모델 초기화\n",
        "custom_config = BertConfig(\n",
        "    vocab_size=30522,\n",
        "    hidden_size=768,\n",
        "    num_hidden_layers=8,\n",
        "    num_attention_heads=12, # 수정된 부분\n",
        "    intermediate_size=3072, # 수정된 부분\n",
        "    hidden_act=\"gelu\",\n",
        "    hidden_dropout_prob=0.1,\n",
        "    attention_probs_dropout_prob=0.1,\n",
        "    max_position_embeddings=512,\n",
        "    type_vocab_size=2,\n",
        "    initializer_range=0.02,\n",
        "    layer_norm_eps=1e-12,\n",
        "    pad_token_id=0,\n",
        "    gradient_checkpointing=False,\n",
        "    position_embedding_type=\"absolute\",\n",
        "    use_cache=True\n",
        ")\n",
        "model = BertForSequenceClassification(custom_config, num_labels=2)\n",
        "\n",
        "# Pretrained 모델의 state_dict를 Custom 모델로 로드\n",
        "model.bert.load_state_dict(pretrained_state_dict, strict=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# 옵티마이저 설정\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-6)\n",
        "\n",
        "# 학습 진행\n",
        "model.train()\n",
        "for epoch in range(3):\n",
        "    epoch_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        token_type_ids = batch['token_type_ids'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask'],\n",
        "            token_type_ids=batch['token_type_ids'],\n",
        "            labels=batch['labels']\n",
        "        )\n",
        "        loss, logits = outputs\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # 예측값 계산\n",
        "        _, predicted = torch.max(logits, 1)\n",
        "        correct_predictions += (predicted == batch['labels']).sum().item()\n",
        "        total_predictions += batch['labels'].size(0)\n",
        "\n",
        "        if batch_idx % 10 == 0:  # 10번째 배치마다 현황 출력\n",
        "            batch_accuracy = correct_predictions / total_predictions\n",
        "            print(f\"Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item()}, Accuracy: {batch_accuracy}\")\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / len(train_dataloader)\n",
        "    epoch_accuracy = correct_predictions / total_predictions\n",
        "    print(f\"Epoch: {epoch} finished with average loss: {avg_epoch_loss}, Accuracy: {epoch_accuracy}\")\n",
        "\n",
        "model.eval()\n",
        "epoch_loss = 0\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, batch in enumerate(val_dataloader):\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        token_type_ids = batch['token_type_ids'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask'],\n",
        "            token_type_ids=batch['token_type_ids'],\n",
        "            labels=batch['labels']\n",
        "        )\n",
        "        loss, logits = outputs\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # 예측값 계산\n",
        "        _, predicted = torch.max(logits, 1)\n",
        "        correct_predictions += (predicted == batch['labels']).sum().item()\n",
        "        total_predictions += batch['labels'].size(0)\n",
        "\n",
        "        if batch_idx % 10 == 0:  # 10번째 배치마다 현황 출력\n",
        "            batch_accuracy = correct_predictions / total_predictions\n",
        "            print(f\"Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item()}, Accuracy: {batch_accuracy}\")\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / len(train_dataloader)\n",
        "    epoch_accuracy = correct_predictions / total_predictions\n",
        "    print(f\"Epoch: {epoch} finished with average loss: {avg_epoch_loss}, Accuracy: {epoch_accuracy}\")\n",
        "\n",
        "# 모델 저장 경로 설정\n",
        "save_path = './my_finetuned_bert_model.pth'\n",
        "\n",
        "# 모델 저장\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"Model saved to {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-BFv9MU58F_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os._exit(00)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsualEUMGMgq"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}